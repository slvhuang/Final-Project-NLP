{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MSCA 32018 Natural Language Processing and Cognitive Computing\n",
    "## Final Project - Targeted (Entity) Sentiment Identification\n",
    "\n",
    "\n",
    "Shijia Huang\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (3.8.1)\n",
      "Requirement already satisfied: spacy in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (3.5.2)\n",
      "Requirement already satisfied: gensim in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (4.3.1)\n",
      "Requirement already satisfied: pyLDAvis in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (3.2.2)\n",
      "Requirement already satisfied: rake_nltk in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (1.0.6)\n",
      "Requirement already satisfied: wordcloud in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 6)) (1.8.2.2)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (4.28.1)\n",
      "Requirement already satisfied: tensorflow in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (2.11.0)\n",
      "Requirement already satisfied: seaborn in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 9)) (0.12.2)\n",
      "Requirement already satisfied: pyarrow in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 10)) (9.0.0)\n",
      "Requirement already satisfied: gcsfs in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 11)) (2023.3.0)\n",
      "Requirement already satisfied: textblob in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 12)) (0.17.1)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk->-r requirements.txt (line 1)) (8.1.3)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.10/site-packages (from nltk->-r requirements.txt (line 1)) (2023.3.23)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from nltk->-r requirements.txt (line 1)) (4.64.1)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk->-r requirements.txt (line 1)) (1.2.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.10/site-packages (from spacy->-r requirements.txt (line 2)) (2.0.8)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from spacy->-r requirements.txt (line 2)) (1.10.7)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy->-r requirements.txt (line 2)) (3.0.8)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from spacy->-r requirements.txt (line 2)) (59.8.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy->-r requirements.txt (line 2)) (2.0.7)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from spacy->-r requirements.txt (line 2)) (0.10.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.10/site-packages (from spacy->-r requirements.txt (line 2)) (3.0.12)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.10/site-packages (from spacy->-r requirements.txt (line 2)) (6.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from spacy->-r requirements.txt (line 2)) (21.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from spacy->-r requirements.txt (line 2)) (3.1.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy->-r requirements.txt (line 2)) (3.3.0)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy->-r requirements.txt (line 2)) (0.7.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy->-r requirements.txt (line 2)) (1.0.9)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.10/site-packages (from spacy->-r requirements.txt (line 2)) (2.4.6)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from spacy->-r requirements.txt (line 2)) (2.28.2)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from spacy->-r requirements.txt (line 2)) (1.1.1)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy->-r requirements.txt (line 2)) (1.0.4)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /opt/conda/lib/python3.10/site-packages (from spacy->-r requirements.txt (line 2)) (8.1.9)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.10/site-packages (from spacy->-r requirements.txt (line 2)) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from gensim->-r requirements.txt (line 3)) (1.9.3)\n",
      "Requirement already satisfied: pandas>=0.17.0 in /opt/conda/lib/python3.10/site-packages (from pyLDAvis->-r requirements.txt (line 4)) (1.5.3)\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.10/site-packages (from pyLDAvis->-r requirements.txt (line 4)) (0.18.3)\n",
      "Requirement already satisfied: funcy in /opt/conda/lib/python3.10/site-packages (from pyLDAvis->-r requirements.txt (line 4)) (2.0)\n",
      "Requirement already satisfied: wheel>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from pyLDAvis->-r requirements.txt (line 4)) (0.40.0)\n",
      "Requirement already satisfied: numexpr in /opt/conda/lib/python3.10/site-packages (from pyLDAvis->-r requirements.txt (line 4)) (2.8.4)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from wordcloud->-r requirements.txt (line 6)) (3.6.3)\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (from wordcloud->-r requirements.txt (line 6)) (9.5.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 7)) (6.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /opt/conda/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 7)) (0.13.4)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 7)) (3.11.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 7)) (0.13.3)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow->-r requirements.txt (line 8)) (1.16.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow->-r requirements.txt (line 8)) (2.11.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow->-r requirements.txt (line 8)) (3.19.6)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow->-r requirements.txt (line 8)) (16.0.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow->-r requirements.txt (line 8)) (23.3.3)\n",
      "Requirement already satisfied: tensorboard<2.12,>=2.11 in /opt/conda/lib/python3.10/site-packages (from tensorflow->-r requirements.txt (line 8)) (2.11.2)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow->-r requirements.txt (line 8)) (1.6.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow->-r requirements.txt (line 8)) (3.3.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow->-r requirements.txt (line 8)) (3.8.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow->-r requirements.txt (line 8)) (4.5.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow->-r requirements.txt (line 8)) (0.29.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow->-r requirements.txt (line 8)) (2.2.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow->-r requirements.txt (line 8)) (1.4.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow->-r requirements.txt (line 8)) (1.15.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow->-r requirements.txt (line 8)) (1.53.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow->-r requirements.txt (line 8)) (0.2.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow->-r requirements.txt (line 8)) (0.4.0)\n",
      "Requirement already satisfied: keras<2.12,>=2.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow->-r requirements.txt (line 8)) (2.11.0)\n",
      "Requirement already satisfied: google-auth>=1.2 in /opt/conda/lib/python3.10/site-packages (from gcsfs->-r requirements.txt (line 11)) (2.17.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.10/site-packages (from gcsfs->-r requirements.txt (line 11)) (3.8.4)\n",
      "Requirement already satisfied: google-cloud-storage in /opt/conda/lib/python3.10/site-packages (from gcsfs->-r requirements.txt (line 11)) (1.44.0)\n",
      "Requirement already satisfied: google-auth-oauthlib in /opt/conda/lib/python3.10/site-packages (from gcsfs->-r requirements.txt (line 11)) (0.4.6)\n",
      "Requirement already satisfied: fsspec==2023.3.0 in /opt/conda/lib/python3.10/site-packages (from gcsfs->-r requirements.txt (line 11)) (2023.3.0)\n",
      "Requirement already satisfied: decorator>4.1.2 in /opt/conda/lib/python3.10/site-packages (from gcsfs->-r requirements.txt (line 11)) (5.1.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs->-r requirements.txt (line 11)) (1.8.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs->-r requirements.txt (line 11)) (22.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs->-r requirements.txt (line 11)) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs->-r requirements.txt (line 11)) (4.0.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs->-r requirements.txt (line 11)) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs->-r requirements.txt (line 11)) (2.1.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs->-r requirements.txt (line 11)) (1.3.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth>=1.2->gcsfs->-r requirements.txt (line 11)) (5.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth>=1.2->gcsfs->-r requirements.txt (line 11)) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth>=1.2->gcsfs->-r requirements.txt (line 11)) (0.2.8)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->spacy->-r requirements.txt (line 2)) (2.1.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->wordcloud->-r requirements.txt (line 6)) (3.0.9)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->wordcloud->-r requirements.txt (line 6)) (1.0.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->wordcloud->-r requirements.txt (line 6)) (1.4.4)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->wordcloud->-r requirements.txt (line 6)) (4.39.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->wordcloud->-r requirements.txt (line 6)) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->wordcloud->-r requirements.txt (line 6)) (0.11.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.17.0->pyLDAvis->-r requirements.txt (line 4)) (2023.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy->-r requirements.txt (line 2)) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy->-r requirements.txt (line 2)) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy->-r requirements.txt (line 2)) (1.26.15)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.12,>=2.11->tensorflow->-r requirements.txt (line 8)) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.12,>=2.11->tensorflow->-r requirements.txt (line 8)) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.12,>=2.11->tensorflow->-r requirements.txt (line 8)) (2.2.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.12,>=2.11->tensorflow->-r requirements.txt (line 8)) (3.4.3)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib->gcsfs->-r requirements.txt (line 11)) (1.3.1)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy->-r requirements.txt (line 2)) (0.0.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy->-r requirements.txt (line 2)) (0.7.9)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage->gcsfs->-r requirements.txt (line 11)) (2.4.1)\n",
      "Requirement already satisfied: google-api-core<3.0dev,>=1.29.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage->gcsfs->-r requirements.txt (line 11)) (1.34.0)\n",
      "Requirement already satisfied: google-cloud-core<3.0dev,>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage->gcsfs->-r requirements.txt (line 11)) (2.3.2)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core<3.0dev,>=1.29.0->google-cloud-storage->gcsfs->-r requirements.txt (line 11)) (1.59.0)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.10/site-packages (from google-resumable-media<3.0dev,>=1.3.0->google-cloud-storage->gcsfs->-r requirements.txt (line 11)) (1.5.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.2->gcsfs->-r requirements.txt (line 11)) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs->-r requirements.txt (line 11)) (3.2.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "# Import basic libraries\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-22 01:24:16.309725: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-22 01:24:17.672292: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64::/opt/conda/lib\n",
      "2023-05-22 01:24:17.672548: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64::/opt/conda/lib\n",
      "2023-05-22 01:24:17.672567: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-05-22 01:24:21.028181: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64::/opt/conda/lib\n",
      "2023-05-22 01:24:21.028230: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5.2\n"
     ]
    }
   ],
   "source": [
    "# Import NLP libraries\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "from pprint import pprint\n",
    "import string\n",
    "from rake_nltk import Rake\n",
    "\n",
    "import eli5\n",
    "import pickle\n",
    "\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from spacy.util import minibatch, compounding\n",
    "spacy.prefer_gpu()\n",
    "print(spacy.__version__)\n",
    "\n",
    "import gensim\n",
    "from gensim import corpora, models\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim as gensimvis\n",
    "#import pyLDAvis.gensim_models as gensimvis\n",
    "pyLDAvis.enable_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import sklearn libraries\n",
    "import sklearn\n",
    "import imblearn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available CPUs: 16\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "\n",
    "num_processors = mp.cpu_count()\n",
    "print(f'Available CPUs: {num_processors}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 45s, sys: 10.8 s, total: 1min 56s\n",
      "Wall time: 2min 25s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(154283, 11)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# read in the article‘s sentiment data\n",
    "path = \"gs://nlp-final-project-data/data/\"\n",
    "df_news = pd.read_parquet(path + 'news_sentiment.parquet', engine='pyarrow')\n",
    "df_news.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>cleaned title</th>\n",
       "      <th>cleaned text</th>\n",
       "      <th>title_tokens</th>\n",
       "      <th>title_lemmatized</th>\n",
       "      <th>text_tokens</th>\n",
       "      <th>text_lemmatized</th>\n",
       "      <th>title_keywords</th>\n",
       "      <th>text_keywords</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-02-27</td>\n",
       "      <td>Children With Autism Saw Their Learning and Social Skills Boosted After Playing With This AI Robot</td>\n",
       "      <td>Children With Autism Saw Their Learning and Social Skills Boosted After Playing With This AI Robot admin  Latest posts by admin see all  Mansplaining in conferences: How can we get him to forestall  February 27, 2020 Coronavirus Could Explode in the U.S. Overnight Like it Did in Italy  February 27, 2020 Levi Strauss marks the next phase in corporate paid leave policies  February 27, 2020 Scientists who designed an artificially clever robotic that helped youngsters with autism spice up their ...</td>\n",
       "      <td>[children, autism, saw, learning, social, skills, boosted, playing, ai, robot, children, autism, saw, learning, social, skills, boosted, playing, ai, robot, children, autism, saw, learning, social, skills, boosted, playing, ai_robot]</td>\n",
       "      <td>[child, autism, see, learn, social, skill, boost, play, robot, child, autism, see, learn, social, skill, boost, play, robot, child, autism, see, learn, social, skill, boost, play, ai_robot]</td>\n",
       "      <td>[children, autism, saw, learning, social, skills, boosted, playing, ai, robot, admin, latest, posts, admin, see, mansplaining, conferences, get, forestall, february, coronavirus, could, explode, overnight, like, italy, february, levi, strauss, marks, next, phase, corporate, paid, leave, policies, february, scientists, designed, artificially, clever, robotic, helped, youngsters, autism, spice, studying, social, talents, hope, era, may, future, help, others, developmental, dysfunction, learn, ...</td>\n",
       "      <td>[child, autism, see, learn, social, skill, boost, play, robot, late, post, admin, see, mansplaining, conference, get, explode, overnight, mark, next, phase, corporate, pay, leave, policy, scientist, design, artificially, clever, robotic, help, youngster, autism, spice, study, social, talent, era, future, help, other, developmental, dysfunction, learn, notice, youngster, gentle, average, autism, take, domestic, s, refer, socially, assistive, robotic, name, kiwi, month, accord, commentary, way...</td>\n",
       "      <td>[social, skill, see, play, learn, child, boost, autism, robot, ai_robot]</td>\n",
       "      <td>[robotic, youngster, kid, child, kiwi, market, autism, learn, crew, talent]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-03-26</td>\n",
       "      <td>Forget ML, AI and Industry 4.0 – obsolescence should be your focus</td>\n",
       "      <td>Forget ML, AI and Industry 4.0  obsolescence should be your focus The world entered a new era of accelerated transformation in the last eighteen months that will continue to evolve and press forward for years to come. Most businesses are playing catchup trying to make sense of a new timeline where the ten years that had been set aside for careful planning and implementation of what was coming up next no longer exists. The next is happening now and, regardless of your industry or seniority, t...</td>\n",
       "      <td>[forget, ml, ai, industry, obsolescence, focus, forget, ml, ai, industry, obsolescence, focus, forget, ml, ai, industry, obsolescence, focus]</td>\n",
       "      <td>[forget, ml, ai, industry, obsolescence, focus, forget, ml, ai, industry, obsolescence, focus, forget, ml, ai, industry, obsolescence, focus]</td>\n",
       "      <td>[forget, ml, ai, industry, obsolescence, focus, world, entered, new, era, accelerated, transformation, last, eighteen, months, continue, evolve, press, forward, years, come, businesses, playing, catchup, trying, make, sense, new, timeline, ten, years, set, aside, careful, planning, implementation, coming, next, longer, exists, next, happening, regardless, industry, seniority, status, quo, shifted, better, face, back, invited, attend, pompous, meeting, london, brazilian, embassy, along, selec...</td>\n",
       "      <td>[forget, ai, industry, obsolescence, focus, world, enter, new, era, accelerate, transformation, last, month, continue, evolve, press, forward, year, come, business, play, catchup, try, make, sense, new, timeline, year, set, aside, careful, planning, implementation, come, next, long, exist, next, happen, regardless, industry, seniority, status, quo, shift, well, face, back, invite, attend, pompous, meeting, brazilian, embassy, select, lead, name, oil, energy, industry, get, update, go, happen...</td>\n",
       "      <td>[obsolescence, ml, industry, forget, focus, ai]</td>\n",
       "      <td>[electronic, come, card, industry, repair, new, system, require, test, business]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id        date  \\\n",
       "0   1  2020-02-27   \n",
       "1   2  2021-03-26   \n",
       "\n",
       "                                                                                        cleaned title  \\\n",
       "0  Children With Autism Saw Their Learning and Social Skills Boosted After Playing With This AI Robot   \n",
       "1                                  Forget ML, AI and Industry 4.0 – obsolescence should be your focus   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          cleaned text  \\\n",
       "0  Children With Autism Saw Their Learning and Social Skills Boosted After Playing With This AI Robot admin  Latest posts by admin see all  Mansplaining in conferences: How can we get him to forestall  February 27, 2020 Coronavirus Could Explode in the U.S. Overnight Like it Did in Italy  February 27, 2020 Levi Strauss marks the next phase in corporate paid leave policies  February 27, 2020 Scientists who designed an artificially clever robotic that helped youngsters with autism spice up their ...   \n",
       "1  Forget ML, AI and Industry 4.0  obsolescence should be your focus The world entered a new era of accelerated transformation in the last eighteen months that will continue to evolve and press forward for years to come. Most businesses are playing catchup trying to make sense of a new timeline where the ten years that had been set aside for careful planning and implementation of what was coming up next no longer exists. The next is happening now and, regardless of your industry or seniority, t...   \n",
       "\n",
       "                                                                                                                                                                                                                                title_tokens  \\\n",
       "0  [children, autism, saw, learning, social, skills, boosted, playing, ai, robot, children, autism, saw, learning, social, skills, boosted, playing, ai, robot, children, autism, saw, learning, social, skills, boosted, playing, ai_robot]   \n",
       "1                                                                                              [forget, ml, ai, industry, obsolescence, focus, forget, ml, ai, industry, obsolescence, focus, forget, ml, ai, industry, obsolescence, focus]   \n",
       "\n",
       "                                                                                                                                                                                title_lemmatized  \\\n",
       "0  [child, autism, see, learn, social, skill, boost, play, robot, child, autism, see, learn, social, skill, boost, play, robot, child, autism, see, learn, social, skill, boost, play, ai_robot]   \n",
       "1                                                  [forget, ml, ai, industry, obsolescence, focus, forget, ml, ai, industry, obsolescence, focus, forget, ml, ai, industry, obsolescence, focus]   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           text_tokens  \\\n",
       "0  [children, autism, saw, learning, social, skills, boosted, playing, ai, robot, admin, latest, posts, admin, see, mansplaining, conferences, get, forestall, february, coronavirus, could, explode, overnight, like, italy, february, levi, strauss, marks, next, phase, corporate, paid, leave, policies, february, scientists, designed, artificially, clever, robotic, helped, youngsters, autism, spice, studying, social, talents, hope, era, may, future, help, others, developmental, dysfunction, learn, ...   \n",
       "1  [forget, ml, ai, industry, obsolescence, focus, world, entered, new, era, accelerated, transformation, last, eighteen, months, continue, evolve, press, forward, years, come, businesses, playing, catchup, trying, make, sense, new, timeline, ten, years, set, aside, careful, planning, implementation, coming, next, longer, exists, next, happening, regardless, industry, seniority, status, quo, shifted, better, face, back, invited, attend, pompous, meeting, london, brazilian, embassy, along, selec...   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       text_lemmatized  \\\n",
       "0  [child, autism, see, learn, social, skill, boost, play, robot, late, post, admin, see, mansplaining, conference, get, explode, overnight, mark, next, phase, corporate, pay, leave, policy, scientist, design, artificially, clever, robotic, help, youngster, autism, spice, study, social, talent, era, future, help, other, developmental, dysfunction, learn, notice, youngster, gentle, average, autism, take, domestic, s, refer, socially, assistive, robotic, name, kiwi, month, accord, commentary, way...   \n",
       "1  [forget, ai, industry, obsolescence, focus, world, enter, new, era, accelerate, transformation, last, month, continue, evolve, press, forward, year, come, business, play, catchup, try, make, sense, new, timeline, year, set, aside, careful, planning, implementation, come, next, long, exist, next, happen, regardless, industry, seniority, status, quo, shift, well, face, back, invite, attend, pompous, meeting, brazilian, embassy, select, lead, name, oil, energy, industry, get, update, go, happen...   \n",
       "\n",
       "                                                             title_keywords  \\\n",
       "0  [social, skill, see, play, learn, child, boost, autism, robot, ai_robot]   \n",
       "1                           [obsolescence, ml, industry, forget, focus, ai]   \n",
       "\n",
       "                                                                      text_keywords  \\\n",
       "0       [robotic, youngster, kid, child, kiwi, market, autism, learn, crew, talent]   \n",
       "1  [electronic, come, card, industry, repair, new, system, require, test, business]   \n",
       "\n",
       "   sentiment  \n",
       "0          5  \n",
       "1          4  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_news.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# remove links and special characters\n",
    "def remove_links(text):\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    text = re.sub(r'@\\S+', '', text)\n",
    "    text = re.sub(r'#\\S+', '', text)\n",
    "    text = re.sub(r'&\\S+', '', text)\n",
    "    text =  re.sub(r'\\S+.com', '', text)\n",
    "    text =  re.sub(r'\\S+.ca', '', text)\n",
    "    text =  re.sub(r'\\S+.org', '', text)\n",
    "    text = re.sub(r'[^a-zA-Z0-9 @ . , : - _]', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# clean the text\n",
    "df_news['cleaned text'] = df_news['cleaned text'].apply(lambda x: remove_links(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(154283, 11)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### SAMPLE DATA\n",
    "# df_news = df_news.sample(frac=0.01, random_state=42)\n",
    "df_news.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.4 ms, sys: 3.92 ms, total: 20.4 ms\n",
      "Wall time: 264 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# read in the entities data\n",
    "path = \"gs://nlp-final-project-data/result/\"\n",
    "AI_entities = pd.read_csv(path + \"AI_entities.csv\")\n",
    "ORG_entities = pd.read_csv(path + \"ORG_entities.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entities</th>\n",
       "      <th>Labels</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ChatGPT</td>\n",
       "      <td>ORG</td>\n",
       "      <td>136885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ML</td>\n",
       "      <td>ORG</td>\n",
       "      <td>24115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>ORG</td>\n",
       "      <td>17099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bard</td>\n",
       "      <td>ORG</td>\n",
       "      <td>14528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GPT3</td>\n",
       "      <td>ORG</td>\n",
       "      <td>8427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GPT</td>\n",
       "      <td>ORG</td>\n",
       "      <td>7565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AIgenerated</td>\n",
       "      <td>ORG</td>\n",
       "      <td>6998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Bing</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>8556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Vectorspace AI</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>1784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ernie Bot</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>1705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Bard</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>1483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Weve</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>1184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Laivly</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Hailo</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Bing</td>\n",
       "      <td>PRODUCT</td>\n",
       "      <td>6707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>HPC</td>\n",
       "      <td>PRODUCT</td>\n",
       "      <td>2586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Cresta</td>\n",
       "      <td>PRODUCT</td>\n",
       "      <td>1624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>A.I.</td>\n",
       "      <td>PRODUCT</td>\n",
       "      <td>1424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Akismet</td>\n",
       "      <td>PRODUCT</td>\n",
       "      <td>1412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>TensorFlow</td>\n",
       "      <td>PRODUCT</td>\n",
       "      <td>1398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Google Cloud</td>\n",
       "      <td>PRODUCT</td>\n",
       "      <td>1340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ADAS</td>\n",
       "      <td>PRODUCT</td>\n",
       "      <td>1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>A100</td>\n",
       "      <td>PRODUCT</td>\n",
       "      <td>1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>JavaScript</td>\n",
       "      <td>PRODUCT</td>\n",
       "      <td>1072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Cloud</td>\n",
       "      <td>PRODUCT</td>\n",
       "      <td>1051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>DGX</td>\n",
       "      <td>PRODUCT</td>\n",
       "      <td>872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>SageMaker</td>\n",
       "      <td>PRODUCT</td>\n",
       "      <td>809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Conversational AI</td>\n",
       "      <td>PRODUCT</td>\n",
       "      <td>575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Jina AI</td>\n",
       "      <td>PRODUCT</td>\n",
       "      <td>560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Lunit</td>\n",
       "      <td>PRODUCT</td>\n",
       "      <td>560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>SoundHound AI</td>\n",
       "      <td>PRODUCT</td>\n",
       "      <td>535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Entities   Labels   count\n",
       "0             ChatGPT      ORG  136885\n",
       "1                  ML      ORG   24115\n",
       "2    Machine Learning      ORG   17099\n",
       "3                Bard      ORG   14528\n",
       "4                GPT3      ORG    8427\n",
       "5                 GPT      ORG    7565\n",
       "6         AIgenerated      ORG    6998\n",
       "7                Bing   PERSON    8556\n",
       "8      Vectorspace AI   PERSON    1784\n",
       "9           Ernie Bot   PERSON    1705\n",
       "10               Bard   PERSON    1483\n",
       "11               Weve   PERSON    1184\n",
       "12             Laivly   PERSON     929\n",
       "13              Hailo   PERSON     926\n",
       "14               Bing  PRODUCT    6707\n",
       "15                HPC  PRODUCT    2586\n",
       "16             Cresta  PRODUCT    1624\n",
       "17               A.I.  PRODUCT    1424\n",
       "18            Akismet  PRODUCT    1412\n",
       "19         TensorFlow  PRODUCT    1398\n",
       "20       Google Cloud  PRODUCT    1340\n",
       "21               ADAS  PRODUCT    1250\n",
       "22               A100  PRODUCT    1250\n",
       "23         JavaScript  PRODUCT    1072\n",
       "24              Cloud  PRODUCT    1051\n",
       "25                DGX  PRODUCT     872\n",
       "26          SageMaker  PRODUCT     809\n",
       "27  Conversational AI  PRODUCT     575\n",
       "28            Jina AI  PRODUCT     560\n",
       "29              Lunit  PRODUCT     560\n",
       "30      SoundHound AI  PRODUCT     535"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AI_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entities</th>\n",
       "      <th>Labels</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Google</td>\n",
       "      <td>ORG</td>\n",
       "      <td>80971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Microsoft</td>\n",
       "      <td>ORG</td>\n",
       "      <td>67475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OpenAI</td>\n",
       "      <td>ORG</td>\n",
       "      <td>32015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IBM</td>\n",
       "      <td>ORG</td>\n",
       "      <td>25276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Facebook</td>\n",
       "      <td>ORG</td>\n",
       "      <td>19353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NVIDIA</td>\n",
       "      <td>ORG</td>\n",
       "      <td>19219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Amazon</td>\n",
       "      <td>ORG</td>\n",
       "      <td>17679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Googles</td>\n",
       "      <td>ORG</td>\n",
       "      <td>14072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Apple</td>\n",
       "      <td>ORG</td>\n",
       "      <td>12477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Twitter</td>\n",
       "      <td>ORG</td>\n",
       "      <td>11906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Intel</td>\n",
       "      <td>ORG</td>\n",
       "      <td>11882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Microsofts</td>\n",
       "      <td>ORG</td>\n",
       "      <td>10465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Nvidia</td>\n",
       "      <td>ORG</td>\n",
       "      <td>9569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Baidu</td>\n",
       "      <td>ORG</td>\n",
       "      <td>9365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Meta</td>\n",
       "      <td>ORG</td>\n",
       "      <td>9182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Tesla</td>\n",
       "      <td>ORG</td>\n",
       "      <td>9110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>EU</td>\n",
       "      <td>ORG</td>\n",
       "      <td>8656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Oracle</td>\n",
       "      <td>ORG</td>\n",
       "      <td>6050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Instagram</td>\n",
       "      <td>ORG</td>\n",
       "      <td>5636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Standigm</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>1348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Nvidias</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>1082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>JAIC</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Telixs</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>DeepMind</td>\n",
       "      <td>PRODUCT</td>\n",
       "      <td>904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>PlayStation</td>\n",
       "      <td>PRODUCT</td>\n",
       "      <td>898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Coinbase</td>\n",
       "      <td>PRODUCT</td>\n",
       "      <td>806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Aetina</td>\n",
       "      <td>PRODUCT</td>\n",
       "      <td>747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>C3 AI</td>\n",
       "      <td>PRODUCT</td>\n",
       "      <td>698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Teslas</td>\n",
       "      <td>PRODUCT</td>\n",
       "      <td>606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>DeepMinds</td>\n",
       "      <td>PRODUCT</td>\n",
       "      <td>568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>SAP</td>\n",
       "      <td>PRODUCT</td>\n",
       "      <td>509</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Entities   Labels  count\n",
       "0        Google      ORG  80971\n",
       "1     Microsoft      ORG  67475\n",
       "2        OpenAI      ORG  32015\n",
       "3           IBM      ORG  25276\n",
       "4      Facebook      ORG  19353\n",
       "5        NVIDIA      ORG  19219\n",
       "6        Amazon      ORG  17679\n",
       "7       Googles      ORG  14072\n",
       "8         Apple      ORG  12477\n",
       "9       Twitter      ORG  11906\n",
       "10        Intel      ORG  11882\n",
       "11   Microsofts      ORG  10465\n",
       "12       Nvidia      ORG   9569\n",
       "13        Baidu      ORG   9365\n",
       "14         Meta      ORG   9182\n",
       "15        Tesla      ORG   9110\n",
       "16           EU      ORG   8656\n",
       "17       Oracle      ORG   6050\n",
       "18    Instagram      ORG   5636\n",
       "19     Standigm   PERSON   1348\n",
       "20      Nvidias   PERSON   1082\n",
       "21         JAIC   PERSON    943\n",
       "22       Telixs   PERSON    924\n",
       "23     DeepMind  PRODUCT    904\n",
       "24  PlayStation  PRODUCT    898\n",
       "25     Coinbase  PRODUCT    806\n",
       "26       Aetina  PRODUCT    747\n",
       "27        C3 AI  PRODUCT    698\n",
       "28       Teslas  PRODUCT    606\n",
       "29    DeepMinds  PRODUCT    568\n",
       "30          SAP  PRODUCT    509"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ORG_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-lg==3.5.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.5.0/en_core_web_lg-3.5.0-py3-none-any.whl (587.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m587.7/587.7 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /opt/conda/lib/python3.10/site-packages (from en-core-web-lg==3.5.0) (3.5.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.0.7)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (6.3.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.10.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (21.3)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.0.12)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.0.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.0.8)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.0.4)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.4.6)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.1.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.23.5)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (0.10.1)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (0.7.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.3.0)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.1.1)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (59.8.0)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /opt/conda/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (8.1.9)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.28.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.0.9)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (4.64.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.0.9)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (4.5.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.4)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (0.0.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (0.7.9)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.10/site-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.1.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_lg')\n"
     ]
    }
   ],
   "source": [
    "import spacy.cli\n",
    "spacy.cli.download(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils import process_text_sen_sentiment\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to extract entities from news text with sentence segmentation and sentiment\n",
    "def extract_entities_sentiment(df):\n",
    "    with mp.Pool() as pool:\n",
    "        results = pool.imap_unordered(process_text_sen_sentiment, df['cleaned text'], chunksize=2000)\n",
    "        for i, ents in enumerate(results):\n",
    "            for ent in ents:\n",
    "                yield df.iloc[i]['id'], ent[0], ent[1], ent[2], ent[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 38min 27s, sys: 8.78 s, total: 38min 36s\n",
      "Wall time: 1h 30min 22s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Entities</th>\n",
       "      <th>Labels</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Adobe</td>\n",
       "      <td>ORG</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.659091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Firefly</td>\n",
       "      <td>ORG</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.659091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>AI</td>\n",
       "      <td>ORG</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.659091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Summit Adobe</td>\n",
       "      <td>ORG</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.659091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>AI</td>\n",
       "      <td>ORG</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.659091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12012051</th>\n",
       "      <td>200329</td>\n",
       "      <td>ChatGPT</td>\n",
       "      <td>ORG</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12012052</th>\n",
       "      <td>200329</td>\n",
       "      <td>AI</td>\n",
       "      <td>ORG</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12012053</th>\n",
       "      <td>200329</td>\n",
       "      <td>one</td>\n",
       "      <td>CARDINAL</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12012054</th>\n",
       "      <td>200329</td>\n",
       "      <td>AI</td>\n",
       "      <td>PRODUCT</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12012055</th>\n",
       "      <td>200329</td>\n",
       "      <td>Intel</td>\n",
       "      <td>ORG</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.437500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12012056 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id      Entities    Labels  Sentiment  Subjectivity\n",
       "0              1         Adobe       ORG   0.272727      0.659091\n",
       "1              1       Firefly       ORG   0.272727      0.659091\n",
       "2              1            AI       ORG   0.272727      0.659091\n",
       "3              1  Summit Adobe       ORG   0.272727      0.659091\n",
       "4              1            AI       ORG   0.272727      0.659091\n",
       "...          ...           ...       ...        ...           ...\n",
       "12012051  200329       ChatGPT       ORG  -0.200000      0.600000\n",
       "12012052  200329            AI       ORG  -0.200000      0.600000\n",
       "12012053  200329           one  CARDINAL   0.166667      0.833333\n",
       "12012054  200329            AI   PRODUCT   0.166667      0.833333\n",
       "12012055  200329         Intel       ORG   0.187500      0.437500\n",
       "\n",
       "[12012056 rows x 5 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "ner_sentiment_df = pd.DataFrame(extract_entities_sentiment(df_news), columns=['id', 'Entities', 'Labels', 'Sentiment', 'Subjectivity'])\n",
    "ner_sentiment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 23s, sys: 272 ms, total: 1min 23s\n",
      "Wall time: 1min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# save dataframe to csv\n",
    "path = \"gs://nlp-final-project-data/result/\"\n",
    "ner_sentiment_df.to_csv(path + 'ner_sentiment_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ORG Targeted Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AI Solutions Targeted Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
