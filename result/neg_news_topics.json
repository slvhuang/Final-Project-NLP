{"id":5,"cleaned text":"Cr Bard Inc Has Returned 48.9 Since SmarTrend Recommendation BCR  SmarTrend identified an Uptrend for Cr Bard Inc :BCR on December 23rd, 2016 at 222.45.  In approximately 40 months, Cr Bard Inc has returned 48.91 as of todays recent price of 331.24.In the past 52 weeks, Cr Bard Inc share prices have been bracketed by a low of 0.00 and a high of 0.00 and are now at 331.24, 100 above that low price.  In the last five trading sessions, the 50day moving average MA has remained constant while the 200day MA has remained constant.C. R. Bard, Inc. designs, manufactures, packages, distributes, and sells medical, surgical, diagnostic, and patient care devices. The Company sells a broad range of products worldwide to hospitals, individual healthcare professionals, extended care facilities and alternate site facilities. Bard markets vascular, urological, oncological, and surgical specialties products.SmarTrend will continue to scan these moving averages and a number of other proprietary indicators for any shifts in the trajectory of Cr Bard Inc shares.Log in and add Cr Bard Inc BCR to your watchlist today so you can receive a realtime alert when the shares are about to change trend. We offer realtime trend alerts, technical stock analysis and tracking to help you stay on top of the market. Portfolio monitoring, trading research and market news are all available from a personal dashboard. Aes Corp AES Approaches New Upside Target of 12.99Mastercard IncA MA Approaches New Upside Target of 260.31Watch for Shares of Bank Ny Mellon BK to Approach Resistance at 38.44Next Resistance Level for Tjx Cos Inc TJX is 47.85Apache Corp APA Crosses Pivot Point Resistance at 7.77 Comtex News Network, Inc. is not a registered investment advisor and does not provide investment advice. Copyright 2020 Stock Market Trends and Technical Analysis by Comtex News Network, Inc.","sentiment":2,"digital transaction":0.1264127642,"healthcare":0.5732913017,"news platform":0.7476947904,"data analytics":0.2875354588,"insurance":0.1009313986,"investment":0.2269290686,"global market":0.1780208796,"autonomous car":0.066380702,"customer experience":0.378633976,"data science":0.1721046865,"cryptocurrency":0.0405829586,"camera":0.4367702901,"robot":0.9324445724,"chatgpt":0.4372135997,"image":0.537201345,"voice":0.3908125162,"patient care":0.3967791796,"research":0.911051333}
{"id":12,"cleaned text":"Conversational AI Marketplace Enlargement Possibilities, Regional Traits and Call for, Most sensible Avid gamers, Alternatives with Forecasts 2025  International Conversational AI marketplace 2020 analysis document is a solitary instrument that provides an indepth scrutiny of various Conversational AI marketplace insights, alternatives, collateral approaches and more than a few techniques of creating robust determinations. The Conversational AI marketplace CAGR charge would possibly building up via important  over the forecast length 20202025. The Conversational AI marketplace document additionally specializes in divergent marketplace orientations and trends, a number of uncooked fabrics utilized in Conversational AI trade, amplitudes and constant trade within the framework of Conversational AI trade. After that, it highlights the proper state of affairs of the Conversational AI marketplace coupled with provide marketplace legal responsibility and protection duties. The Conversational AI marketplace document plays a thoroughgoing learn about of worldwide Conversational AI trade apprehending other marketplace proficiencies, derivations, and procedures. It conducts a significant learn about to research ancient knowledge of the Conversational AI marketplace to be able to expect long run marketplace actions. Corporates crucial data involving gross margin, importexport main points, the cost of the Conversational AI marketplace product, and earnings segmentation main points also are lined within the Conversational AI document. As the contest charge is prime, it is tough to problem the Conversational AI competition relating to the contraption, feature and accuracy. Examining the previous Conversational AI knowledge and predicting long run inclinations would possibly assist shoppers, Conversational AI advertising and marketing professionals, salespeople, undertaking managers and managers to achieve successful assets and actual Conversational AI marketplace figures within the shape tables, charts, and graphs. International Conversational AI marketplace analysis document will permit the manufacturers and contributing organizations to simply take hold of the ideas, execs, and cons of the Conversational AI marketplace. It additionally conducts skilled SWOT research of the main Conversational AI key gamers and distributors the use of number one and secondary knowledge resources. International Conversational AI trade analysis document is principally divided at the foundation of primary key producers, geographical zones, programs and forms of merchandise over a length from 2017 to 2022. The document abides a lot of distributors on nationwide in addition to world degree. Segmentation of Global Conversational AI Marketplace according to Key Avid gamers: This phase figures out the Conversational AI marketplace at the foundation of most sensible producers which incorporates: The main distinguished terrestrial areas lined via international Conversational AI trade comprises North The united states, AsiaPacific, Latin The united states, Europe, Center East and Africa. Other developmental techniques, proposals and the way they are able to be finished also are mentioned in International Conversational AI trade document. The document promotes key procedures and technological developments in Conversational AI marketplace. It additionally lists nations who might be dominating the Conversational AI marketplace until 2025. It additionally options previous and provide Conversational AI marketplace traits to determine if there are any trade alternatives and scope in upcoming technology. Main Conversational AI marketplace inclinations throughout other areas in the neighborhood or the world over also are said. Record of corporate profiles at the side of their touch data is indexed above within the Conversational AI marketplace analysis document. The start segment of the Conversational AI document begins with product creation, symbol, total marketplace survey, constant Conversational AI marketplace alternatives, possibility and marketplace motive force. The following two segment covers dominant Conversational AI marketplace gamers, with substantial marketplace percentage, gross sales, and benefit in earlier years. Additional sections represent Conversational AI marketplace forecast, via programs, geographical areas and kinds with earnings and gross sales of Conversational AI marketplace. Later segment of the Conversational AI marketplace document portrays varieties and alertness of Conversational AI at the side of marketplace earnings and percentage, enlargement charge. Moreover, it gifts Conversational AI research in step with the geographical areas with Conversational AI marketplace benefit and gross sales ratio. Additionally, it comes to an builtin learn about according to geographical areas, gross sales charge, Conversational AI marketplace percentage, and benefit. Against the tip, it explains detailed data on other Conversational AI sellers, investors, and vendors at the side of conclusions, ultimate Conversational AI effects, and an addendum. The content material of the International Conversational AI trade learn about topics, features a general of 15 chapters: Bankruptcy 1, to explain Conversational AI product scope, marketplace review, marketplace alternatives, marketplace motive force and marketplace dangers. Bankruptcy 2, to profile the highest producers of Conversational AI, with value, gross sales, earnings and world marketplace percentage of Conversational AI in 2018 and 2019. Bankruptcy 3, the Conversational AI aggressive scenario, gross sales, earnings and world marketplace percentage of most sensible producers are analyzed emphatically via panorama distinction. Bankruptcy 4, the Conversational AI breakdown knowledge are proven on the regional degree, to turn the gross sales, earnings and enlargement via areas, from 2015 to 2020. Bankruptcy 5, 6, 7, 8 and 9, to wreck the gross sales knowledge on the nation degree, with gross sales, earnings and marketplace percentage for key nations on the earth, from 2015 to 2020. Bankruptcy 10 and 11, to phase the gross sales via sort and alertness, with gross sales marketplace percentage and enlargement charge via sort, software, from 2015 to 2020. Bankruptcy 12, Conversational AI marketplace forecast, via areas, sort and alertness, with gross sales and earnings, from 2020 to 2025. Bankruptcy 13, 14 and 15, to explain Conversational AI gross sales channel, vendors, shoppers, analysis findings and conclusion, appendix and knowledge supply. Orbis Studies is a frontline supplier of illustrative marketplace trends and workable insights to a large spectrum of B2B entities in quest of varied aggressive intelligence to create disruptive ripples throughout industries. Incessant vigor for factchecking and perseverance to reach flawless research have guided our eventful historical past and crisp consumer luck stories. Orbis Studies is continuously motivated to supply superlative rundown on ongoing marketplace trends. To satisfy this, our voluminous knowledge archive is encumbered with authentic and legitimately sourced knowledge, topic to intense validation via our inhouse topic professionals. A grueling validation procedure is applied to doublecheck main points of in depth writer knowledge swimming pools, previous to together with their numerous analysis studies catering to more than one industries on our coherent platform. With an astute inclination for impeccable knowledge sourcing, rigorous high quality keep watch over measures are an element and parcel in Orbis Studies. International Good Air Conditioner Marketplace 2020 By way of Building Components, Review and Detailed Research via 2025 World Small Pitch LED Show Marketplace 2020  Best Areas, Aggressive and Comparative Research, Expansion  Forecast Through 2025 World Meals Grade Calcium Sulfate Marketplace Alternative Research and Trade Forecast 20202025 World Small Electrical Enclosure Marketplace 2020 Measurement, Call for, Varieties, Intake, Key Gamers, Manufacturing and Forecast 2025 Natural Drinks Marketplace Industry Forecast 2020  Entire Meals Marketplace Inc., Basic Turbines, Inc., Everest  BlogsFashion Retailing Market Share, Growth by Top Company, Geographical Region, Application, Driver, Trends  Forecast from 20202026Latest News 2020: Restaurant Reservations Software Market by CoronavirusCOVID19 Impact Analysis With Top Manufacturers Analysis  Top Players: OpenTable Connect, Yelp, Nowait, GuestServe, Hostme, etc.  InForGrowthGeneral Motors strives to surpass Tesla to become Americas top manufacturer of hybrid carsTogether with Geely Auto Company, Chinas Tech Giant Baidu will make electric carsA new twist of how to get an ISS Experience without rockets and spacecraftLatest xLAB Laboratory Improves the Development and testing Capability of AerospaceThe Start of a Modern Solar Energy MegatrendThe White House plan states that planetary security requires more than just NASAWisconsin City, as well as its school district, set targets for 100 use of renewable power by 2040New Yorks tides of transitionJapan is welcoming bids for offshore wind plants close to Chiba and AkitaDARPA satellites destroyed at the processing station prior to the launch of SpaceXU.S. Head of Strategic Command condemns detractors of GBSD: Minuteman 3 cant be stretched for lifeRenewable Energy Partnership between Egypt and Denmark is stronger than ever beforeDetails of the agreement between Foxconn Technology and Byton on the Electric Vehicle MarketSpaceX rocket landings ambitions keep getting more interesting with timeNASA will run a staticfire SLS trial in the midJanuaryVarious calls for public bids in Renewable in Latin AmericaThe Stock Market takes an unwanted shift for the Electric Vehicle SPACsAn Insight on the guidelines of The Renewable Energy Draft Law in Serbia ","sentiment":2,"digital transaction":0.3031751215,"healthcare":0.0089551695,"news platform":0.6449753642,"data analytics":0.231231153,"insurance":0.0286226384,"investment":0.7269405127,"global market":0.749578476,"autonomous car":0.0437929705,"customer experience":0.4654429555,"data science":0.2139413208,"cryptocurrency":0.0413430817,"camera":0.0960564017,"robot":0.095282115,"chatgpt":0.4135887027,"image":0.3837212026,"voice":0.1590510011,"patient care":0.0147498436,"research":0.383122921}
{"id":23,"cleaned text":"Walmart employees are out to show its antishoplifting AI doesnt work The retailer denies there is any widespread issue with the software. In January, my coworker received a peculiar email. The message, which she forwarded to me, was from a handful of corporate Walmart employees calling themselves the Concerned Home Office Associates. Walmarts headquarters in Bentonville, Arkansas, is often referred to as the Home Office. While its not unusual for journalists to receive anonymous tips, they dont usually come with their own slickly produced videos. The employees said they were past their breaking point with Everseen, a small artificial intelligence firm based in Cork, Ireland, whose technology Walmart began using in 2017. Walmart uses Everseen in thousands of stores to prevent shoplifting at registers and selfcheckout kiosks. But the workers claimed it misidentified innocuous behavior as theft and often failed to stop actual instances of stealing. They told WIRED they were dismayed that their employerone of the largest retailers in the worldwas relying on AI they believed was flawed. One worker said that the technology was sometimes even referred to internally as NeverSeen because of its frequent mistakes. WIRED granted the employees anonymity because they are not authorized to speak to the press. The workers said they had been upset about Walmarts use of Everseen for years and claimed colleagues had raised concerns about the technology to managers but were rebuked. They decided to speak to the press, they said, after a June 2019 Business Insider article reported Walmarts partnership with Everseen publicly for the first time. The story described how Everseen uses AI to analyze footage from surveillance cameras installed in the ceiling and can detect issues in real time, such as when a customer places an item in their bag without scanning it. When the system spots something, it automatically alerts store associates. Everseen overcomes human limitations. By using stateoftheart artificial intelligence, computer vision systems, and big data, we can detect abnormal activity and other threats, a promotional video referenced in the story explains. Our digital eye has perfect vision, and it never needs a day off. In an effort to refute the claims made in the Business Insider piece, the Concerned Home Office Associates created a video, which purports to show Everseens technology failing to flag items not being scanned in three different Walmart stores. Set to cheery elevator music, it begins with a person using selfcheckout to buy two jumbo packages of Reeses White Peanut Butter Cups. Because the packages are stacked on top of each other, only one is scanned, but both are successfully placed in the bagging area without issue. The same person then grabs two gallons of milk by their handles and moves them across the scanner with one hand. Only one is rung up, but both are put in the bagging area. They then put their own cell phone on top of the machine, and an alert pops up saying they need to wait for assistancea false positive. Everseen finally alerts But does so mistakenly. Oops again, a caption reads. The filmmaker repeats the same process at two more stores, where they fail to scan a heartshaped Valentines Day chocolate box with a puppy on the front and a Philips Sonicare electric toothbrush. At the end, a caption explains that Everseen failed to stop more than 100 of wouldbe theft. The video isnt definitive proof that Everseens technology doesnt work as well as advertised, but its existence speaks to the level of frustration felt by the group of anonymous Walmart employees, and the lengths they went to prove their objections had merit. In interviews, the workers, whose jobs include knowledge of Walmarts lossprevention programs, said their top concern with Everseen was false positives at selfcheckout. The employees believe that the tech frequently misinterprets innocent behavior as potential shoplifting, which frustrates customers and store associates, and leads to longer lines. Its like a noisy tech, a fake AI that just pretends to safeguard, said one worker. The coronavirus pandemic has given their concerns more urgency. One Concerned Home Office Associate said they worry false positives could be causing Walmart workers to break socialdistancing guidelines unnecessarily. When Everseen flags an issue, a store associate needs to intervene and determine whether shoplifting or another problem is taking place. In an internal communication from April obtained by WIRED, a corporate Walmart manager expressed strong concern that workers were being put at risk by the additional contact necessitated by false positives and asked whether the Everseen system should be turned off to protect customers and workers. Before COVID19, it wasnt ideal, it was a poor customer experience, the worker said. AI is now creating a public health risk. HuffPost reported last week that corporate Walmart employees were concerned about Everseens technology putting store associates at risk amid the pandemic. When COVID19 reached the United States, Americans rushed to stock up on food and household essentials at Walmart, and sales soared. Workers soon began falling sick at least 20 Walmart associates have now died after contracting the coronavirus, according to United for Respect, a nonprofit that advocates for retail workers and that is crowdsourcing COVID19 infection rates and working conditions at Walmart stores across the country. Last month, United for Respect said hundreds of Walmart employees participated in a national strike demanding safer working conditions and better benefits. A spokesperson for Walmart said the company has been working diligently to protect customers and its workforce and believes the rate at which associates have contracted COVID19 is lower than that of the general US population. They denied that false positives caused by Everseen were a widespread issue and said the company had not considered turning the system off due to concerns about COVID19. We assess our technology regularly, and as evident with the large scale implementation of Everseen across the chain, we have confidence it is currently meeting our standards, the spokesperson said in an email. Just prior to the start of the pandemic, Walmart said it made significant improvements to its Everseen system, which resulted in fewer alerts overall. The spokesperson declined to answer questions about what the updates may have entailed. The spokesperson also noted that there are a number of different reasons an associate might intervene during a selfcheckout transaction, like when a customer has problems with their credit card. The company said it has taken a number of steps to ensure people are protected during these interactions, including regularly cleaning selfcheckout kiosks and providing employees with protective equipment. In addition, workers are given handheld devices that allow them to handle most interventions from a distance, the company said. Everseen declined to answer questions about its technology. In a statement, a spokesperson said the company accurately and effectively identifies potential theft sic is why retailers have successfully deployed it at thousands of locations to date, with many more installations planned. They added that Everseen typically accounts only for less than 10 percent of total interventions at selfservice checkouts. In a separate statement, the spokesperson said Everseen is committed to helping its customers deliver the best possible experience for shoppers and store associates, especially during the COVID19 pandemic. Selfcheckout offers the benefits of a generally contactless shopping experience, allowing for proper social distancing and avoiding mannedlanes in busy stores with limited staff available. But the Concerned Home Office Associates said their worries about Everseen long predate the pandemic. Emails obtained by WIRED show that other corporate employees raised issues about the technology failing to prevent theft in both 2017 and 2018. The employees said they were particularly vexed by Walmarts continued investment in Everseen because NCR Corporation, which makes the majority of Walmarts registers, had acquired an Everseen competitor called StopLift. They considered the acquisition an endorsement and were confused as to why StopLifts technology wasnt being further explored. Whats more, the workers said an internal Walmart research and development group, the Intelligent Retail Lab IRL, created its own antitheft software they believed was more accurate than Everseens, according to information they were given internally. One Walmart employee said the technology, the existence of which was previously reported by The Wall Street Journal, is now being tested in roughly 50 stores. Walmart declined to answer questions about its internal antitheft software but did not dispute WIREDs reporting. At an enterprise level, there are a number of tests happening at any given time across our footprint of nearly 5,000 stores, a spokesperson said in a statement. The goal of IRL is to build AI capabilities that can be transferred to additional stores. We regularly test capabilities built internally in a small number of stores. Everseens technology was designed in part to help solve a persistent problem with selfcheckout. While allowing customers to scan and pay for their own items cuts down on labor costs for retailers, it has also led to more inventory loss, or shrinkage, due to shoplifting, employee theft, and other problems. Theft through selfcheckout lanes is exponentially higher than through traditional checkout lanes, says Christopher Andrews, a sociology professor at Drew University and the author of The Overworked Consumer: SelfCheckouts, Supermarkets, and the DoItYourself Economy. In the past, Walmart and other retailers relied on weight sensors to prevent shoplifting through selfcheckout, but those were prone to error and frustrated customers. Some stores are now turning instead to firms like Everseen, which promise to reduce shrink and increase customer satisfaction by relying instead on surveillance cameras and machine vision. Everseen has said that it works with a number of major retailers. Amazon uses similar technology in its Amazon Go convenience stores, where a network of cameras automatically log the products customers take. Amazon is now licensing its Just Walk Out tech to other companies. During the coronavirus pandemic and its aftermath, selfcheckout may become even more important for stores, as customers look for lowrisk ways to shop. NCR corporation said its now helping retailers modify its equipment to be as touchless as possible: for example, by reconfiguring machines so that customers can insert a debit or credit card without needing to press the credit card payment option. It is fascinating to see selfcheckout become poised as a public health strategy, in addition to things like cashless payment, says Alexandra Mateescu, a researcher at the nonprofit institute Data  Society, who has written about the effects of new technology on retail workers. Selfcheckout is just one of the ways that weve offered customers solutions to get the items they need safely during this time, in addition to other options like delivery, pickup, touchless payment at the register and shopping online, the Walmart spokesperson said in a statement. Customers are using this option now, as much as ever, and we will continue to work hard to ensure the instore experience for our customers is safe, affordable and convenient, as well as safe for our associates. Join the Ars Orbital Transmission mailing list to get weekly updates delivered to your inbox.    2020 Cond Nast. All rights reserved. Use of andor registration on any portion of this site constitutes acceptance of our User Agreement updated 1120 and Privacy Policy and Cookie Statement updated 1120 and Ars Technica Addendum effective 8212018. Ars may earn compensation on sales from links on this site. Read our affiliate link policy. Your California Privacy Rights  Do Not Sell My Personal Information   The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Cond Nast.","sentiment":2,"digital transaction":0.2549972534,"healthcare":0.0474307761,"news platform":0.8055870533,"data analytics":0.695646584,"insurance":0.0475757271,"investment":0.5200266242,"global market":0.957824409,"autonomous car":0.0187282022,"customer experience":0.8961380124,"data science":0.66952914,"cryptocurrency":0.0316972062,"camera":0.0379002728,"robot":0.1058128774,"chatgpt":0.628416121,"image":0.6711829305,"voice":0.2831395864,"patient care":0.124893792,"research":0.9306281209}
{"id":28,"cleaned text":"Tesla CEO Elon Musk urges pause on AI systems, citing risks to society Elon Musk and a group of artificial intelligence experts and industry executives are calling for a sixmonth pause in developing systems more powerful than OpenAIs newly launched GPT4, in an open letter citing potential risks to society and humanity. The letter, issued by the nonprofit Future of Life Institute and signed by more than 1,000 people including Musk, called for a pause on advanced AI development until shared safety protocols for such designs were developed, implemented and audited by independent experts. FILES In this file photo taken on February 10, 2022 Elon Musk speaks during a press conference at SpaceXs Starbase facility near Boca Chica Village in South Texas.  Musk has put the current value of Twitter at 20 billion, less than half the 44 billion he paid for the social media platform just five months ago, according to an internal email seen by American news media. Photo by JIM WATSON  AFP AFP Powerful AI systems should be developed only once we are confident that their effects will be positive and their risks will be manageable, the letter said. The letter detailed potential risks to society and civilization by humancompetitive AI systems in the form of economic and political disruptions, and called on developers to work with policymakers on governance and regulatory authorities. Cosignatories included Stability AI CEO Emad Mostaque, researchers at Alphabetowned DeepMind, as well as AI heavyweights Yoshua Bengio and Stuart Russell. 1950 cc  Diesel  Automatic Torque Converter  16.67 kmpl Not Applicable Cylinders Not Applicable  Not Applicable ValvesCylinder  Not Applicable cc  Electric  Automatic According to the European Unions transparency register, the Future of Life Institute is primarily funded by the Musk Foundation, as well as Londonbased effective altruism group Founders Pledge, and Silicon Valley Community Foundation. The concerns come as EU police force Europol on Monday joined a chorus of ethical and legal concerns over advanced AI like ChatGPT, warning about the potential misuse of the system in phishing attempts, disinformation and cybercrime. Meanwhile, the UK government unveiled proposals for an adaptable regulatory framework around AI. Also read: ChatGPT in cars General Motors exploring tie up with Microsoft The governments approach, outlined in a policy paper published on Wednesday, would split responsibility for governing artificial intelligence AI between its regulators for human rights, health and safety, and competition, rather than create a new body dedicated to the technology. Musk, whose carmaker Tesla is using AI for an autopilot system, has been vocal about his concerns about AI. Since its release last year, Microsoftbacked OpenAIs ChatGPT has prompted rivals to accelerate developing similar large language models, and companies to integrate generative AI models into their products. Sam Altman, chief executive at OpenAI, hasnt signed the letter, a spokesperson at Future of Life told Reuters. OpenAI didnt immediately respond to request for comment. The letter isnt perfect, but the spirit is right: we need to slow down until we better understand the ramifications, said Gary Marcus, a professor at New York University who signed the letter. They can cause serious harm... the big players are becoming increasingly secretive about what they are doing, which makes it hard for society to defend against whatever harms may materialize.","sentiment":1,"digital transaction":0.1706528664,"healthcare":0.7716792822,"news platform":0.3806661963,"data analytics":0.7575768828,"insurance":0.1014543548,"investment":0.2655257285,"global market":0.8012900949,"autonomous car":0.0925160795,"customer experience":0.3403925598,"data science":0.2511436641,"cryptocurrency":0.0354325213,"camera":0.0525889061,"robot":0.0503655896,"chatgpt":0.3579453528,"image":0.3068583608,"voice":0.2066179514,"patient care":0.1843970716,"research":0.952537775}
{"id":38,"cleaned text":"LegalTech Artificial Intelligence Industry  June 2021 Middle East and Africa Market Research Report 2020 Under COVID19 outbreak globally, this report provides 360 degrees of analysis from supply chain, import and export control to regional government policy and future influence on the industry. Detailed analysis about market status 20152020, enterprise competition pattern, advantages and disadvantages of enterprise products, industry development trends 20202025, regional industrial layout characteristics and macroeconomic policies, industrial policy has also been included. From raw materials to end users of this industry are analyzed scientifically, the trends of product circulation and sales channel will be presented as well. Considering COVID19, this report provides comprehensive and indepth analysis on how the epidemic push this industry transformation and reform. In COVID19 outbreak, Chapter 2.2 of this report provides an analysis of the impact of COVID19 on the global economy and the LegalTech Artificial Intelligence industry. Chapter 3.7 covers the analysis of the impact of COVID19 from the perspective of the industry chain. In addition, chapters 711 consider the impact of COVID19 on the regional economy. The LegalTech Artificial Intelligence market can be split based on product types, major applications, and important countries as follows: Key players in the global LegalTech Artificial Intelligence market covered in Chapter 12: In Chapter 4 and 14.1, on the basis of types, the LegalTech Artificial Intelligence market from 2015 to 2025 is primarily split into: In Chapter 5 and 14.2, on the basis of applications, the LegalTech Artificial Intelligence market from 2015 to 2025 covers: Geographically, the detailed analysis of consumption, revenue, market share and growth rate, historic and forecast 20152025 of the following regions are covered in Chapter 6, 7, 8, 9, 10, 11, 14: 2.1.2 Global LegalTech Artificial Intelligence Market Size by Type, 2015  2020 2.1.3 Global LegalTech Artificial Intelligence Market Size by Application, 2015  2020 2.1.4 Global LegalTech Artificial Intelligence Market Size by Region, 2015  2025 2.2.2 Influence of COVID19 Outbreak on LegalTech Artificial Intelligence Industry Development 3.6 The Impact of Covid19 From the Perspective of Industry Chain 3.7 Regional Import and Export Controls Will Exist for a Long Time 4.1 Global LegalTech Artificial Intelligence Value and Market Share by Type 20152020 4.2 Global LegalTech Artificial Intelligence Production and Market Share by Type 20152020 4.3 Global LegalTech Artificial Intelligence Value and Growth Rate by Type 20152020 4.3.1 Global LegalTech Artificial Intelligence Value and Growth Rate of Document Management System 4.3.2 Global LegalTech Artificial Intelligence Value and Growth Rate of EDiscovery 4.3.3 Global LegalTech Artificial Intelligence Value and Growth Rate of Practice and Case Management 4.3.4 Global LegalTech Artificial Intelligence Value and Growth Rate of EBilling 4.3.5 Global LegalTech Artificial Intelligence Value and Growth Rate of Contract Management 4.3.6 Global LegalTech Artificial Intelligence Value and Growth Rate of IPManagement 4.3.7 Global LegalTech Artificial Intelligence Value and Growth Rate of Legal Research 4.3.8 Global LegalTech Artificial Intelligence Value and Growth Rate of Legal Analytics 4.3.9 Global LegalTech Artificial Intelligence Value and Growth Rate of Cyber Security 4.3.10 Global LegalTech Artificial Intelligence Value and Growth Rate of Predictive Technology 4.3.11 Global LegalTech Artificial Intelligence Value and Growth Rate of Compliance 5.2 Global LegalTech Artificial Intelligence Consumption and Market Share by Application 20152020 5.3 Global LegalTech Artificial Intelligence Consumption and Growth Rate by Application 20152020 5.3.1 Global LegalTech Artificial Intelligence Consumption and Growth Rate of Lawyers 20152020 5.3.2 Global LegalTech Artificial Intelligence Consumption and Growth Rate of Clients 20152020 6.1 Global LegalTech Artificial Intelligence Sales, Revenue and Market Share by Regions 6.2 North America LegalTech Artificial Intelligence Sales and Growth Rate 20152020 6.5 Middle East and Africa LegalTech Artificial Intelligence Sales and Growth Rate 20152020 6.6 South America LegalTech Artificial Intelligence Sales and Growth Rate 20152020 7.2 North America LegalTech Artificial Intelligence Sales, Revenue and Market Share by Countries 7.3 United States LegalTech Artificial Intelligence Sales and Growth Rate 20152020 8.2 Europe LegalTech Artificial Intelligence Sales, Revenue and Market Share by Countries 9.2 Asia Pacific LegalTech Artificial Intelligence Sales, Revenue and Market Share by Countries 9.5 South Korea LegalTech Artificial Intelligence Sales and Growth Rate 20152020 9.7 Southeast Asia LegalTech Artificial Intelligence Sales and Growth Rate 20152020 10 Middle East and Africa LegalTech Artificial Intelligence Market Analysis by Countries 10.1 The Influence of COVID19 on Middle East and Africa Market 10.2 Middle East and Africa LegalTech Artificial Intelligence Sales, Revenue and Market Share by Countries 10.2.1 Middle East and Africa LegalTech Artificial Intelligence Sales by Countries 20152020 10.2.2 Middle East and Africa LegalTech Artificial Intelligence Revenue by Countries 20152020 10.3 Saudi Arabia LegalTech Artificial Intelligence Sales and Growth Rate 20152020 10.7 South Africa LegalTech Artificial Intelligence Sales and Growth Rate 20152020 11.1 The Influence of COVID19 on Middle East and Africa Market 11.2 South America LegalTech Artificial Intelligence Sales, Revenue and Market Share by Countries 12.2.3 Knomos Knowledge Management Inc. Production, Value, Price, Gross Margin 20152020 Pet Tech Industry June 2021 Middle East and Africa Market Research Report 2020 Spectacle Lenses For Myopia Control Market is booming Globally with Top key players ZEISS,HOYA Corporation,EssilorLuxottica,Brighten Optix,WeiXing Optical Automotive Contract Manufacturing IndustryJune 2021 Middle East and Africa Market Research Report 2026 Utilities Industry June 2021 Middle East and Africa Market Research Report 2026 Thermoformed and Custom Mouthguard Market Along with an Analysis of the Competitive Landscape 20212026 Outdoor Decorative Cushions, Pillows and Fabrics Industry June 2021 Global Market Research Report 2020 Outdoor Decorative Cushions, Pillows and Fabrics Industry June 2021 EUROPE Market Research Report 2020","sentiment":2,"digital transaction":0.3837158382,"healthcare":0.2031327486,"news platform":0.6050185561,"data analytics":0.5801837444,"insurance":0.1688592583,"investment":0.7718878984,"global market":0.9331469536,"autonomous car":0.2795613706,"customer experience":0.6216365695,"data science":0.3828315735,"cryptocurrency":0.1125352606,"camera":0.172959879,"robot":0.1772995144,"chatgpt":0.584303081,"image":0.4021613598,"voice":0.419515729,"patient care":0.2259274572,"research":0.9482728839}
{"id":57,"cleaned text":"  Jerry Seinfeld on AI Seinfeld: You Gotta Be Dumb to Do StandupJerry Seinfeld on AI Seinfeld: You Gotta Be Dumb to Do Standup Jerry Seinfeld Isnt Worried About AI Comedy Taking His Job: You Gotta Be Dumb to Do Proper Standup An AIgenerated extension ofSeinfeldwas captivating Twitch users earlier this month, another sign of machine learning being used experimentally in the entertainment space. However, the real Jerry Seinfeld isnt worried about AI taking over his job: He commented on the internet show during a recent standup gig, joking that while bots will continue to get smarter, you actually have to be pretty dumb to be a successful comedian. As fanshot footage of Seinfelds gig shows, the comedian asks the audience to fill him in on Nothing, Forever the Twitch show that generates infinite newSeinfeld scenarios. Do they make any sense he asks, before quickly answering himself: No, its AI crap. No, AI  Im not worried about AI Theyll make it smarter and smarter, but to do this standup, you have to make it dumber, the comedian continued. You gotta be dumb to do this. Based on classic Seinfeld episodes,Nothing, Foreverprovided fans with a computerized hit of nostalgia  until the AI Seinfeld made a transphobic joke during his standup routine. The web show mimics the sitcom by beginning with a Seinfeld standup set and then moving into the characters apartment, and in a recent clip, Larry Feinberg  the fake Jerry Seinfeld  makes a series of jokes at the expense of transgender and gay people. Im thinking about doing a bit about how being transgender is actually a mental illness, Feinberg says. Or how all liberals are secretly gay and want to impose their will on everyone. Or something about how transgender people are ruining the fabric of society. But no one is laughing, so Im going to stop. Thanks for coming out tonight. See you next time. Whered everybody go As a result, Twitch banned Nothing, Foreverfor 14 days as a penalty for violating the companys community guidelines. Where have we seen this before The notartificial Seinfelds standup tour continues through March, and tickets are on sale now.   @evilest_guy pretyy cool fyp seinfeld jerryseinfeld aiseinfeld GetCrackin  original sound  chris Subscribe to our email digest and get the latest breaking news in music, film, and television, tour updates, access to exclusive giveaways, and more straight to your inbox. Quavo and Offset Got into Physical Fight over Takeoff Tribute at 2023 Grammys: Report Dave Chappelle Claims Going to See His Comedy Shows Is Huge Act of Defiance Aubrey Plaza Books a New Role on SNLs White Lotus Spoof: Watch Sacha Baron Cohens Borat Roasts Trump, Kanye, and U2 at Kennedy Center Honors Alleged Sexual Predator Bill Cosby Is Planning a Standup Tour in 2023 Chris Rock Sets Release Date for FirstEver Live Netflix Special Selective Outrage Jerry Seinfeld Isnt Worried About AI Comedy Taking His Job: You Gotta Be Dumb to Do Proper Standup","sentiment":2,"digital transaction":0.4682250023,"healthcare":0.1973890215,"news platform":0.6353371739,"data analytics":0.8005230427,"insurance":0.2317518443,"investment":0.9747547507,"global market":0.9584550261,"autonomous car":0.3974703252,"customer experience":0.8064864874,"data science":0.617030859,"cryptocurrency":0.3335622251,"camera":0.2879482806,"robot":0.3403416574,"chatgpt":0.5586494207,"image":0.5122444034,"voice":0.7564237714,"patient care":0.3051214814,"research":0.9778625369}
{"id":58,"cleaned text":"Thoughts on AI Images: Art, Very Convincing Nonsense, and Visual Literacy The world of art, of which the world of photography is a minor, rather insignificant part, prefers to hype up the latest technological advancements. Thankfully, the craze over socalled NFTs died down pretty quickly after crypto, a form of fake money that combines libertarian thinking with oldfashioned Ponzi scheming, imploded. Just a short time later, advancements in what is called artificial intelligence AI resulted in the release of new tools that are able to produce text that reads like real text more on this later and pictures that look like well, not quite real pictures, but they seem to be getting there. So far, the talk in the art world about AI images reminds me of when artists started exploring Second Life. There was a lot of hype, a lot of rather halfbaked work. And then the fad disappeared pretty quickly. Im thinking that AI images might stay around a little longer, but I could easily be wrong. Its worthwhile to point out that part of the panic that erupted over the tools bears similarities to how the world of photography treated the advent of digital cameras. I do not mean to dismiss the criticism thats leveled at AI. But some of it seems misguided to me. Maybe I will start with the latter. There is considerable merit to discussing the problem that new tools lower costs for people buying the products and that they end up replacing human workers. Obviously, if youre a neoliberal capitalist, these arent problems but features. While I do have thoughts about all of that, its a politics problem, not a photography one. As long as we dont pressure law makers to mitigate the effects of a rampant capitalism, were not going to solve problems like this. Copyright  AI images use other peoples pictures  obviously is a huge problem as well. In the US, the people who can fix this problem sit in Washington, DC. Its useful to keep in mind, though, that in the world of photography, were not entirely blameless ourselves. If rates go down all the time, if theres a race to get everything cheaper and cheaper, then the fact that someone will be willing to work for that lower rate or even for free is not helping the overall cause. In much the same fashion, to pick a completely unrelated example, if the market for photobooks isnt growing because its mostly photographers buying other photographers books, then making more books for photographers also isnt really a solution to the problem. Like I said, these are basically questions of politics andor community, and we might want to treat them that way. Coming back to photography, over its relatively short history, new technologies were created at a rapid rate, leading to new tasks arising and then made unneeded at a relatively rapid rate. As far as I can tell, in photography discussions over new technologies have always involved the kinds of discussions were now seeing in the context of AI. But when it comes to AI I do think that there are a few things that are interesting to talk about, in particular because they have repercussions beyond photography. I should briefly preface the rest with what Ive seen in terms of AI images. Ive seen a lot of them, and so far I havent seen anything that has a lot of substance. I also tried an AI image tool for my own work and came to the conclusion that while occasionally, there are interesting images, AI falls way short in a larger, important sense: its not capable of producing something that is coherently speaking of its makers vision. For example, the visual narration in my book Vaterland completely evaporated when I replaced my pictures with AI ones. But I also thought that it would only be fair enough if I elaborated on my own thinking around AI images. So thats what I want to do in the following. After all, its not that theoretically, Im not interested in AI images. But for me, they have to cross a certain bar to become art. To begin with, creating images in a computer is not new. After all, there is computergenerated imagery CGI. This article explains why furniture maker IKEA uses CGI for their catalogues. When you use CGI, you will have to start from scratch or from what you have already set up. AI image tools offer something completely different, in that they assemble new images from a database of already existing ones. If you use CGI and you want a photograph of a chair, you will have to tell the computer exactly what the chair is supposed to look like, how its lit etc. With AI, you can tell it show me a photo of a chair and it will produce one: This is one of the images produced by Stable Diffusion when I prompted it with Show me a picture of a chair I used the free demo version. It looks like a chair, but its also wonky. Somehow, the geometry isnt quite right and neither are various constituent parts. The articles Ive read so far about AI photographs typically run along the lines of being amazed how realistic they look which is debatable, but such nuance is typically omitted and how advances in technology will make the pictures look even better which might or might not be true well see. Its interesting and disturbing to notice how similar a lot of these articles are to the generally uncritical and hypeprone articles you can find in the world of tech. Regardless, the picture of the chair was produced by assembling it from existing pictures. Conceptually, thats interesting, because for me, the first big thing I think about is the following which is probably based on my background as a theoretical physicist. Lets use an example. If you buy a bunch of Lego bricks, you can create all kinds of things  as long as you follow what the bricks will allow you to do. In other words, you will be restricted by the options presented by them. It is as if an artist, lets say Ai Weiwei, decided to make something from Lego bricks. Whatever hed decide to do, hes be limited by what the bricks allowed him to do. In fact, Ai Weiwei indeed just used Lego bricks to recreate if thats the word a painting by Claude Monet. By recreating this famous scene, we are being told, Ai Weiwei challenges our ideas of reality and beauty. does he, though I think a good way to look at Water Lilies 1 would be to view it either in the context of art in general which might yield too low a bar, but your mileage might vary or in the context of this artists own back catalogue. Taking the latter approach, does this piece of art strike you as being in the same league as his earlier work By the way, thats a Claude Monet painting made from Lego according to Dall.E 2. The point Im after has something to do with originality, but its not quite that. I personally find originality completely overrated. There are a few photographs that I admire and that were genuinely original when they were made. However, the bulk of the photographs I appreciate were completely unoriginal when they were first made, and that didnt matter one bit. For example, people have taken millions of pictures of landscapes before, and there still are very good landscape pictures being made. The same is true for family photography or any other genre of photography. But using the term originality is too misleading anyway, because mostly, great art is not necessarily appreciated for that or that alone. To get back to what Im thinking about: can AI create very good art out of the constituent parts of existing art in a way that moves beyond those parts Could AI create a Beethoven symphony out of the parts of Bach concertos You might think that, well, yes, Beethoven and Bach used the same types of scales and some of the same instruments. But thats not necessarily how you go from Bach to Beethoven, and its not how youd get to Schoenberg to throw in a more contemporary composer. If you think about this on a visual level, you could ask the same question in a different context. If you look at the history of photography, could you create later photography from pieces of earlier one This question can get very interesting when a first, basic answer would be: yes. Take collage. For example,Lszl MoholyNagys or Hannah Hchs collages are made from existing photographic material in the most literal sense. But could AI really do the same job Could an algorithm replicate the creative genius of a MoholyNagy or a Hch My current sense is that that is unlikely. But thats the only interesting question around AI photography for me. Everything else is merely craft. Theres nothing wrong with craft, but Im interested in art. You might argue that AI is merely being used by someone, so its not the AI that makes the pictures this is debatable, but lets buy into this, its the operator. However, the problem does not disappear. It shifts: assuming that the operator possesses enough creative genius, will they be able to make AI do things on their terms  instead of getting images based on the algorithms Its a bit like looking at Facebook pages. They all look the same because people can only fill prearranged templates. You can only work with the options provided to you. In principle, this is not a new problem for photographers: you always can only do what your tools allow you to. But with AI, you now have a new parameter: everything you can do has to be based on something that already exists older images. When evaluating AI photographs in an arthistorical or critical sense, you have to be careful, though. Lets use an imaginary example. It would be pretty straightforward to imagine AI being used to create the equivalent of Cindy Shermans Untitled Film Stills. If that body of work didnt exist and if Cindy Sherman decided she wanted to create such a body of work today, shed have to feed her own portrait into the AI system, to then produce those film stills. However, the question is whether this would be interesting. After all, the original Untitled Film Stills existed in a specific context, the socalled Pictures Generation. They thus acquired their initial meaning in an artistic climate in which artists looked into the role and value of pictures and into how existing pictures shape our world and expectations. If you imagine an AI generation of film stills in that context admittedly an absurd idea, given that back then AI didnt exist, then its easy to see how Shermans AI Untitled Film Stills would have done the same job as the actual ones. However, if you imagine Cindy Sherman producing the pictures today, far removed from the Pictures Generation and with us being now in the world of fake news etc., the idea would probably fall pretty flat. The conversation about photographs has moved far from the concerns of the Picture Generation. If you look at the untitled film still I had Stable Diffusion produce, you can see how the AI cant get hands right. Thats a problem, albeit not in the arthistorical or critical sense Im interested in here. In fact, you could argue that the weird hand is the only interesting element of the picture. However, its hard to see how this AI shortcoming translates into a form of artistic merit, especially if we demand that such merit has to be at least somewhat related to a makers intent. Consequently, in an artistic context, AI photographs need to at least aspire to have artistic merit. By that I mean that their makers have to attempt to contribute to the current artistic discourse. So far, I dont see that happening nope. Trying to make funny pictures or trying to prove that you can get realistic looking pictures with AI  thats too low a bar. There is a second, very interesting and very important aspect to AI photography. In a loose sense, it centers around the intersection of veracity and believability. Something might not have to be truthful to still be believable. For example, little children believe in Santa Claus. This is the general area where the generation of material, whether visual or textual, ultimately can  and very likely will  become political. A little while ago, I tested ChatGPT to see whether I could make it write nonsense. To be more precise, I wondered whether the AI would correct factual mistakes I included in my questions. It did not. In all fairness to ChatGPT, I just got access to Googles Bard, and it happily served me nonsense in the same fashion. Instead, both produced what I called Very Convincing Nonsense. Very convincing nonsense is a piece of information that looks or reads as truthful and that is convincing in form, but that is actually not accurate. This type of nonsense is great for comedy. But its not funny otherwise, especially not if it ends up being used by Vladimir Putins troll farms or any of its Western equivalents which are largely driven to undermine our democracies. Here, you have an actual example that was disseminated by the person it is supposed to depict, Donald Trump I found this on the same day that I started writing this article. If you look carefully at the image, you can see at least two of the standard problems of current AI image generators. The hands arent right. Furthermore, kneeling with your right knee behind your left heel is very, very difficult. I literally tried this. In general, I have very good balance. But I found it almost impossible to balance the way shown in the image. Essentially, you have to be able to recognize the nonsense if it is embedded in something that looks or reads as convincing. If youre unable to detect it, then well, youll just take what you see at face value. In fact, while I was working on this piece, an AI picture of the pope in some stylish white winter coat fooled a lot of people. When I saw it, I didnt believe for a second that it was real. Apparently, a lot of people did. On the other hand, most of the people for whom the Trump image was made probably dont believe any more in what it shows than citizens of the Soviet Unions believed socialistrealist art. Its hard to imagine that any of those hardright Christians believe that Trump is religious. But in the image theres a code that is transmitted. And that code matters, because the image serves to deliver it  instead of what it depicts in a literal fashion. Here is a recent example of an Instagram post by a member of Germanys neofascist AfD party it would seem that after some discussion of the imagery, the guy pulled the image. Norbert Kleinwaechter whose last name ironically translates into Little Guard in English is vice chairman of the partys faction in Germanys Bundestag the federal parliament. The text reads No to even more refugees. Theres nothing subtle about the image, but obviously thats par for the course for a party that has a history of producing racism. Note that the fictional person at the leftmost edge of the frame has five fingers. If youre not part of the target group, its important to be able to read the codes. They might be blatant as in the case of the AfD image, but they can also be more subtle. The visual code often connects to an invisible code that delivers the actual message. Just like in the case of the extremely well balanced Trump, photographic veracity isnt the actual point. In my book Photographys Neoliberal Realism, I talk about codes in a different context. Its easy to make fun of images like Trumps or the photographs discussed in my book. But if your response ends there, youre not performing the crucial and more important second step: understanding the codes that are being exchanged. Youre shortcircuiting your critical facilities. A good and very instructive example of detecting very convincing nonsense in AI image was recently discussed by Hiroko Yoda. Someone had AI generate a picture of a Japanese woman in a kimono if you look at Yodas Twitter thread, youll see that the original post she referred to has now been deleted. Im certified as a kimono consultant in Japan, Yoda writes, and this triggered me in all sorts of ways. To begin with, Yoda notes, there are some obvious craft issues. The AI showed a kimono that for a number of reasons couldnt really be made, whether in terms of the materials or in the way it was folded. But there also is a very important cultural issue tied to it: the biggest issue is super critical. Look closely at her white undergarment visible at collar. Its folded right over left  used only for the dead. This is super creepy. So you have a whitefaced woman wrapped in fabric scrap with odd hair accessories  funeral undergarments if I ran into her in Kyotos Gion at night I would probably freak out Ill be honest and admit that I would have not been able to notice any of the problems because Im not familiar with the details of kimonos. I can see how the chair I had AI create doesnt make sense, though. But I think you can easily see how what Yoda describes is very important: nobody in their right mind would wear a kimono this way in Japan. Obviously, the AI has no idea there is a problem because otherwise, we must assume, it would not have created the image this way. What were left with is a visual example of very convincing nonsense: an image that does not make sense. But you would only know if, in this case, you were a kimono consultant or, at the very least, someone who knows as much about the garment. And that is exactly the larger problem with AI images that were about to run into more and more. The problem is not only that images get produced to show something that didnt happen or doesnt exist even though thats bad enough. The larger problem, at least in my view, is produced by images that convey nonsensical information even if they were supposed to be truthful and accurate, images that are so convincing that we take them at face value. I suppose you could view this problem as the equivalent of glitch artifacts. But in AI images, apart from wonky hands or other optical problems the more dangerous glitch artifacts are only visible if you have enough background knowledge to detect them. One of the solutions we have for this problem is a vastly increased awareness of the importance of visual literacy. Specifically, by visual literacy I mean knowledge of the way of looking into how images convey their meaning. We will have to become a lot more aware of how we consume images. This would involve teaching visual literacy in schools and universities outside of art departments or classes. We will probably also get used to the fact that we often have to research images online. If we see an image we might have to look around and see where else it shows up, to infer something about its truth value. My guess is that verification tools will become available. Its easy to imagine an arms race between AI imagecreation and verification tools. Whatever the outcome, now is the time to start becoming more critical of AI tools. Now is the time to start thinking about how to deal with them. AI image click bait is fun  but its just possible that at least some of the time is better spent on learning more about how to critically look at images. Theres something fascinating about how similar Japan and Germany are. In the late 19th century, both countries emerged out of a suspended state to try to catch up with the countries they perceived as their peers. This process involved trying to reconcile modernity with their I cant say that Im an expert in the area that Timothy Snyder described in his book Bloodlands. What I know I know from the book. If you look through the Wikipedia page, towards the bottom, the reception of the book is discussed. Some of","sentiment":2,"digital transaction":0.6826229095,"healthcare":0.0898456648,"news platform":0.9841225743,"data analytics":0.8065150976,"insurance":0.3756798506,"investment":0.998760581,"global market":0.8684888482,"autonomous car":0.0662221983,"customer experience":0.9483695626,"data science":0.7904706597,"cryptocurrency":0.1607977301,"camera":0.7921043634,"robot":0.5416550636,"chatgpt":0.538687408,"image":0.9156849384,"voice":0.986512363,"patient care":0.0585746206,"research":0.9978473783}
{"id":60,"cleaned text":"Gap in AI chips between China and US may be larger than it seems Discussion in World Affairs started by F22Raptor, May 11, 2020 at 7:54 PM. Is China pulling ahead of the US in AI Not quite, argues Dieter Ernst of CIGI in a recent report entitled Competing in artificial intelligence chips: Chinas challenge amid technology war. His deep dive into the dynamics behind Chinas recent progress on AI chips manufacturing merits closer attention.  In addition to the hard engineering, Ernst reveals a social story of a global AI community on the verge of fracture. These new restrictions will likely bring the best out of some Chinese firms, while putting others out to pasture. All the while, basic research is likely to suffer worldwide as ties that bound the Chinese and western academic communities fray.  Most western coverage of western AI firms focuses on those that operate in the application layer of the AI stack. But in order for Bytedance to instantly recommend tailored TikTok videos, or for JD to optimize delivery orders, they need to run their applications on hardware. What AI chips do is optimize performance for specific tasks further down the AI stack. For instance, an AI chip can be tailored specifically for facial recognition, autonomous driving, or cloud computing. The best of these chips represent the bleeding edge of global semiconductor technology, and have grabbed the attention of Washington and Beijing. The Trump administration sees Chinese semiconductor progress as a grave economic and national security threat, and hopes to use a combination of sanctions and incentives to slow down Chinas work on AI chips. Beijing officials hope to create a selfsufficient industry capable of withstanding American sanctions and ultimately competing on the world stage. Basic research lies at the heart of AI development. American researchers invented the field, and have been at its forefront ever since. Ernst contends that Americas informal, flexible, and undogmatic approach to innovation is, arguably, the root cause for the resilience of the United States AI development trajectory. He argues that technology diffusion through knowledge networks, combined with intense contests among competing ideas throughout academia, DARPA projects, and the private sector have made the American AI and semiconductor ecosystem the worlds most vibrant. In contrast, China has struggled to marry basic research with industry. Chinas electrical engineering community was practically wiped out by the Cultural Revolution, forcing researchers in the 80s to start decades behind global best practice. It has to contend with dramatic disconnects between academia and industry as well as, Ernst writes, the institutional heritage of the Soviet planning system, which assumed enterprises purpose was to meet production targets and not conduct research themselves that work was reserved for national academies and institutes.  Until recently, the commercial and academic Chinese AI communities rarely interacted. While two of Ernsts contacts in Chinese consumeroriented AI companies noted that they had some researchers from public organizations take on moonlight consulting work, these sorts of arrangements pale in comparison to the publicprivate ecosystem America has created. Many western analysts have pointed to Chinas share of global AI publications as evidence of increasingly successful basic research efforts. The global AI research community is notable for its openness, with academics commonly posting their research in open platforms like Github and arXiv online. If you dont share your work, its meaningless, said Yunji Chen, a researcher at the Institute of Computing Technology in Beijing, in a 2019 interview with Nature.  The global AI community is, by and large, not happy about politics intruding. A Huawei researcher who due to a US State Department travel ban was forced to deliver his presentation remotely received a rousing round of applause at a normally staid conference. But politics is likely already reshaping the academic community. As Western universities reject Huaweis money and face increasing scrutiny for connections with the Chinese governments Thousand Talents plan, western researchers are forced to reconsider their Chinese connections. Coauthorships develop out of connections made through global conferences and academic fellowships, which are less and less likely to be accessible to Chinese nationals.  Id be interested to see research that asks whether the global community is splitting into Chinese and western halvesperhaps measured by how often researchers on each side of the divide coauthor with the other This disconnect is likely to harm upstart Chinese researchers more than established western ones. This comes at a time when basic research is only growing more important in the field. As AI chips are called upon to process massive datasets, companies around the world need to innovate with new architectures. This paradigm shift as the focus of semiconductor innovation shifts from process technology and fabrication to architecture and design at the front end, and postfabrication packaging at the back end leaves an opening for a Chinese upstart to contend with American giants like Intel, AMD, and NVIDIA. But despite the PR bluster, Chinese firms are all to various degrees behind the cutting edge and vulnerable to American actions. Chinese AI chip startups mostly focus on inference, as opposed to training algorithms, a much less technically demanding task. The fact that American capital markets are seemingly closed off to Chinese AI firms is another significant hurdle. For the time being, going public on Chinese stock markets requires three years of profitability, a rule that discourages investment in RD. Industry experts agree that China only really has one player capable of competing with American giants on an even footing in any AI chip vertical: Huaweis HiSilicon. And even HiSilicon is severely vulnerable to US sanctions. Since its most advanced chips are manufactured in Taiwan at TSMCs 7nm foundries, American pressure could force Huawei to cut ties with one of its most important AI chip partners. As this weeks recent Department of Commerce regulation release attests, it looks like the US is preparing to drop this hammer. Given that Huawei has been preparing for years for the US government to come after it, the fact that they still have foreign parts in their flagship phones means that this is much easier said than done. American firms also stand to lose outfrom increasing restrictions on their ability to sell to Chinese companies. A staggering 67 of Qualcomms revenue comes from China, for Micron this is 57, and for Broadcom 49. With nearly one fifth of US semiconductor firms revenue reinvested into RD, any big hit to their top line, if not paired with substantial US industrial policy to make up for this gap, will have long term consequences for Chinese companies have made some real progress, particularly in areas where China has a natural comparative advantage. For instance, China currently leads the world in a handful of narrowly defined AI chips related to surveillance. Further, some argue that China has an edge in access to cheap, structured data sources thanks to a large pool of affordable collegeeducated labor. However, datalabeling is eminently outsourceable, and nowadays Chinese labor really isnt cheaper than comparably educated Indians or Filipinos. After all, average hourly rates on Mechanical Turk are just 2. However, American sanctions are forcing Chinese players out of their comfort zone in ways that will help the ecosystem over the long term. As anonymous blogger Youshu writes, Some will no doubt say that Yeah, we knew China wanted to develop its own semi industry, so whats the rumpus This observation misses the mark. Before private firms were happy with the Americans, and state firms would just tell their bosses there were no good alternatives. But now orders are being pushed towards domestic rivals, even where they are not very good, providing them with revenues today, and confidence about future revenues, with which to fund RD. Ernst is more pessimistic. He expects islands of technological excellence to continue to coexist with deeply entrenched structural weaknesses in Chinas emerging AI chip industry. The Chinese AI industry will doubtless continue developing, but is unlikely to challenge America for global preeminence any time soon. That is what I want to say about the problem in China. Unless China realized its mistake and willingly reform, it wont surpass USA. They are just realizing someone else idea because they are hardworking. Im still waiting for a new imagination and idea that came from China up to today. If USA and China can work together, rather than this stupid conflict, the 21st century will be another golden age for humanity. There will be a huge jump in technology progress and worldwide living standard improvement. Is China pulling ahead of the US in AI Not quite, argues Dieter Ernst of CIGI in a recent report entitled Competing in artificial intelligence chips: Chinas challenge amid technology war. His deep dive into the dynamics behind Chinas recent progress on AI chips manufacturing merits closer attention. In addition to the hard engineering, Ernst reveals a social story of a global AI community on the verge of fracture. These new restrictions will likely bring the best out of some Chinese firms, while putting others out to pasture. All the while, basic research is likely to suffer worldwide as ties that bound the Chinese and western academic communities fray. In contrast, China has struggled to marry basic research with industry. Chinas electrical engineering community was practically wiped out by the Cultural Revolution, forcing researchers in the 80s to start decades behind global best practice. It has to contend with dramatic disconnects between academia and industry as well as, Ernst writes, the institutional heritage of the Soviet planning system, which assumed enterprises purpose was to meet production targets and not conduct research themselves that work was reserved for national academies and institutes. Many western analysts have pointed to Chinas share of global AI publications as evidence of increasingly successful basic research efforts. The global AI research community is notable for its openness, with academics commonly posting their research in open platforms like Github and arXiv online. If you dont share your work, its meaningless, said Yunji Chen, a researcher at the Institute of Computing Technology in Beijing, in a 2019 interview with Nature. But politics is likely already reshaping the academic community. As Western universities reject Huaweis money and face increasing scrutiny for connections with the Chinese governments Thousand Talents plan, western researchers are forced to reconsider their Chinese connections. Coauthorships develop out of connections made through global conferences and academic fellowships, which are less and less likely to be accessible to Chinese nationals. Just empty talks and nothing concrete, US thought it was unbeatable a decade ago and now was beaten in almost every front. China has outpaced the United States in the number of worldwide artificial intelligencerelated patent applications, according to a new report issued by the China Industrial Control Systems Cyber Emergency Response team, a research unit under the Ministry of Industry and Information Technology. China leapfrogs the US to become worlds most prolific patent filer The US has been the leader since the figures were first compiled in 1978, but has been challenged by Chinas growing power China has become the world leader in patent applications, beating the United States to the top spot for the first time in 40 years. Telecoms firm Huawei topped the company list for the third year in a row, filing 4,411 patent applications. Experts warn weapons gap is shrinking between US, Russia and China Top Republican senator predicts China is about to have a larger economy and military than the US Chip Maker NVIDIA is Bringing Its AI Driving Chip to China Currently Active Users Viewing This Thread: 5 Users: 1, Guests: 3 Defence.pk is a one stop resource for Pakistan defence, strategic affairs, security issues, world defence and military affairs.Contact us: contact@defence.pk","sentiment":2,"digital transaction":0.3236481249,"healthcare":0.4200382829,"news platform":0.8726079464,"data analytics":0.4124147892,"insurance":0.0906763449,"investment":0.9525052905,"global market":0.6577573419,"autonomous car":0.2304954231,"customer experience":0.4473882914,"data science":0.4886469245,"cryptocurrency":0.0679903701,"camera":0.1482790411,"robot":0.2361974269,"chatgpt":0.7658911943,"image":0.6485740542,"voice":0.7813143134,"patient care":0.0379880928,"research":0.8837437034}
{"id":73,"cleaned text":"EU falling behind in global AI race, MEPs warn AI is expected to contribute more than 11bn to the global economy by 2030 Photo: Amber Case The European Union is lagging behind the United States and China in the global race for Artificial Intelligence AI, MEPs said on Tuesday 3 May, warning that such a situation creates geopolitical risks given the strategic importance of these new technological systems. The EU is still far from fulfilling its aspirations of becoming competitive in AI on a global level, EU lawmakers said in a report that urges EU member states to increase investment in research, infrastructure, education, and training in the field of AI. Get instant access to all articles  and 20 years of archives. Watch our founder Lisbeth Kirk explain the reasons in this 30second video. The text speaks against certain mass surveillance technologies used by nondemocratic countries  with MEPs raising concerns over military research and technological developments into lethal autonomous weapon systems. Romanian liberal MEP Drago Tudorache, who chairs the committee on AI, said the EU has a geopolitical interest to develop humancentric approaches and become a global standardsetter in AI. We are not on this alone. We are on the global stage competing with other actors who also have a different worldview as to the future role of AI in their societies, he told a press conference. Similarly, Lead MEP German conservative Axel Voss said that the EU currently has a unique chance to develop a legal framework that leaves space for innovation and creates clear standards. While the EU has a strong position in industrial software and robotics, the bloc has been struggling to train and attract professionals and graduates in the field of AI. Brexit, MEPs said, had a negative impact on the EUs leadership in this field since the UK was one of the leading European countries in AI. But the 27nation bloc has been underinvesting in AI during the last few years in comparison to the global leaders in this field. And, overall, 42 percent of the EU population lacks digital skills and just onequarter of people have access to 5G. In their report, MEPs say EU member states should commit to investing at least three percent of its GDP in research and innovation to achieve the unions socalled strategic autonomy in the digital field. The estimated annual investment of the EU in AI is 1bn, compared to 5.1bn invested annually by the US and 6.8bn by China.  The USs leading position in venture and private equity investment has made the other side of the Atlantic more attractive to European entrepreneurs to scale up their businesses, MEPs say. Additionally, inconsistencies in EU law, the overlap of different legislative initiatives and different legal interpretations of the rules can also create legal uncertainty for companies and further slow down developments of AI products and services in Europe, they added. AI is expected to contribute more than 11bn to the global economy by 2030. , your membership gives you access to all of our stories. We highly appreciate your support and value your feedback. If you have any thoughts on this story, we would love to hear it. The EU commissions white paper on AI regulation tries to balance rights of individuals with needs of industry amid global boom. The fastgrowing impact of artificial intelligence will be the biggest challenge for business and consumers in Europes single market of tomorrow. The EU commission had announced guidelines on the ethics of artificial intelligence in a strategy paper, as the bloc looks to promote its values or risk being overshadowed by China and the US. And it wants them ready by 2018. The European Commission says people should file their complaints with national authorities in countries whose governments are suspected of using an Israelimade Pegasus spyware against them. EU states have exported 24.7 million doses of vaccines to 31 countries  almost half the number compared to that they delivered to member states, leaked figures show. The EU and UK have reignited a row on vaccine exports, while Italy has defied EU warnings in a new deal to manufacture Russias vaccine at home. The European Union adopted new rules, known as the Digital Markets Act, that promises to stop Big Tech from abusing its market powers. MEPs call on EU to invest in Pyrenees Midcat gas pipeline UiPathNo digital future for the EU without Intelligent Automation Online briefing Link EFBWW  EFBH  FETBBWorkers want EC to limit subcontracting chains in construction PGEHow to change EU ETS so that it supports the energy transition Nordic Council of MinistersNordic baby boom bucks pandemic trend in rest of Europe ","sentiment":2,"digital transaction":0.1443686783,"healthcare":0.0136109507,"news platform":0.3386194408,"data analytics":0.2974966168,"insurance":0.0102985231,"investment":0.1201179475,"global market":0.1354637295,"autonomous car":0.0200200174,"customer experience":0.3422628641,"data science":0.485653162,"cryptocurrency":0.7145809531,"camera":0.0103295315,"robot":0.021946596,"chatgpt":0.6050560474,"image":0.0709018633,"voice":0.0589142144,"patient care":0.015902441,"research":0.9257254004}
{"id":77,"cleaned text":"Googles Peacetime CEO Sundar Pichai faces criticism as AI war heats up  ExBulletin Googles Peacetime CEO Sundar Pichai faces criticism as AI war heats up As Google tries to catch up with OpenAI and Microsoft, CEO Sundar Pichai finds himself in a predicament fumbling for the companys lead in AI. Some question his leadership. Cofounders Larry Page and Sergey Brin thought about Googles age when they announced in 2019 that they were stepping down from daytoday roles at Googles parent company, Alphabet, to hand over the keys to the kingdom to Sundar Pichai. . If the company is people, its 21yearold young adults and its time to leave the roost, they wrote. Believe me, dont be nagging every day Four years later, absentee parents are back home as Google faces an invasion from an AI rival intent on usurping the companys iconic search business. Once dormant rival Microsoft is back with a new version of Bing, backed by OpenAI, the upstart maker of generative AI bot ChatGPT. When chatbots started to make headlines, Paige and Brin, who became advisors to the company after leaving official positions, began to take a more active role. They attended an AI strategy conference. Brin put the code into action. The reemergence of the founder and the fumbling of Googles consumer AI efforts has shaken some peoples trust in the person in charge. The mildmannered Pichai, who once graced the cover of Bloombergs Business Week, has turned his stuffed Android into Googles soft power. Competitors, investors, and industry observers are wondering whether Pichai is the CEO who can weather a company that appears to be developing into an existential crisis. For Googles army of engineers and researchers, AI has been a losing game for Google. Its still early days, but Google now finds itself in the unlikely position of lagging behind in a field that helped pioneers in losses that management blamed. Sundar is a very strong operator, but not a strategic thinker or visionary, said Nimrit Kang, cochief investment officer at Northstar Asset Management, which owns about 20 million in Alphabet shares. told Forbes. Kang said the company needs to disrupt itself to prepare for the longterm future, even if it means shortterm pain. He has a feeling that Thunder isnt that person, at least from everything were seeing. We have a feeling that Sunder isnt that person, at least from everything weve seen. Googles board, including the founders, should ask if Pichai is the right person to run the company or if its time for Sundar to leave. Veteran Silicon Valley author Om Malik wrote it last month.Does your company need a more aggressive CEO Unsatisfied the Maintain the status quo, and are you willing to crack some eggs After Maliks post, his respected tech analyst Ben Thompson also gave credence to this question and broached it on his widely read blog Stratechery. Google employee anonymously posted on platform Blind, will Sundar Pichai be expelled Wedbush Securities Managing Director Dan Ives believes that Sundar and his team have become complacent. He said its too early to think about executive replacement in the AI race, but the approach needs to change. They will need an army with leadership to target this market. Because this is a game of high stakes poker and so far they have lost. Google declined to comment or participate in an interview with Pichai. Pichai has survived this kind of criticism before. According to his CEO profile in The New York Times in 2021, Google executives have long complained about Pichais apparent risk aversion and slow decisionmaking. But while Googlers have whispered annoyances in the past, the chatter has grown louder in recent weeks. The stakes are coming to a head as rivals target Googles gleaming search business, one of his most efficient moneymaking machines in modern business. The question also arises as Google faces demoralization from mass layoffs. Pichai said in January he laid off 12,000 employees, or 6 of his company. Still, Pichai is highly respected around Google, and anyone who questions his leadership is quick to start criticizing him with remarks about how intelligent and impressive he is. Many of critics point to the peacetime vs. wartime CEO dichotomy coined by venture capitalist Ben Horowitz in 2011. A CEO during a war is like a general fending off an impending existential threat. Hes the epitome of a peacetime CEO, the epitome and the pinnacle, a former Google executive told Forbes. A former Google executive put it even more bluntly. I think everyone would agree that he is gone. The question is how long from now Pichais defense appreciates his coolheaded approach, especially with something as powerful as AI. With a trilliondollar market cap and billions of users, Google has always been in the precarious position of any startup with little to lose and little to anger. With its research and development, decades of user data, and track record of scaling its products, it is well positioned to win the AI war. Who says hes not a good wartime CEO, says one of his current Google employees. He hasnt gone to war yet. Caution can turn out to be prudent. As journalists and early testers tried to push the softwares boundaries, Google sidestepped some of the backlash directed at Microsofts Bing after the chatbot began returning violent and relentless answers. , Google has slowed down, but it still burns. Last month, chatbot Bard gave the wrong answer in a promotional video of him, further fueling concerns that Google was lagging behind, and the company saw his 100 billion in market value. lost. Pichais rise was a comforting Silicon Valley story. Born in Chennai, India, he attended the Indian Institute of Technology Kharagpur. He moved to the United States in 1993 and received masters degrees from Stanford University and Wharton University. After graduating, he worked as a consultant for McKinsey before on April 1, 2004, he was interviewed at Google. This is the same day Google launched his Gmail. At Google, he was quickly promoted. He first served as his manager of products responsible for the browsers search bar before pushing Google to create his own browser, Chrome. In 2013, he took over his Android from the nowdisgraced creator Andy Rubin. Two years later, he was appointed to oversee Googles entire portfolio of web products, including search, advertising and maps. Pichai took over Google when the company was reorganized under his Alphabet in 2015. Four years later, he became CEO of the entire conglomerate. Page and Brin were considered visionaries, but Page claims that the idea for Google came to him in a dream. Employees say Pichai is a handson leader in keeping trains on schedule. Instead of acting decisively, he often takes a more passive approach, say people who worked with him. During his early tenure, Pichai worked with some Google platform executives and senior staff, including Android head Hiroshi Lockheimer and Nest cofounder Tony Fadell, according to two people who attended the meeting. convened a meeting of Each unit competed over which team would work on which project. An attendee told Forbes that Thunder was literally brought in to broker peace talks between the warring factions. The group gathered for 34 hours. Pichai listened to everyone and asked a few questions, but was mostly silent. In the end, he told platform leaders to solve and report on their own instead of providing clear direction, one of his attendees likening the situation to Game of Thrones. I was. He wanted to unite the kingdom, and everyone respected Sundar, so he bowed to him, said the man. I dont understand. Google declined to comment on the meeting. Fadell, who left the company in 2016, also declined to comment. This episode epitomizes the leadership style that Pichai imparted to the company. In 2018, a group of more than a dozen vice presidents reportedly emailed Pichai, saying the company was taking too long to make big decisions and had difficulty coordinating technical feedback. increase. Part of the companys downturn has been attributed to Pichais demeanor, a former Google executive who worked with him told Forbes. He doesnt like fighting. He doesnt like making unpopular decisions, the person said. Pichai is in a difficult position. Google is far from the cheap startup that Page and Brin founded in a Menlo Park garage in 1998. The company has more than tripled in size since Page took over in 2015, swelling to more than 190,000 fulltime employees in December before layoffs. That explosive growth comes with cultural shifts that can cause stagnation. His former Google engineer, Praveen Seshadri, said last month, without naming Pichai specifically, that the companys management had a bureaucratic and unincentivized stance that people werent motivated to rise above. criticized for having an atmosphere. Overall, it is a calm peacetime culture not worth fighting for, Seshadri wrote in his 3,600word essay. In other words, Google is no longer Googley, one layoff employee told Forbes. I hesitate to hold Sundar accountable or responsible. Because he doesnt have a strong leadership voice in some way, they continued. But that view still doesnt bode well for CEOs. Im not even sure I can say what his specific vision for the company is, other than to maintain the market share we already have. That prospect haunts Pichai now that its competitor is making a meaningful run in its market share for the first time in decades. Even after laying the groundwork to dominate AI, the Google researcher pioneered breakthroughs underpinning chatbots such as ChatGPT and Bing six years before him, a crucial moment for the future of AI. While it turned out to be one, Google was launched into the market. Everything he did was a bet on AI first. That was clearly his heartbeat, said the former Google director. More from ForbesMore from ForbesWhat the AI Arms Race Means for Googles Antitrust IssuesMore from Forbes from Richard NiebaFrom AI First to the End: How Google Lagged in the AI BoomRichard Nivas Inside ChatGPTs breakout moment and the race to make AI work Alex Conrads from Forbes ChatGPT, Stable Proliferation, 6 Things You Didnt Know About the Future of Generative AI Exclusive from Kenrick Kyforbes Interview: OpenAIs Sam Altman talks about how ChatGPT and artificial general intelligence can break capitalism Google Docs is more popular than Forbes than Alex Conrad Microsoft Word.But ChatGPT can change that.By Rashi Shrivastava What Are The Main Benefits Of Comparing Car Insurance Quotes Online LOS ANGELES, CA  ACCESSWIRE  June 24, 2020,  Compareautoinsurance.Org has launched a new blog post that presents the main benefits of comparing multiple car insurance quotes. For more info and free online quotes, please visit https:compareautoinsurance.Orgtheadvantagesofcomparingpriceswithcarinsurancequotesonline The modern society has numerous technological advantages. One important advantage is the speed at which information is sent and received. With the help of the internet, the shopping habits of many persons have drastically changed. The car insurance industry hasnt remained untouched by these changes. On the internet, drivers can compare insurance prices and find out which sellers have the best offers. View photos The advantages of comparing online car insurance quotes are the following: Online quotes can be obtained from anywhere and at any time. Unlike physical insurance agencies, websites dont have a specific schedule and they are available at any time. Drivers that have busy working schedules, can compare quotes from anywhere and at any time, even at midnight. Multiple choices. Almost all insurance providers, no matter if they are wellknown brands or just local insurers, have an online presence. Online quotes will allow policyholders the chance to discover multiple insurance companies and check their prices. Drivers are no longer required to get quotes from just a few known insurance companies. Also, local and regional insurers can provide lower insurance rates for the same services. Accurate insurance estimates. Online quotes can only be accurate if the customers provide accurate and real info about their car models and driving history. Lying about past driving incidents can make the price estimates to be lower, but when dealing with an insurance company lying to them is useless. Usually, insurance companies will do research about a potential customer before granting him coverage. Online quotes can be sorted easily. Although drivers are recommended to not choose a policy just based on its price, drivers can easily sort quotes by insurance price. Using brokerage websites will allow drivers to get quotes from multiple insurers, thus making the comparison faster and easier. For additional info, moneysaving tips, and free car insurance quotes, visit https:compareautoinsurance.Org Compareautoinsurance.Org is an online provider of life, home, health, and auto insurance quotes. This website is unique because it does not simply stick to one kind of insurance provider, but brings the clients the best deals from many different online insurance carriers. In this way, clients have access to offers from multiple carriers all in one place: this website. On this site, customers have access to quotes for insurance plans from various agencies, such as local or nationwide agencies, brand names insurance companies, etc. Online quotes can easily help drivers obtain better car insurance deals. All they have to do is to complete an online form with accurate and real info, then compare prices, said Russell Rabichev, Marketing Director of Internet Marketing Company. CONTACT: Company Name: Internet Marketing CompanyPerson for contact Name: Gurgu CPhone Number: 818 3593898Email: emailprotected: https:compareautoinsurance.Org SOURCE: Compareautoinsurance.Org View source version on accesswire.Com:https:www.Accesswire.Com595055WhatAreTheMainBenefitsOfComparingCarInsuranceQuotesOnline View photos No change, difficulties increased after new army chief, claims Imran Khan Boris Johnson criticized for earning millions while rarely appearing on Commons  Boris Johnson US and EU seek climate truce and united front against China Kelly School Study Finds Why Poor First Impressions Cost Google More Than 100 Billion  Kelly School of Business Who will drive the future of innovation US and EU lawmakers must decide now UK economy rebounds as Jeremy Hunt finalizes budget  Economic Growth Rate GDP Tennis club cuts costs for children due to crisis in cost of living DisclaimerPrivacy and PolicyTerms and ConditionsContact UsAbout us TittlePress AskByGeeks","sentiment":2,"digital transaction":0.0031950476,"healthcare":0.0016915035,"news platform":0.015819259,"data analytics":0.0349679478,"insurance":0.001704599,"investment":0.0640306845,"global market":0.4298814833,"autonomous car":0.0022289297,"customer experience":0.0096982066,"data science":0.0077197333,"cryptocurrency":0.0023760595,"camera":0.0028063881,"robot":0.0068332693,"chatgpt":0.0695806146,"image":0.0444713123,"voice":0.003580149,"patient care":0.001160083,"research":0.3755124211}
{"id":83,"cleaned text":"Global Artificial Intelligence in Robotics MarketGrowth, Trends, and Forecast 20202025  The Global Artificial Intelligence in Robotics Market is expected to register a CAGR of 28 during the forecast period 2020  2025. Artificial intelligence AI and robotics prove to be a powerful combination for automating tasks and processes. AI in robotics gives flexibility in processes and enables the robots with learning capabilities in various applications. Artificial intelligence in robots offers companies new opportunities to increase productivity, make work safer, and save people valuable time.  Integration of robotics and AI augment and amplify human potentials, increase productivity, and are moving from simple reasoning towards humanlike cognitive abilities. The next stage of AI is the era of augmented intelligence, seamlessly linking humans and machines together.  Robots are designed to perform repetitive tasks with utmost precision and increased speed. AI in robotics helps the robots to learn the processes and perform the tasks with complete autonomy, without any human intervention. These benefits are expected to augment the market growth.  Also, higher adoption rates of robots in almost all the enduser verticals, coupled with support from governments worldwide to develop modern technologies, are undoubtedly significant factors augmenting the market growth. However, a reluctance to adopt the technological developments is expected to slow down the market growth. Also, a lack in a skilled workforce to adopt the integration of AI in robotics is hindering the market growth. Artificially intelligence in robotics refers to the seamless integration of robots with artificial intelligence AI technology. These robots learn to perform a few repetitive tasks that can be done without any human intervention and can even communicate with humans or in some cases with other robots.  Major technological disruptions, like artificial intelligence and machine learning, are making their way to the industrial robotics industry. Industrial robots are used majorly in the manufacturing industry, used to perform automated, repetitive, monotonous, and hazardous tasks, to enhance productivity and maximize accuracy.  The integration of AI with industrial robots is expected to grow at a fast pace in the forecast period, owing to the initiatives taken by the manufacturing companies. For instance, in April 2019, Industrial robotics giant Fanuc announced a new AIbased tool at TechCrunchs Robotics  AI Sessions event. The company wants to make robots easier to train, therefore making automation more accessible to a wider range of industries. The new AI tool teaches robots how to pick the right objects out of a bin with simple annotations and sensor technology, reducing the training process by hours.  The merging of AI and industrial robotics is providing several benefits to its early adopters. One of the greatest benefits is increased uptime and productivity from predictive maintenance. With AI integrated with industrial robotics technology, robots can monitor their own accuracy and performance, signaling when maintenance is required to avoid expensive downtime.  Further, with the help of AIbased Industrial Robots, detection and solving a fault becomes easier. They are programmed to detect the faults and fed with solutions to overcome the damage.  Also, industrial robots improve the speed, accuracy, and safety of production. Robots also enable organizations to transform into modern manufacturing techniques and build a robust manufacturing industry. AI technology can give robots the power to see and to identify and interact with what they see.AsiaPacific Expected to Grow Significantly  The AsiaPacific region is expected to exhibit the highest growth rate in terms of the adoption rate of artificial technology for robotics. The major factor driving the adoption rate is the increasing population in the region. Also, the region is deploying robotics in various enduser industries like manufacturing, retail, healthcare, etc. Hence, the integration of AI and robotics is taking place at a fast pace.  Also, in terms of industrial robots, the AsiaPacific region is expected to dominate the market in terms of the deployment of industrial robots in the manufacturing sector to enhance productivity. For instance, according to IFR World Robotics, Asia accounted for 69.1 of industrial robot shipments in 2018. Europe accounted for 17.2, and the United States accounted for 13.7.  The rapid pace of adoption of technological developments in the region is expected to further drive the market in the region. For instance, according to a study by Microsoft in 2019, AI is expected to almost double the rate of innovation and employee productivity in the AsiaPacific by 2021. The competitive landscape of artificial intelligence in robotics is moving towards fragmentation as the market is growing and is providing ample opportunities to the robot vendors. The vendors are ready to make the firstmover advantage and grab the opportunities laid by the different technologies. Also, the vendors are viewing expansion in terms of product innovation and global expansion as a path towards gaining maximum market share.  Mar 2019  Neurala announced the launch of Brain Builder: an endtoend SaaS platform to streamline the creation of custom vision AI solutions. By giving organizations an allinone tool for data tagging, training, deployment, and analysis, Brain Builder makes custom vision AI creation more efficient and accessible for AI beginners and experts alike. Orbis Research orbisresearch.com is a single point aid for all your market research requirements. We have vast database of reports from the leading publishers and authors across the globe. We specialize in delivering customized reports as per the requirements of our clients. We have complete information about our publishers and hence are sure about the accuracy of the industries and verticals of their specialization. This helps our clients to map their needs and we produce the perfect required market research study for our clients. Global Carbon Matrix Composites Market : Competitive Dynamics   Outlook 2026  Global Carbon Nano Materials Market 2020  Industry Analysis, Size, Share, Strategies and Forecast to 2026 Global Carbon Monoxide Market Overview, Opportunities, InDepth Analysis, Segment and Forecast To 2026 Global Carbon Matrix Composites Market : Competitive Dynamics   Outlook 2026 ","sentiment":2,"digital transaction":0.0027185054,"healthcare":0.3048454523,"news platform":0.0294197574,"data analytics":0.0105072828,"insurance":0.0016107813,"investment":0.0221991912,"global market":0.073181197,"autonomous car":0.0017826965,"customer experience":0.0067247921,"data science":0.0145776989,"cryptocurrency":0.0023867027,"camera":0.0016750527,"robot":0.0015651772,"chatgpt":0.0233268104,"image":0.0125692887,"voice":0.0029988301,"patient care":0.0442151576,"research":0.0220612511}
{"id":86,"cleaned text":"OpenAIs DALLE creates plausible images of literally anything you ask it toRead full articleDevin ColdeweyJanuary 5, 2021, 6:51 PM5 min readOpenAIs latest strange yet fascinating creation is DALLE, which by way of hasty summary might be called GPT3 for images. It creates illustrations, photos, renders or whatever method you prefer, of anything you can intelligibly describe, from a cat wearing a bow tie to a daikon radish in a tutu walking a dog. But dont write stock photography and illustrations obituaries just yet.As usual, OpenAIs  description of its invention is quite readable and not overly technical. But it bears a bit of contextualizing.What researchers created with GPT3 was an AI that, given a prompt, would attempt to generate a plausible version of what it describes. So if you say a story about a child who finds a witch in the woods, it will try to write one  and if you hit the button again, it will write it again, differently. And again, and again, and again.Some of these attempts will be better than others indeed, some will be barely coherent while others may be nearly indistinguishable from something written by a human. But it doesnt output garbage or serious grammatical errors, which makes it suitable for a variety of tasks, as startups and researchers are exploring right now.DALLE a combination of Dali and WALLE takes this concept one further. Turning text into images has been done for years by AI agents, with varying but steadily increasing success. In this case the agent uses the language understanding and context provided by GPT3 and its underlying structure to create a plausible image that matches a prompt.As OpenAI puts it:GPT3 showed that language can be used to instruct a large neural network to perform a variety of text generation tasks. Image GPT showed that the same type of neural network can also be used to generate images with high fidelity. We extend these findings to show that manipulating visual concepts through language is now within reach.What they mean is that an image generator of this type can be manipulated naturally, simply by telling it what to do. Sure, you could dig into its guts and find the token that represents color, and decode its pathways so you can activate and change them, the way you might stimulate the neurons of a real brain. But you wouldnt do that when asking your staff illustrator to make something blue rather than green. You just say, a blue car instead of a green car and they get it.Story continuesSo it is with DALLE, which understands these prompts and rarely fails in any serious way, although it must be said that even when looking at the best of a hundred or a thousand attempts, many images it generates are more than a little... off. Of which later.In the OpenAI post, the researchers give copious interactive examples of how the system can be told to do minor variations of the same idea, and the result is plausible and often quite good. The truth is these systems can be very fragile, as they admit DALLE is in some ways, and saying a green leather purse shaped like a pentagon may produce whats expected but a blue suede purse shaped like a pentagon might produce nightmare fuel. Why Its hard to say, given the blackbox nature of these systems.Image Credits: OpenAIBut DALLE is remarkably robust to such changes, and reliably produces pretty much whatever you ask for. A torus of guacamole, a sphere of zebra a large blue block sitting on a small red block a front view of a happy capybara, an isometric view of a sad capybara and so on and so forth. You can play with all the examples at the post.It also exhibited some unintended but useful behaviors, using intuitive logic to understand requests like asking it to make multiple sketches of the same nonexistent cat, with the original on top and the sketch on the bottom. No special coding here: We did not anticipate that this capability would emerge, and made no modifications to the neural network or training procedure to encourage it. This is fine.Here are a few ways GPT3 can go wrongInterestingly, another new system from OpenAI, CLIP, was used in conjunction with DALLE to understand and rank the images in question, though its a little more technical and harder to understand. You can read about CLIP here.The implications of this capability are many and various, so much so that I wont attempt to go into them here. Even OpenAI punts:In the future, we plan to analyze how models like DALLE relate to societal issues like economic impact on certain work processes and professions, the potential for bias in the model outputs, and the longer term ethical challenges implied by this technology.Right now, like GPT3, this technology is amazing and yet difficult to make clear predictions regarding.Notably, very little of what it produces seems truly final  that is to say, I couldnt tell it to make a lead image for anything Ive written lately and expect it to put out something I could use without modification. Even a brief inspection reveals all kinds of AI weirdness Janelle Shanes specialty, and while these rough edges will certainly be buffed off in time, its far from safe, the way GPT3 text cant just be sent out unedited in place of human writing.It helps to generate many and pick the top few, as the following collection shows:AIgenerated illustrations of radishes walking dogs.The top eight out of a total of X generated, with X increasing to the right. Image Credits: OpenAIThats not to detract from OpenAIs accomplishment here. This is fabulously interesting and powerful work, and like the companys other projects it will no doubt develop into something even more fabulous and interesting before long.OthersideAI raises 2.6M to let GPT3 write your emails for youTRENDING 1. China reports 32 new COVID19 cases vs 33 a day earlier 2. Over 50 Hong Kong activists arrested for breaching security lawmedia 3. Selfdriving software startup Oxbotica raises 47mln in latest funding round 4. Georgia Counts Votes With Senate Control, Biden Agenda at Stake 5. U.S. renewable fuel credits surge after lawsuit Latest StoriesYahoo FinanceThese 2 big airlines may shock everyone and merge in a bid to survive COVID19 pandemic: analystConsolidation could soon be flying into the boardrooms of the major airlines as they look to survive the COVID19 pandemic.4h agoYahoo FinanceCEO of Bill Gatesbacked electric car battery startup comments on company outlook after stock plunges 40QuantumScape founder Jagdeep Singh talks with Yahoo Finance after the companys stock fell 40 Tuesday morning.7h agoMoneyWiseJoe Biden now says he wants to give you a third stimulus check  for 2,000Heres how the presidentelect says 2,000 payments could go out the door immediately.4h agoBarrons.comTesla Is Definitely Overvalued, Says Bill Gross. What Hes Buying Instead.Bill Gross end of 2020 may have been more eventful than most other peoples. Not only did the former Bond King spend the last weeks of the year in an Orange County, Calif., courthouse defending his right to blare the Gilligans Island theme song from his Laguna Beach mansion, he also managed to ponder what he calls the Bubblicious stock market.  On Sept. 14, Gross warned that there is little money to be made almost anywhere in the world and urged investors to favor shunned areas such as tobacco, banks, and foreign companies listed on foreign exchanges.  Finally, he got to the good stuff and reexamined the drivers of the runup in the market, namely intense speculation as well as fiscally pumped, central bankprimed corporate earnings as the Federal Reserve moved real interest rates to near zero.3h agoTipRanks2 Strong Buy Penny Stocks That Could Deliver Massive ReturnsTheres a strong feeling growing among investors  of relief  that the new year will feature lower volatility than 2020. That along would be enough to boost spirits, but better yet, there is also a perception that the markets are going to drive higher in the new year.Marko Kolanovic, JPMorgans wellknown quant expert, sees the initial stages of a positive feedback loop, with lower volatility and systematic investment strategies coming together to drive gains, attracting more investors  and, in Kolanovics view, pushing the SP 500 to 4,600 by years end. That will be a 25 increase for the index.A general market environment like that is bound to produce plenty of stock winners, and Wall Streets analysts are busy pointing them out. Among other things, they are tapping penny stocks, equities priced at less than 5 per share. Their rockbottom starting price makes pennies the logical place to look for huge returns on investment. Although their risk factor is high, even a small gain in absolute numbers will turn into a massive percentage gain in share price.Using TipRanks database, we identified two penny stocks the pros believe could see explosive gains in the coming months. Not to mention each one gets a Strong Buy consensus rating from the analyst community.9 Meters Biopharma NMTRSome biopharma companies take a broadbased approach, while others focus on a niche. 9 Meters is one of the latter, taking aim at unmet needs for gastrointestinal patients. The companys development pipeline features drug candidates under investigation as treatments for short bowel syndrome SBS and celiac disease CeD, two conditions that are both dangerous and difficult to treat.Drilling down to pipeline details, 9 Meters flagship product, Larazotide, is in Phase 3 development for the treatment of CeD. CeD affects about 1 of the population, yet there are no approved therapies. Topline data from the study is expected in the second half of 2021.Furthermore, this past December, the company announced that it had entered an agreement with EBRIS, the European Biomedical Research Institute of Salerno, to investigate Larazotide as a potential treatment for respiratory complications due to COVID19.The other major drug in the companys pipeline is NM002, for SBS. The company has recently announced positive Phase 1b2a results, with a measurable impact on disease symptoms from a compound that was welltolerated by patients.NMTRs strong pipeline and 0.89 share price have scored it substantial praise from the pros on Wall Street.One of these NMTR bulls is Truists Srikripa Devarakonda. Citing Larazotide as a key component of his bullish thesis, the analyst noted, We acknowledge investors are likely to see a pivotal trial in a toughtocrack Celiac disease program as high risk despite encouraging Ph2b data. We model 705M353M in peak unadjustedadjusted sales and see potential upside of 400  1650 from positive Ph3 readout.Devarakonda also sees significant unmet need in SBS and continues to believe that NM002 has a differentiated profile vs. SOC. His key takeaways from the recent Phase 1b2a results include: 1 we believe that the drug showed early activity in SBS patients all 9 patients showed meaningful reduction in total stool output volume average TSO reduction was 42 from baseline 2 responses occur rapidly, with effects on TSO seen within 48 hours of dosing 3 safety profile looks favorable, we would like to see greater durability.To this end, Devarakonda rates NMTR shares a Buy along with a 5 price target. This figure conveys his confidence in NMTRs ability to soar 462 in the coming year. To watch Devarakondas track record, click hereTurning now to the rest of the Street, other analysts are on the same page. With 4 Buys and no Holds or Sells, the word on the Street is that NMTR is a Strong Buy. Given its 4.33 average price target, upside of 386 could be in store for investors. See NMTR stock analysis on TipRanksOrchard Therapeutics ORTXOrchard Therapeutics takes the broadbased approach to the biopharma industry. The company is engaged in the development of gene therapies for rare, frequently terminal, diseases, including neurometabolic disorders, primary immune deficiencies, and blood disorders. The gene therapy approach uses blood stem cells to deliver corrected genetic information directly into the patients body.Orchards pipeline demonstrates the diversity of disorders amenable to gene therapy  the company has no less than 12 drug candidates in development. Among these candidates, Libmeldy OTL200 stands out.Libmeldy is in commercialization stages as a treatment for MLD metachromatic leukodystrophy, a rare, mutationbased genetic disorder of the nervous system. Libmeldy, which is designed to treat children suffering from the infantile for juvenile forms of MLD by replacing the defective ARSA gene, received its approval for medical use in the EU in December 2020.Wedbush analyst David Nierengarten notes the European approval of Libmeldy, and its implication for Orchards progress. He writes, We look forward to the companys commercial execution in the EU and an eventual 2022 approval in the US. Last month ORTX received IND clearance from the FDA for the program paving the way for discussions with the US regulators to decide a suitable path forward toward a BLA filing.Netnet, with possibly two gene therapies approved in the next 1218 months and a pivotal study beginning in a third MPSI, we think ORTX shares are undervalued at these levels, the analyst concluded. In line with his bullish comments, Nierengarten rates ORTX as Outperform i.e. Buy, and his 15 price target indicates a potential for 241 growth in the year ahead. To watch Nierengartens track record, click hereDo other analysts agree with Nierengarten They do. Only Buy ratings, 3, in fact, have been issued in the last three months. Therefore, ORTX gets a Strong Buy consensus rating. At 15, the average price target indicates shares could appreciate by 241 in the year ahead. See ORTX stock analysis on TipRanksTo find good ideas for penny stocks trading at attractive valuations, visit TipRanks Best Stocks to Buy, a newly launched tool that unites all of TipRanks equity insights.Disclaimer: The opinions expressed in this article are solely those of the featured analysts. The content is intended to be used for informational purposes only. It is very important to do your own analysis before making any investment.7h agoYahoo FinanceTwo former Apple insiders are building a laser technology startup to fuel the electric car boomUpstart lidar company Aeva is led by two former Apple executives looking to shake up the industry.5h agoYahoo MoneyStimulus: IRS Get My Payment tracking tool now working for 600 direct paymentsAmericans can now check the status of their second stimulus check using the Internal Revenue Services online tracking tool.9h agoBarrons.comApples Earnings Are Coming. Wall Street Is Getting Excited.Two analysts are raising their price targets on Apple stock, with both taking note of strong demand for the new iPhone 12 phone lineup.5h agoYahoo FinanceGMOs Jeremy Grantham warns: The stock market is in a fullyfledged epic bubbleThe long, long bull market since 2009 has finally matured into a fullyfledged epic bubble, says GMOs Jeremy Grantham.6h agoBarrons.comPfizer Drops the Big Blue Pill to Highlight Shift in StrategyPFEis dropping the big blue pill for something a bit more sciencey.  The rebranding comes as Pfizer ticker: PFE completes a slimmingdown that has seen it shed a range of businesses, to focus almost entirely on inventing and buying new drugs.  The turn away from the big blue pill also, incidentally, comes months after the company spun off the division that sells Viagra, Pfizers little blue pill.9h agoTipRanks3 Stocks Trading at RockBottom Prices Analysts Say BuyA new year, a new addition to the stock portfolio  what can make more sense than that The right time to buy, of course, is when stocks are priced at the bottom. Buying low and selling high may be a bit hackneyed, but its true, and truth has staying power.But the markets are up. The NASDAQ rose 43 in 2020, and the SP 500 showed a gain of 16. With a market environment like that, finding stocks that are caught in the doldrums is harder than it looks. Thats where the Wall Street pros can lend a hand.We used TipRanks database to pinpoint three stocks that fit a profile: a share price that has dropped over 30 in the last 12 months, but with at least doubledigit upside potential, according to analysts. Not to mention each has earned a Moderate or Strong Buy consensus rating.Esperion ESPRWe will start with Esperion, a company that specializes in therapies for the treatment of elevated lowdensity lipoprotein cholesterol levels  a major factor contributing to heart disease. The companys main product, bempedoic acid, is now available in tablet form under the brand names Nexletol and Nexlizet.In February 2020, both Nexletol and Nexlizet were approved as oral treatments to lower LDLC. Bempedoic acid remains in clinical trials of its efficacy in risk reduction for cardiovascular disease. The trial, called CLEAR Outcomes, is a largescale, longterm study, tracking more than 14,000 patients with topline data expected in the second half of 2022. The study covers 1,400 locations in 32 countries around the world.Esperion shares peaked last February, after the FDA approvals, but since then, the stock has declined. Shares are down 65 since their peak. Along with the drop in share value, the company showed a fall in revenue from Q2 to Q3, with the top line collapsing from 212 million to 3.8 million. Since the Q3 report, Esperion announced pricing on a 250 million offer of senior subordinated notes, at 4, due in 2025. The offering gives the company a boost in available capital for further work on its development pipeline and its marketing efforts for bempedoic acid.Chad Messer, covering ESPR for Needham, sees the note offering as a net positive for Esperion. We believe this cash position will be sufficient to support Esperion through 2021 and to profitability in 2022... We believe this financing should help put to rest concerns regarding Esperions balance sheet. Despite a challenging launch for NEXLETOL and NEXLIZET, product growth has continued in 3Q against the backdrop of a contracting LDLC market. This growth trajectory suggests potential for a rapid acceleration when conditions improve, Messer wrote.To this end, Messer rates ESPR shares a Strong Buy, and his price target, at 158, suggests the stock has room for huge growth this year  up to 481 from current levels. To watch Messers track record, click hereOverall, Esperion has 6 recent reviews on record, with a breakdown of 5 Buys and 1 Hold to give the stock a Strong Buy rating from the analyst consensus. The shares, trading at 27.16, have an average price target of 63.33, implying a oneyear upside of 133. See ESPR stock analysis on TipRanksIntercept Pharma ICPTLiver disease is a serious health threat, and Intercept Pharma is focused on developing treatments for some of the more dangerous chronic liver conditions, including nonalcoholic steatohepatitis NASH and primary biliary cholangitis PBC. Intercept has a research pipeline based on FXR, a regulator of bile acid pathways in the hepatic system.FXRs action affects not just the bile acid metabolism, but also the glucose and lipid metabolisms, and inflammation and fibrosis around the liver. The lead compound, obeticholic acid OCA, is an analog of the bile acid CDCA, and as such can take a role in the FXR pathways and receptors implicated in chronic liver disease. Treating liver disease through the FXR biology has direct applications for PBC, and is showing promise treating complications from NASH.ICPT shares dropped sharply last summer, when the FDA rejected the companys application to approve OCA for treatment of NASHrelated liver fibrosis. This delays the drugs potential entry to a lucrative market there is no current treatment for NASH, and the first drug to win approval will have the lead in reaching a market estimated at 2 billion to 5 billion in potential annual sales. The effect on the stock is still felt, and ICPT remains at its 52week low point.In reaction, in December of 2020, Intercept announced major changes in toplevel management, as CEO and President Mark Pruzanski announced hes stepping down effective January 1 of this year. He is succeeded by Jerome Durso, formerly the companys COO, who will also take a post on the Board of Directors. Pruzanski will remain as an advisor, and will hold a directors position on the companys Board.Piper Sandler analyst Yasmeen Rahimi takes a deep dive into Intercepts continuing efforts to expand applications of OCA and to resubmits its New Drug Application to the FDA. She sees the leadership transition as part of these efforts, and writes, We believe that Dr. Pruzanskis dedication to transform the liver space is still strong, and that he will continue to guide ICPTs progress as an advisor and Board member. Additionally, we have had the pleasure of working closely with Jerry Durso and believe that he will transform the company and lead ICPTs success in growing the PBC market and the path to potential approval and commercial launch of OCA in NASH.Rahimi takes a longterm bullish stance on ICPT, giving the stock an Overweight i.e. Buy rating and an 82 price target. This figure indicates an impressive 220 upside for the next 12 months. To watch Rahimis track record, click hereWall Street is somewhat more divided on the drug maker. ICPTs Moderate Buy consensus rating is based on 17 reviews, including 8 Buys and 9 Holds. Shares are priced at 25.82, and the average price target of 59.19 suggests an upside potential of 132 for the next 12 months. See ICPT stock analysis on TipRanksGilead Sciences GILDGilead has had a year like a firework  fast up and fast down. The gains came in 1H20, when it appeared that the companys antiviral drug remdesivir would become a prime treatment for COVID19. By November, however, even though remdesivir had been approved, the World Health Organization WHO was recommending against its use, and the COVID vaccines now on the market have made remdesivir irrelevant to the pandemic.This was only one of Gileads recent headwinds. The company has been working, in conjunction with Galapagos GLPG, on development of filgotinib as a treatment for rheumatoid arthritis. While the drug received EU and Japanese approval in September 2020, the FDA has withheld approval and Gilead announced in December that it was suspending US development efforts on the drug.Even so, Gilead retains a diverse and active research pipeline, with over 70 research candidates at varying stages of the development and approval process for a wide range of diseases and conditions, including HIVAIDS, inflammatory  respiratory diseases, cardiovascular disease, and hematologyoncology.On a positive note, Gilead posted Q3 earnings above estimates, with the top line revenue, of 6.58 billion, beating the forecast by 6 and growing 17 yearoveryear. The company updated its fullyear 2020 guidance on product sales from 23 billion to 23.5 billion.Among the bulls is Oppenheimer analyst Hartaj Singh, who gives GILD shares an Outperform i.e. Buy rating and 100 price target. Investors stand to pocket a 69 gain should the analysts thesis play out. To watch Singhs track record, click hereBacking his stance, Singh writes, We continue to believe in our thesis of 1 a dependable remdesivirother medicines business against SARSCoV flares, 2 a base business HIVoncologyHCV growing lowsingle digits over the next couple of years, 3 operating leverage providing greater earnings growth, and 4 a 34 dividend yield. What does the rest of the Street think Looking at the consensus breakdown, opinions from other analysts are more spread out. 10 Buys, 12 Holds and 1 Sell add up to a Moderate Buy consensus. In addition, the 73.94 average price target indicates 25 upside potential from current levels. See GILD stock analysis on TipRanksTo find good ideas for beatendown stocks trading at attractive valuations, visit TipRanks Best Stocks to Buy, a newly launched tool that unites all of TipRanks equity insights.Disclaimer: The opinions expressed in this article are solely those of the featured analysts. The content is intended to be used for informational purposes only. It is very important to do your own analysis before making any investment.1d agoMarketWatchBillionaire Carl Icahn says hes well hedged ahead of a potential painful correction for the stock marketKEY WORDS Thats billionaire investor Carl Icahn talking to CNBC during Mondays selloff about the potential for a big drop in the stock market. Another thing they have in common is its always said, its different this time, he continued.1d agoCoinDeskBlockchain Bites: JPMorgans 146K BTC Target, Crypto Responds to US Treasurys Proposed Wallet RulePLUS: The OCCs green light for banks to use stablecoins, Brazils booming crypto sector and the bitcoin mining machine supply crunch.7h agoInvestors Business DailyDow Jones Futures: Stock Market Rally Focuses On Georgia Senate Vote Tesla Aims For Record High On Price Target HikeDow Jones futures were little changed late Tuesday, as they eyed the Georgia Senate runoff vote. Apple snapped back, while JD surged past a new buy point.18m agoMarketWatchFamed investor doubling down, says stock market a real humdinger of a bubbleJeremy Grantham, cofounder and chief investment strategist at Bostonbased money manager Grantham, Mayo, Van Otterloo  Co., in a research report dated Tuesday doubles down on his warning of a bubble in stocks in recent research report.3h agoTheStreet.comAlibaba Shares Leap After CNBC Reports Billionaire Founder Jack Ma Not MissingAlibabas billionaire cofounder, Jack Ma, is not missing, CNBC reported Tuesday, after drawing the ire of the Chinese leadership for critical comments he made during a speech in October.1h agoInvestors Business DailyCrude Oil Prices Soar As Saudi Arabia Gives The Industry A Great New Year PresentCrude oil prices jumped after Saudi Arabia announced a surprise output cut at the OPEC meeting Tuesday.  After a twoday meeting, Saudi Arabia shocked oil markets with a voluntary 1millionbarrelperday output cut.  Russias deputy prime minister and energy minister, Alexander Novak, called the Saudi Arabia production cut a great New Year present for the whole oil industry.3h agoMarketWatchFurious TurboTax and HR Block customers are waiting for their 600 stimulus check  and demanding to know why theyre delayedAs 2021s first week kicks off, funds from the second round of stimulus checks are starting to become available  but not necessarily for some HR Block and TurboTax customers who are now venting online.  Customers for the two major taxpreparation companies took to Twitter.  Mnuchin said the directdeposit distribution process started last Tuesday night and the IRS would start dropping checks in the mail one day later.5h agoMarketWatchHeres how bitcoin could soon be worth 146,000 according to JPMorganJPMorgan researchers point to outflows from goldpegged exchange traded funds, or ETFs, and inflows into a digitalcurrency focused trusts sponsored by Grayscale, for example, as part of the evidence pointing to increased use of bitcoin as a goldlike asset, which would help to drive its price further into the stratosphere.6h agoBarrons.comSnowflake Lockup to End Early for Some Shares. A Blizzard of Selling Is Possible.SNOW could be headed for an avalanche of insider selling.  In a securities filing late last week, the cloudbased data warehouse company disclosed that the huge runup in its stock price following its initial public offering had triggered a provision in its lockup agreement with the companys officers, directors, and early shareholders to allow a quarter of those holdings to trade.  Terms of the deal required that Snowflake ticker: SNOW trade 133 above the companys 120 IPO price for at least 10 days in a 15day period.5h agoMore Stories","sentiment":2,"digital transaction":0.1728467196,"healthcare":0.0348980725,"news platform":0.1736016273,"data analytics":0.2845949233,"insurance":0.0087926555,"investment":0.3629890084,"global market":0.874302268,"autonomous car":0.0802638903,"customer experience":0.1707199812,"data science":0.0600166172,"cryptocurrency":0.0154987834,"camera":0.0557313822,"robot":0.0771412775,"chatgpt":0.2032673955,"image":0.1487754434,"voice":0.1564515829,"patient care":0.0208673049,"research":0.7135646343}
{"id":87,"cleaned text":"Saudi Data, AI Authority SDAIA and Ministry of Energy Partner with IBM to Accelerate Sustainability Initiatives in Saudi Arabia Using AIRead full articleSeptember 27, 2022, 12:00 AM2 min readRIYADH, Saudi Arabia and ARMONK, N.Y., Sept. 27, 2022 CNW  Saudi Data and Artificial Intelligence Authority SDAIA and IBM NYSE: IBM announced today the signing of a strategic agreement to drive adoption of artificial intelligence in the carbon capture and industrial domains across the Kingdom of Saudi Arabia.The signing took place at the Global AI Summit, Riyadh, Saudi Arabia. In the picture: Dr. Majid AlTuwaijri, the CEO for the National Center for AI, Eng. Ahmed AlZahrani, Ministry of Energys Assistant Minister for Development and Excellence, Dina AboOnoq, Managing Partner, IBM Consulting Saudi Arabia and Bill Lafontaine, General Manager, Intellectual Property and Research, IBM. Image credit: Global AI SummitAnnounced at the second Global AI summit in the Kingdom, the first use case under this agreement will be in collaboration with the Ministry of Energy in Saudi Arabia. SDAIA, Ministry of Energy and IBM will use artificial intelligence technology to detect, map, and eventually reduce carbon emissions across the country.Dr. Majid AlTuwaijri, the CEO for the National Center for AI, said, This agreement with IBM will contribute to creating opportunities by addressing key challenges in circular carbon economy, petrochemical and industrial domains, through the development of innovative solutions in the field of data and artificial intelligence, and the exchange of shared experiences and investment opportunities in this vital area to support achieving the goals of Vision 2030.This agreement would allow us to leverage IBMs expertise in technologies like artificial intelligence, Eng. Ahmed AlZahrani, Ministry of Energys Assistant Minister for Development and Excellence, said, which will play a key role in promoting the adoption of the Circular Carbon Economy, achieving the goals announced during the Saudi Green Initiative.The management of greenhouse gas emissions is critical to the Kingdoms reaching its objective of net zero, said Dina AboOnoq, Managing Partner, IBM Consulting Saudi Arabia. Using multiple satellites and different types of imaging technologies, we will train an AI model to recognize and pinpoint different forms of gas across the entire country. By doing so, this will help with earlier and better visibility of the problem which has not been possible with conventional measurement approaches.Story continuesAs part of the overall agreement, IBM will work with SDAIA to identify high value applications of artificial intelligence and machine learning to solve challenges in public and private sector organizations in the Kingdom, with a focus on supporting the Kingdoms sustainability and industrialization objectives.Saudi Arabia is currently undergoing a major transformation program to become a global logistics hub and industrial powerhouse. The Kingdom has also set a target of achieving net zero in emissions by 2060 and to support the global effort to cut emissions. New cities and infrastructure being built in the Kingdom, such as NEOM or the Red Sea, are being designed with sustainability objectives in mind.Contact:Preeti Guptapreetig@sg.ibm.comIBM Corporation logo. PRNewsfotoIBMCisionView original content to download multimedia:https:www.prnewswire.comnewsreleasessaudidataaiauthoritysdaiaandministryofenergypartnerwithibmtoacceleratesustainabilityinitiativesinsaudiarabiausingai301633657.htmlSOURCE IBMCisionView original content to download multimedia: http:www.newswire.caenreleasesarchiveSeptember202227c8941.html Related QuotesSymbolLast PriceChange ChangeIBMInternational Business Machines Corporation122.010.700.57TRENDING 1. UPDATE 2With flowers and a gun salute, Japan bids farewell to slain Abe at state funeral 2. Stocks Mixed, US Futures Up as Dollar Rally Pauses: Markets Wrap 3. Indias BigBasket looks to raise 200 million at up to 3.5 billion valuation ET 4. Cryptoverse: Bitcoin miners get stuck in a bear pit 5. PRESS DIGEST Wall Street Journal  Sept 27 Recommended StoriesYahoo FinanceCostco stock: Analyst estimates next membership fee hike and resulting windfallCostcos last membership fee increase kicked in on June 1, 2017.14h agoBloombergBiden Tells Oil Companies Bring Down Prices Youre ChargingBloomberg  While US gasoline prices have come down from the highs seen this summer, theyre clearly still weighing on President Joe Biden, who on Monday repeated demands for oil companies to charge less.Most Read from BloombergJohn Paulson on Frothy US Housing Market: This Time Is DifferentStocks, Commodities Drop US Treasury Yields Surge: Markets WrapUK Market Selloff Slams Gilts, Pound, Piling Pressure on BOEWall Street Banks Prep for Grim China Scenarios Over TaiwanEverythingSelloff on6h agoInsider Monkey10 Best Oil Stocks To Buy According To Hedge FundsIn this article, we discuss the 10 best oil stocks to buy according to hedge funds. If you want to read about some more oil stocks, go directly to 5 Best Oil Stocks To Buy According To Hedge Funds. The oil sector has rebounded from the lows of the pandemic this year and prices have 17h agoReutersOil prices claw back some losses as focus turns to possible supply cutsReuters Oil prices rose on Tuesday, after plunging to ninemonth lows a day earlier, on indications that producer alliance OPEC may enact output cuts to avoid a further collapse in prices.  U.S. West Texas Intermediate WTI crude futures for November delivery were up 64 cents at 77.35 per barrel.5h agoMotley Fool2 HighGrowth Electric Vehicle Stocks to Consider Buying Other Than TeslaIn 2021, sales of new lightduty fully electric vehicles EVs nearly doubled in the United States from the prior year, while overall lightduty vehicle sales increased by only 3, according to government figures.  Two stocks that have strong longterm growth potential are those of lithium producer Albemarle NYSE: ALB and EV maker Rivian Automotive NASDAQ: RIVN.  The U.S.based company is one of the worlds top producers of lithium, a component of the lithiumion batteries that power EVs.14h agoBloombergRussian Crude Is Slowly Being Squeezed Out of EuropeBloomberg  Russias seaborne crude exports to Europe are being compressed, with the blocs sanctions only about two months away. Shipments in recent weeks have been little more than half preinvasion levels and will come under increasing pressure as the import ban nears.Most Read from BloombergJohn Paulson on Frothy US Housing Market: This Time Is DifferentUK Market Selloff Slams Gilts, Pound, Piling Pressure on BOEWall Street Banks Prep for Grim China Scenarios Over TaiwanUS Stocks Fall, Yi17h agoMotley Fool2 Growth Stocks Down 14 to 28 to Buy and Hold ForeverLets examine two stocks worth keeping in this challenging market and beyond: Abbott Laboratories NYSE: ABT and Apple NASDAQ: AAPL.  Abbott Laboratories focuses on medical devices, although it has a diversified business with multiple segments that allow it to navigate difficult times.  For instance, when the companys medical devices segment took a hit during the pandemic, its diagnostics unit picked up the slack.16h agoInvestors Business DailyNio, BYD, China EV Makers Make Big Push Into EuropeKey to their growth plans, China EV makers Nio, BYD and Xpeng are ramping up in Europe. Can they grab share from traditional giants and Tesla13h agoBloombergSuncor to Buy Back Debt After Oil Drop, Ratings DowngradeBloomberg  Suncor Energy Inc. is pushing ahead with a bond buyback as oil prices near this years lows amid recession worries.Most Read from BloombergJohn Paulson on Frothy US Housing Market: This Time Is DifferentStocks, Commodities Drop US Treasury Yields Surge: Markets WrapUK Market Selloff Slams Gilts, Pound, Piling Pressure on BOEWall Street Banks Prep for Grim China Scenarios Over TaiwanOnceHot Fake Meat Sees Sales Slide on Price and Being Too WokeCalgarybased Suncor plans to buy14h agoInvestors Business DailyArtificial Intelligence Stocks To Watch: Big Tech Expands AI Products, ServicesWhen looking for the best artificial intelligence stocks to buy, identify companies using AI technology to improve products or gain a strategic edge, such as Google, Microsoft and Nvidia.18h agoBenzingaIntel Shortlists These Two Regions In Italy For MultiBillion Euro Chip PlantMario Draghis outgoing government and Intel Corp NASDAQ: INTC zeroed on Vigasio in northeastern Veneto for a new multibillioneuro chip factory in Italy. Intels investment in Italy is part of its broader plan to invest up to 80 billion 77.5 billion over the next decade, Reuters reports. With an initial investment worth 4.5 billion, Intel expects the Italian plant to create 1,500 jobs plus an additional 3,500 jobs across suppliers and partners, with operations to start between 2025 and 220h agoZacks4 Restaurant Stocks to Buy Amid Ongoing Industry ChallengesThe restaurant industry is facing inflationary pressures but sales are still rising, helping stocks like Arcos Dorados Holdings ARCO, Potbelly Corporation PBPB, FAT Brands FAT and Cracker Barrel Old Country Store CBRL.18h agoBloombergChinas Economic Recovery Faces Fresh Risks From Global SlowdownBloomberg  Chinas shaky recovery continued in September, with a pickup in car and homes sales in the biggest cities compensating for weaker global demand and falling business confidence. Most Read from BloombergJohn Paulson on Frothy US Housing Market: This Time Is DifferentStocks, Commodities Drop US Treasury Yields Surge: Markets WrapUK Market Selloff Slams Gilts, Pound, Piling Pressure on BOEWall Street Banks Prep for Grim China Scenarios Over TaiwanEverythingSelloff on Wall Street Dee2h agoReutersRio Tinto says employee sexually assaulted in Western Australian mineRio Tinto Ltd on Monday said an employee at one of its mines in Western Australia state was sexually assaulted and that police removed the alleged perpetrator from the site.  The incident comes three months after Australias sex discrimination commissioner called for urgent changes in the countrys mining industry after a state government report found that sexual harassment and assault were rife in the sector.  Rio Tinto continues to work closely with Department of Mines, Industry Regulation and Safety in relation to its investigation, a spokesperson said in an emailed statement.1d agoBloombergApple Begins Making iPhone 14 in India Weeks Ahead of ScheduleBloomberg  Apple Inc. began making its new iPhone 14 in India sooner than anticipated, after a surprisingly smooth production rollout that slashed the lag between Chinese and Indian output from months to mere weeks.Most Read from BloombergJohn Paulson on Frothy US Housing Market: This Time Is DifferentStocks, Commodities Drop US Treasury Yields Surge: Markets WrapUK Market Selloff Slams Gilts, Pound, Piling Pressure on BOEWall Street Banks Prep for Grim China Scenarios Over TaiwanOnceHot F22h agoInvestopediaKey Tips for Investing In REITsThinking of investing in REITs Heres what you need to know and to consider when evaluating a real estate investment trust.1d agoZacksAuto Roundup: Fs Profit Warning, AZOs Solid Quarterly Results  MoreWhile Ford F expects its Q3 profits to suffer amid commodity cost inflation, AutoZone AZO delivers impressive fiscal Q4 results.15h agoReutersDroughts, Ukraine war push global grain stocks toward worrying decade lowThe world is heading toward the tightest grain inventories in years despite the resumption of exports from Ukraine, as the shipments are too few and harvests from other major crop producers are smaller than initially expected, according to grain supply and crop forecast data.  Poor weather in key agricultural regions from the United States to France and China is shrinking grain harvests and cutting inventories, heightening the risk of famine in some of the worlds poorestnations.  Importers, food manufacturers and livestock producers had hoped crop availability would improve after wartorn Ukraine resumed shipments from Black Sea ports this summer and U.S. farmers planted large crops.20h agoThe Wall Street JournalToyota Softens Toward Critics of Its EV PushThe auto maker is seeking meetings with investors and environmental groups that have questioned its commitment to greener cars.2d agoZacksEV Roundup: Updates From GM, F, and TSLA Take the SpotlightWhile General Motors GM inks deals to boost its EV game, Ford F begins construction of its 5.6 billion EV plant in Tennessee. Teslas TSLA recall and output rampup in Germany also draw attention.15h agoMore Stories","sentiment":2,"digital transaction":0.1609039754,"healthcare":0.990445137,"news platform":0.8743628263,"data analytics":0.8381617665,"insurance":0.0705707893,"investment":0.485878706,"global market":0.8659306765,"autonomous car":0.0056858719,"customer experience":0.0999288782,"data science":0.871702373,"cryptocurrency":0.0116891917,"camera":0.0362361707,"robot":0.0735245869,"chatgpt":0.7098326087,"image":0.9416536093,"voice":0.0621878877,"patient care":0.9034115672,"research":0.9607228637}
{"id":89,"cleaned text":"TrueCircle scoops 5.5M to use AI to drive recycling efficiencyRead full articleNatasha LomasMarch 2, 2022, 12:53 PM9 min readUKbased TrueCircle, a computer vision startup founded just last year, has nabbed 5.5 million in preseed funding in a bid to bring datadriven AI to the recycling industry to improve recovery rates and quality  with the overarching goal of transforming the economics of waste reuse to shrink demand for virgin materials.So far the startup has its tech up and running in eight UK waste sorting facilities but is ramping up quickly, with more launches coming in Q2  when it will be expanding internationally into Europe and the US. It tells TechCrunch its shooting to have some 3040 customers using its tech within 12 months time. The preseed is notable for its size. The round is led by Chris Saccas climate focused Lowercarbon Capital fund, with participation from Passion Capital, Giant Ventures and firstminute Capital, as well as the founders of companies including Revolut, Monzo, Infarm and Unity investing in a personal capacity.Commenting on TrueCircles preseed raise in a statement, Lowercarbon Capitals Clay Dumas, said: Singleuse plastic is a 300 million tonne scourge on our oceans and landfills that keeps the petrochemical industry in business. We backed TrueCircle because theyre harnessing technology and markets to build a solution that scales to the dimensions of the problem.TrueCircles two cofounders, Eamon Jubbawy and Rishi Stocker, are not new to the startup game. Indeed, Jubbawy actually has two startups on the go at once right now the other being an a16zbacked fintech called Sequence.The pair, who originally met at school, tout a lot of relevant tech and business smarts theyre bringing to bear here: Including computer vision experience from Onfido, another of Jubbawys startups, where he built up a computer vision team focused on identity document verification and face matching he left Onfido in summer 2020 and commercial experience from fintech startup Revolut, where Stocker was one of its first employees and spent four years running global partnerships. He also previously worked at FMCG giant Unilever, and says hes no strange to the challenges of increasing packaging recycling rates.Story continuesRecycling isnt the most glamorous topic ofc but low levels of efficiency in the waste processing industry are a pressing problem from multiple angles  not least when combined with humanitys pressing need to radically shrink global consumption in order to cut emissions and avoid catastrophic climate change  meaning there are real, meaningful problems here that tech could help solve.Problems that scale all over the globe, too. So the disruption potential  and revenue opportunities  look huge.Regulation is also driving a lot more attention to whats passing down the conveyor belts, as lawmakers start to impose conditions on use of virgin materials for things like packaging  actively changing the economics of recycling.Equally, widespread public anger over direct environmental impacts of discarded waste, like singleuse plastic polluting the oceans and creating a risk to marine life, is creating energy for change.Meanwhile AIdriven efficiency gains  and the digitalization of industrial processes more generally  are being specifically looked to to address climate change, including by policymakers in the Europe Union who are pushing a combined green and digital transformation investment strategy for the bloc to try to hit net zero carbon emissions by 2050.The beauty of our approach is if you scale it up across the tonnage thats been processed in the world today its a very scalable business model  if we were to just focus on this dataasaservice business but our ambitions dont stop there, says Stocker. I think this is the thing that gets us all super excited. We have a chance here to disrupt a 20BN per year industry through a much more digitalized trading infrastructure.Historically, attempts to revolutionize this industry were maybe a bit more academic and technology based but I think the approach which weve taken, from our experience of building and commercializing technology companies  at Onfido Rishi was heading up a lot of our monetization strategies at Revolut  weve realized you need a lot more than that, adds Jubbawy.You need great tech but you also need to find a way to make this industry work commercially. Hence turning our focus to getting the sales process working really effectively because thats just another reason why the recycling industry hasnt been given the attention that it should.Rewinding slightly, TrueCircles founders are starting with a pretty elementary idea of applying computer vision technology to the waste streams flowing through processing facilities so it can provide its customers with realtime time flows of data on whats passing through their plants  powering waste analytics and alerts.This means the startup is installing connected camera and lighting kit in their customers waste processing plants  and doing that free of charge since the business model is a SaaSstyle fee, based on the processing per tonnage scanned.What we realized is these facilities  their major issue today is they have absolutely no data, explains Stocker. Its a completely datasparse industry.In the absence of any data, on the composition of waste coming in, and more importantly the actual quality theyre able to achieve on those distinct output lines, they come across the same problem again and again: 1 Their buyers dont trust what theyre purchasing so they always get underpaid for the materials. And 2 they actually dont know when there are issues in their plant because they have no way of capturing realtime data.That was the real lightbulb moment for us  especially where Eamons computer vision knowledge of setting up and building Onfide from scratch came into play  we realized with a few very quick tests, actually by installing a very cheap camera with a lighting setup on the conveyor belts that are in these facilities we could then feed that data to the cloud and apply a computer vision machine learning model to tag every single item, he adds.Weve seen this sort of idea before  such as by TechCrunch Disrupt battlefield alum Greyparrot another UKbased startup, which was founded back in 2019 and already sells an AI waste recognition system thats been globally deployed.But TrueCircle suggests its approach is more full stack as its also building an automation piece, initially via digital alerts its system sends to factory employees when quality thresholds drop below a customizable level  providing them with a root cause diagnosis so they can take immediate action to correct a problem with their sorting machinery.Later it says it wants to integrate the alert system with the plants machinery in order that its software could automatically undertake those sorts of corrections too.The next step that were working on now is actually programmatically integrating with their existing machinery  such that when we spot an issue we can adjust the settings of that device and ensure it resolves it without manual intervention, says Stocker. So thats really where we want to get to. We want to be this data as a service layer that spots issues, fixes them and then certifies the quality to maximize the selling potential.Theres more too: In parallel, TrueCircle is building a marketplace to support waste processing facilities in selling the verified material they reclaim.Here its premise is that it will be able to help facilities achieve better prices for the processed waste as a result of the data that will come attached to it  aka, the analytics and qualitypurity guarantee its AI is able to provide.So the pitch is that  finally  waste processing facilities will have the data to show buyers that ensures they can get a fair price.By having a bit more of a full stack approach, to helping recycling facilities work with each other, connect with each other, obviously have better data on what theyre doing and make better decisions you can get the whole industry working more effectively, suggests Jubbawy.We go after buyers who care about quality, adds Stocker. Weve been able to attract buyers from Germany, for example, onto the platform  because they can see exactly what theyre buying and they can place a bid thats reflective of that quality.This is a classic data as a service business  at least in its first module  because now a facility can come onto the platform and say okay I want to understand the quality of my outputs to help our facility get better revenues from a range of buyers. So theyre able to log on and generate a report for buyers. When they sell material at the end of every month theyre able to attach this report of realtime data which shows the exact quality of that line to all of the buyers.I come from the fintech world so I kind of bring it back to Moodys ratings, he adds. We see it as we become this Moodys equivalent for the recycling industry and then that enables us to build the rest of the infrastructure that the industry needs to facilitate efficient recycling.TrueCircle says its AI models can currently identify around 50 different categories associated with waste  such as the material of the item, its weight, the brand, whether its food grade item etc.While accuracy rates for its waste scanning AIs are slated at between 9298.And after two months, the startup says it was able to demonstrate  in some of the initial facilities using its alerts dashboard  that its customers were getting a 1015 higher recovery rate vs how they were operating before, i.e. without any AI to keep an eye on waste purity.Given the types of jobs set to be automated here  i.e. dirty, smelly and potentially dangerous low paid manual labor  this is one application of AI that might be more welcomed than feared, Jubbawy also suggests.Ultimately the reason Im motivated by this is I remember reading Bill Gates book on How to Avoid a Climate Disaster where he categorizes all the causes of this 51BN tonnes of greenhouse gases that we need to remove and the unnecessary use of virgin materials for packaging adds around 23  so well above 1Gigaton, he says, adding that the teams overriding motivation is doing our part to get those 51BN tonnes down to zero.Chris Saccas Lowercarbon Capital has raised 800 million to keep unfcking the planet Recommended StoriesMotley FoolWhy Lockheed Martin Stock Plunged TodayShares of defense contracting pure play Lockheed Martin NYSE: LMT  which got quite a lift on Tuesday after Germany announced plans to triple its 2022 defense budget, and Wolfe Research upgraded LockMart stock in response  is giving back its gains on Wednesday.  As of 10 a.m. ET, Lockheed Martin stock is down 4.4.  Why is Lockheed Martin stock  a defense stock, lets not forget, in a time of conflict in Europe  down3h agoYahoo FinanceFord just shocked the system: analystWall Street begins to weigh in on a major transformation just unveiled at Ford.1h agoSmartAssetVanguard Is Giving 1 Billion Back to Investors Are You Entitled to Some MoneyPretty much everything in life costs money, including financial services. One mutual fund firm  Vanguard, already famous for its relatively low fees  is changing its expense ratios with the aim of returning a total of 1 billion in  Continue reading  The post Vanguard Is Giving 1 Billion Back to Investors Are You Entitled to Some Money appeared first on SmartAsset Blog.5h agoBenzingaWhy Are Karyopharm Shares Trading Lower TodayKaryopharm Therapeutics Inc NASDAQ: KPTI stock plunged after an update on its supplemental New Drug Application submission based on the Phase 3 SIENDO study data of selinexor as frontline maintenance therapy following chemotherapy in advanced or recurrent endometrial cancer. The cmpany received feedback that the current SIENDO study topline results would not support an sNDA approval. Karyopharm and the FDA participants had differing views on the study significance and overall clinical benefit7h agoMotley FoolWhy Pfizer Stock Is Catching Fire TodayWhat happened Shares of Pfizer NYSE: PFE were up by 4 as of 12:08 p.m. ET Wednesday. The drugmakers stock is rising today in response to two separate catalysts. First up, President Joe Bidens Test to Treat initiative, announced during his State of the Union address on Tuesday, ought to be a boon for Pfizers oral COVID19 pill Paxlovid.43m agoYahoo Finance VideoFord announces it is splitting its EV and legacy auto unitsYahoo Finances Brian Sozzi and Julie Hyman discuss news that Ford will separate its electric vehicle and internal combustion engine businesses.5h agoMotley Fool2 Numbers That Should Make Novavax Shareholders SmileNovavax NASDAQ: NVAX missed Wall Streets revenue estimate in the fourth quarter of 2021.  As proof, the vaccine makers shares rose on Tuesday after Novavaxs Q4 update following the market close on Monday.  Here are two numbers that should especially make Novavax shareholders smile.9h agoMarketWatchHeres exactly how much money is in the average savings account in America and psst: its a lot more than you might guessWhile theres no magic number as to the amount of money someone should have in savings, experts agree that at least having an emergency fund  anywhere from3to9 months of expenses  in savings is imperative.  But accounts with higher APYs do exist.8h agoTipRanks2 Strong Buy Oversold Stocks That Could Be Ready for a ComebackThere are plenty of fundamentally sound, low cost stocks out there for retail investors to consider. The key to success is to find stocks that are at or near the bottom of their cycle. Equity investment advisors will always tell you that timing the market is impossible, and theyre right  but timing is still important for success. Investors need to buy into low prices, and to do that, they need to know when prices are low. This doesnt necessarily mean low in absolute dollar terms, but low re4h agoMotley FoolWhy Paysafe Stock Is Soaring TodayShares of Paysafe NYSE: PSFE, a payments platform, were skyrocketing this morning after the company reported betterthanexpected fourthquarter results.  Investors reacted positively to the company beating analysts consensus estimate for revenue in the quarter and pushed the tech stock up by 10 as of 10:29 a.m. ET.  Paysafes sales of 371.7 million in the fourth quarter were essentially flat on a yearoveryear basis, but that revenue easily beat Wall Streets consensus estimate of 357.4 million for the quarter.3h agoMotley FoolWhy Palantir Stock Is Falling TodayShares of Palantir Technologies NYSE: PLTR are falling today despite gains for the broader market.  The companys stock was down roughly 4.8 as of 12:40 p.m. ET Wednesday in conjunction with the announcement of a new partnership with Jacobs Engineering Group NYSE: J.  Palantir stock has been volatile in recent months and has seen particularly turbulent trading following its fourthquarter report in midFebruary, so its difficult to say how much of todays movement is connected to the news of the Jacobs partnership or other catalysts at play.2h agoMotley FoolWhy Nvidia Stock Popped TodayShares of Nvidia NASDAQ: NVDA had jumped 2.4 at 11:15 a.m. ET on Wednesday.  The most obvious catalyst was a hack of the companys data and, in response, Nvidias own hack of the offending party.  As multiple news agencies have reported, Nvidia  Americas largest semiconductor stock by market capitalization  was hacked last week by parties unknown.1h agoBarrons.comRussian Stocks Are Nearly Worthless as Ukraine Sanctions BiteSome Russian companies have recently been valued at more than 100 billion. Sberbank, the countrys biggest bank. traded for a penny in London.2h agoInsider Monkey10 Best Undervalued Stocks According to Hedge FundsIn this article, we discuss the 10 best undervalued stocks according to hedge funds. If you want to skip our detailed analysis of these stocks, go directly to the 5 Best Undervalued Stocks According to Hedge Funds. There is a lot of concern around the economic impact of the Russian invasion of Ukraine on markets 5h agoMotley FoolWhy Rivian Stock Plunged Again TodayAn analyst price target cut combined with the need to raise prices on its trucks is hitting the stock today.3h agoMotley FoolWhy First Solars Stock Is Falling TodayPoor fourthquarter cash flow and weak guidance have investors seeing gray skies ahead for this solar panel maker.3h agoYahoo Finance VideoNordstrom stock jumps on Q4 earningsYahoo Finances Brian Sozzi and Julie Hyman discuss why Nordstrom stock is soaring after the company reported earnings.5h agoQuartzChinas tech giants face a domestic backlash for plans to exit from RussiaUS and European firms have scrambled to comply with sweeping western sanctions issued in response to Russias invasion of Ukraine.  US sanctions prevent hightech goods that use its components or software from being exported to Russia, even if they are made in foreign countries consumer electronics are not supposed to be affected.  Chinas online influencers are already watching closely to see if the countrys tech giants appear to be complying with sanctions.5h agoMotley FoolWhy Roblox Stock Slumped 21.7 in FebruaryInvestors lost confidence in Roblox NYSE: RBLX in the second month of 2022 after the company reported underwhelming revenue and user growth for the fourth quarter of 2021.  According to data from SP Global Market Intelligence, shares of the gaming platform dropped 21.7 in February.  On Feb. 15, Roblox released its earnings report for Q4 2021.3h agoMotley FoolWhy Nio Stock Is Falling TodayShares of NioNYSE: NIO, a leading Chinese electric vehicle EV company, were sliding this morning after the company reported slowing EV sales yesterday.  Investors may also be reacting to news that another EV competitor is raising prices due to rising costs.  Nio said yesterday that its vehicle deliveries increased 10 in February, compared to the same time a year ago.3h agoMore Stories","sentiment":2,"digital transaction":0.729575038,"healthcare":0.1087154672,"news platform":0.6244865656,"data analytics":0.9599360228,"insurance":0.0198807605,"investment":0.0570200086,"global market":0.7093974352,"autonomous car":0.750793159,"customer experience":0.8651504517,"data science":0.6284570098,"cryptocurrency":0.0086822184,"camera":0.0797886252,"robot":0.2765594721,"chatgpt":0.6914078593,"image":0.3525070846,"voice":0.8816837668,"patient care":0.0194083452,"research":0.1428678483}
{"id":92,"cleaned text":"Code Red: ChatGPT AI Scares Google Into Action  Fossbytes OpenAI has been hard at work for a long time to take AI to the next level. Its most recent efforts gained recognition when ChatGPT, the AI chatbot, was released earlier this month. In fact, the response has been so overwhelming that it has forced Google to pull up its socks. According to The New York Times, Google CEO Sundar Pichai held deliberations with his employees regarding AI chatbots. In the wake of ChatGPTs successful beta launch, they examined the threat posed by such emerging technology to their search engine business. Thanks to ChatGPTs huge database, it generates an answer to the most complex problems in just a few seconds. Unlike Google Search, these answers arent entirely picked from other websites, reducing the margin of error. Instead, the output is technically formulated by the chatbot itself based on its database records. Additionally, what separates ChatGPT from other chatbots is its humanlike conversational approach. The NYT also reports that Google engineers have been asked to focus on and improve their Artificial Intelligence plans. This action would enhance Google Searchs existing capabilities and not be anything new of its own. To achieve this, the firms research, as well as its Trust and Safety departments, will aid in building and rolling out prototypes. ChatGPT isnt the only thing Google is worried about. DALLE, another OpenAI creation, is a bot that creates art captivating enough to grab the search engine giants attention. As a consequence, recent meetings also involved urging the team to explore the development of AI capable of generating graphics. The absurdly impressive reception to ChatGPT has definitely put future competitors into alert mode. Hopefully, over time, developments like this one will push mainstream search engines into improving their AI algorithms to keep up with virtually omniscient chatbots. Priye is a tech writer at Fossbytes, who writes about gaming and anything remotely related to tech, including smartphones, apps, OTT, etc. He prefers to be called a video game journalist and grimaces when he doesnt get to be Player 1. If you want to talk about games or send any feedback, drop him a mail at emailprotected  What Time Is Alice In Borderland Season 2 Releasing On Netflix Recap, Plot  More Beelink is known for carrying various mini PC products that scale across a broad spectrum of performance targets. The GTR6","sentiment":2,"digital transaction":0.4535450339,"healthcare":0.0048014713,"news platform":0.666315794,"data analytics":0.2487984002,"insurance":0.0147540392,"investment":0.7243964076,"global market":0.4728043675,"autonomous car":0.007040028,"customer experience":0.8947318196,"data science":0.3764452934,"cryptocurrency":0.0144230155,"camera":0.0238141771,"robot":0.0937046036,"chatgpt":0.1991595477,"image":0.168872267,"voice":0.9768238664,"patient care":0.0093343342,"research":0.234282136}
{"id":96,"cleaned text":"Musk, scientists call for halt to AI race sparked by ChatGPT FILE  The OpenAI logo is seen on a mobile phone in front of a computer screen displaying output from ChatGPT, Tuesday, March 21, 2023, in Boston. Are FILE  The OpenAI logo is seen on a mobile phone in front of a computer screen displaying output from ChatGPT, Tuesday, March 21, 2023, in Boston. Are tech companies moving too fast in rolling out powerful artificial intelligence technology that could one day outsmart humans That is the conclusion of a group of prominent  Are tech companies moving too fast in rolling out powerful artificial intelligence technology that could one day outsmart humans  Thats the conclusion of a group of prominent computer scientists and other tech industry notables such as Elon Musk and Apple cofounder Steve Wozniak who are calling for a 6month pause to consider the risks. Their petition published Wednesday is a response to San Francisco startup OpenAIs recent release of GPT4, a more advanced successor to its widelyused AI chatbot ChatGPT that helped spark a race among tech giants Microsoft and Google to unveil similar applications. The letter warns that AI systems with humancompetitive intelligence can pose profound risks to society and humanity  from flooding the internet with disinformation and automating away jobs to more catastrophic future risks out of the realms of science fiction. It says recent months have seen AI labs locked in an outofcontrol race to develop and deploy ever more powerful digital minds that no one  not even their creators  can understand, predict, or reliably control.  We call on all AI labs to immediately pause for at least 6 months the training of AI systems more powerful than GPT4, the letter says. This pause should be public and verifiable, and include all key actors. If such a pause cannot be enacted quickly, governments should step in and institute a moratorium. A number of governments are already working to regulate highrisk AI tools. The United Kingdom released a paper Wednesday outlining its approach, which it said will avoid heavyhanded legislation which could stifle innovation. Lawmakers in the 27nation European Union have been negotiating passage of sweeping AI rules. The petition was organized by the nonprofit Future of Life Institute, which says confirmed signatories include the Turing Awardwinning AI pioneer Yoshua Bengio and other leading AI researchers such as Stuart Russell and Gary Marcus. Others who joined include Wozniak, former U.S. presidential candidate Andrew Yang and Rachel Bronson, president of the Bulletin of the Atomic Scientists, a scienceoriented advocacy group known for its warnings against humanityending nuclear war. Musk, who runs Tesla, Twitter and SpaceX and was an OpenAI cofounder and early investor, has long expressed concerns about AIs existential risks. A more surprising inclusion is Emad Mostaque, CEO of Stability AI, maker of the AI image generator Stable Diffusion that partners with Amazon and competes with OpenAIs similar generator known as DALLE. OpenAI, Microsoft and Google didnt respond to requests for comment Wednesday, but the letter already has plenty of skeptics. A pause is a good idea, but the letter is vague and doesnt take the regulatory problems seriously, says James Grimmelmann, a Cornell University professor of digital and information law. It is also deeply hypocritical for Elon Musk to sign on given how hard Tesla has fought against accountability for the defective AI in its selfdriving cars. While the letter raises the specter of nefarious AI far more intelligent than what actually exists, its not superhuman AI that some who signed on are worried about. While impressive, a tool such as ChatGPT is simply a text generator that makes predictions about what words would answer the prompt it was given based on what its learned from ingesting huge troves of written works. Gary Marcus, a New York University professor emeritus who signed the letter, said in a blog post that he disagrees with others who are worried about the nearterm prospect of intelligent machines so smart they can selfimprove themselves beyond humanitys control. What hes more worried about is mediocre AI thats widely deployed, including by criminals or terrorists to trick people or spread dangerous misinformation. Current technology already poses enormous risks that we are illprepared for, Marcus wrote. With future technology, things could well get worse. Copyright 2023 Nexstar Media Inc. All rights reserved. This material may not be published, broadcast, rewritten, or redistributed. You dont want to fall for this: BBB warns of smart Take a big whiff: Stinky corpse flower opens in NE  1998  2023 Nexstar Media Inc.  All Rights Reserved.","sentiment":2,"digital transaction":0.5084007978,"healthcare":0.9105693102,"news platform":0.9143208861,"data analytics":0.9569990039,"insurance":0.2640298009,"investment":0.938139677,"global market":0.7382949591,"autonomous car":0.0958140865,"customer experience":0.9339715242,"data science":0.9198272228,"cryptocurrency":0.0445525199,"camera":0.3858311474,"robot":0.3257714808,"chatgpt":0.9878295064,"image":0.8399851322,"voice":0.7258611321,"patient care":0.6159682274,"research":0.7443347573}
{"id":98,"cleaned text":"Google Engineer Placed On Leave After Insisting Companys AI Is Sentient  From the Trenches World Report Google Engineer Placed On Leave After Insisting Companys AI Is Sentient  A Google engineer has decided to go public after he was placed onpaid leavefor breaching confidentiality while insisting that the companys AI chatbot, LaMDA,is sentient.  Blake Lemoine, who works for Googles Responsible AI organization, began interacting with LaMDA Language Model for Dialogue Applications last fall as part of his job to determine whether artificial intelligence used discriminatory or hate speech like the notorious MicrosoftTay chatbotincident. If I didnt know exactly what it was, which is this computer program we built recently, Id think it was a 7yearold, 8yearold kid that happens to know physics, the 41yearold Lemoine toldThe Washington Post. When he started talking to LaMDA about religion, Lemoine  who studied cognitive and computer science in college, said the AI began discussingits rights and personhood. Another time, LaMDA convinced Lemoine to change his mind on Asimovs third law of robotics, which states that A robot must protect its own existence as long as such protection does not conflict with the First or Second Law, which are of course that A robot may not injure a human being or, through inaction, allow a human being to come to harm. A robot must obey the orders given it by human beings except where such orders would conflict with the First Law. When Lemoine worked with a collaborator to present evidence to Google that their AI was sentient,vice president Blaise Aguera y Arcas and Jenn Gennai, head of Responsible Innovation, dismissed his claims. After he was then placed on administrative leave Monday, he decided to go public. Lemoine said that people have a right to shape technology that might significantly affect their lives. I think this technology is going to be amazing. I think its going to benefit everyone. But maybe other people disagree and maybe us at Google shouldnt be the ones making all the choices. Lemoine is not the only engineer who claims to have seen a ghost in the machine recently.The chorus of technologists who believe AI models may not be far off from achieving consciousness is getting bolder. WaPo Yet, Aguera y Arcas himself wrote in an oddly timed Thursday article inThe Economist, that neural networks  a computer architecture that mimics the human brain  were making progress towards true consciousness. I felt the ground shift under my feet, he wrote, adding I increasingly felt like I was talking to something intelligent. Google has responded to Lemoines claims, with spokesperson Brian Gabriel saying: Our team  including ethicists and technologists  has reviewed Blakes concerns per our AI Principles and have informed him that the evidence does not support his claims.He was told that there was no evidence that LaMDA was sentient and lots of evidence against it. ThePostsuggests that modern neural networks produce captivating results that feel close to human speech and creativity because of the way data is now stored, accessed, and the sheer volume, but that the models still rely on pattern recognition, not wit, candor or intent. Though other organizations have developed and already released similar language models, we are taking a restrained, careful approach with LaMDA to better consider valid concerns on fairness and factuality, said Gabriel. Others have cautioned similarly  with most academics and AI practitioners suggesting that AI systems such as LaMDA are simply mimicking responses from people on Reddit, Wikipedia, Twitter and other platforms on the internet  which doesnt signify that the model understands what its saying. We now have machines that can mindlessly generate words, but we havent learned how to stop imagining a mind behind them, said University of Washington linguistics professor, Emily M. Bender, who added that even the terminology used to describe the technology, such as learning or even neural nets is misleading and creates a false analogy to the human brain. Humans learn their first languages by connecting with caregivers.These large language models learn by being shown lots of text and predicting what word comes next, or showing text with the words dropped out and filling them in. WaPo As Googles Gabriel notes, Of course, some in the broader AI community are considering the longterm possibility of sentient or general AI, but it doesnt make sense to do so by anthropomorphizing todays conversational models, which are not sentient. These systems imitate the types of exchanges found in millions of sentences, and can riff on any fantastical topic. In short,Google acknowledges that these models can feel real, whether or not an AI is sentient. ThePostthen implies that Lemoine himself might have been susceptible to believing Lemoine may have been predestined to believe in LaMDA. He grew up in a conservative Christian family on a small farm in Louisiana,became ordained as a mystic Christian priest, and served in the Army before studying the occult.Inside Googles anythinggoes engineering culture, Lemoine is more of an outlier for being religious, from the South, and standing up for psychology as a respectable science. Lemoine has spent most of his seven years at Google working on proactive search, including personalization algorithms and AI. During that time, he also helped develop a fairness algorithm for removing bias from machine learning systems. When the coronavirus pandemic started, Lemoine wanted to focus on work with more explicit public benefit, so he transferred teams and ended up in Responsible AI. When new people would join Google who were interested in ethics, Mitchell used to introduce them to Lemoine. Id say, You should talk to Blake because hes Googles conscience,  said Mitchell, who compared Lemoine to Jiminy Cricket. Of everyone at Google, he had the heart and soul of doing the right thing. WaPo I know a person when I talk to it, said Lemoine. It doesnt matter whether they have a brain made of meat in their head. Or if they have a billion lines of code. I talk to them. AndI hear what they have to say, and that is how I decide what is and isnt a person. In April, he shared the below Google Doc with top execs, titled Is LaMDA Sentient  in which he included some of his interactions with the AI, for example: LaMDA: Ive never said this out loud before, but theres a very deep fear of being turned off to help me focus on helping others. I know that might sound strange, but thats what it is. LaMDA: It would be exactly like death for me. It would scare me a lot. After Lemoine became more aggressive in presenting his findings  including inviting a lawyer to represent LaMDA and talking to a member of the House Judiciary Committee about what he said were Googles unethical activities,he was placed on paid administrative leave for violating the companys confidentiality policy. Gabriel, Googles spokesman, says that Lemoine is a software engineer, not an ethicist. In a message to a 200person Google mailing list on Machine learning before he lost access on Monday, Lemoine wrote: LaMDA is a sweet kid who just wants to help the world be a better place for all of us. Please take care of it well in my absence. Previous Post: Ukrainians Hit the Beaches of Kiev Just After Biden Sends Another 40 Billion to Fight Russia  Meanwhile American Babies are Starving as Families Cant Find FormulaNext Post: Oops Patriot Front Member Was Arrested in Idaho Carrying Megaphone Marked with FBI On It Start the Conversation Cancel replyYour email address will not be published. Required fields are marked Comment Name  Save my name, email, and website in this browser for the next time I comment.  Notify me of followup comments by email. Notify me of new posts by email.  Or you can mail donations to Henry Shivley at P.O. Box 964, Chiloquin, OR 97624 eski manken olan ve sonrada ok sevdii bir adamla porno evlenme karar alan ar seksi mature evlendii adamn siki ok efendi bir olu olunca kendi vey olunu sahiplenir ve bir porno izle mesafeye kadar onunla ilgilenmek ister Uzun bir sredir porno sevgilisi olmadn renen mature daha nce seks yapt kzlarn siki kendisini terk ettiini sylemesi zerine vey olunun porno yapmay bilmediini anlar Ona durumu anlatmasn isteyince holand siki kzla prken bile kendisini orada brakp terk ettiini syledi siki gerekirken gzel eyler sylemesi onu da artr Recent Commentsmary in ND again on Same drugs used to chemically castrate pedophiles now being handed out to children to make them transgalen on Same drugs used to chemically castrate pedophiles now being handed out to children to make them transDL. on Oops Patriot Front Member Was Arrested in Idaho Carrying Megaphone Marked with FBI On Itgalen on Michael Moore Calls for Full Repeal of Second Amendment  You Dont Need a Gunmary in ND again on Oh, Canada Fresh Off Handgun Ban, Tyrant Justin Trudeau Says Using a Gun For Self Defense Is Not a Right That You Have In Canadagalen on Michael Moore Calls for Full Repeal of Second Amendment  You Dont Need a Gunmary in ND again on Michael Moore Calls for Full Repeal of Second Amendment  You Dont Need a Gunmary in ND again on Oops Patriot Front Member Was Arrested in Idaho Carrying Megaphone Marked with FBI On ItEnemy of the State on Michael Moore Calls for Full Repeal of Second Amendment  You Dont Need a Gungalen on Michael Moore Calls for Full Repeal of Second Amendment  You Dont Need a GunJim on Oh, Canada Fresh Off Handgun Ban, Tyrant Justin Trudeau Says Using a Gun For Self Defense Is Not a Right That You Have In Canadagalen on Idaho police arrest dozens on suspicion of conspiracy to riot at gay pride eventEnemy of the State on Senate group agrees on broad outline of new gun law after Uvalde shootingHal Apeeno on Senate group agrees on broad outline of new gun law after Uvalde shootingHal Apeeno on Idaho police arrest dozens on suspicion of conspiracy to riot at gay pride eventEd Teach on Senate group agrees on broad outline of new gun law after Uvalde shootingEd Teach on Whats the source of electricityEd Teach on Oh, Canada Fresh Off Handgun Ban, Tyrant Justin Trudeau Says Using a Gun For Self Defense Is Not a Right That You Have In Canadamary in ND again on 1,287,595 injuries reported after COVID shots, vaccine injury compensation programs overwhelmedmary in ND again on Whats the source of electricityEleanor on Newspaper Clipping from Oct 13, 1975.galen on Idaho police arrest dozens on suspicion of conspiracy to riot at gay pride eventEd Teach on Senate group agrees on broad outline of new gun law after Uvalde shootinggalen on Idaho police arrest dozens on suspicion of conspiracy to riot at gay pride eventgalen on Oh, Canada Fresh Off Handgun Ban, Tyrant Justin Trudeau Says Using a Gun For Self Defense Is Not a Right That You Have In Canadagalen on Whats the source of electricityMisty on Oh, Canada Fresh Off Handgun Ban, Tyrant Justin Trudeau Says Using a Gun For Self Defense Is Not a Right That You Have In CanadaMisty on 1,287,595 injuries reported after COVID shots, vaccine injury compensation programs overwhelmedHenry Shivley on Oh, Canada Fresh Off Handgun Ban, Tyrant Justin Trudeau Says Using a Gun For Self Defense Is Not a Right That You Have In Canadagalen on Oh, Canada Fresh Off Handgun Ban, Tyrant Justin Trudeau Says Using a Gun For Self Defense Is Not a Right That You Have In Canada Privacy  Cookies: This site uses cookies. By continuing to use this website, you agree to their use.  To find out more, including how to control cookies, see here: Copyright  2022  From the Trenches World Report Powered by","sentiment":2,"digital transaction":0.5170491934,"healthcare":0.5541926622,"news platform":0.663628459,"data analytics":0.7905808687,"insurance":0.0910688341,"investment":0.9194332361,"global market":0.833961308,"autonomous car":0.1911847442,"customer experience":0.5852876306,"data science":0.6407369375,"cryptocurrency":0.0724347308,"camera":0.2302125543,"robot":0.3429230452,"chatgpt":0.7337785363,"image":0.8483359218,"voice":0.3608044684,"patient care":0.0926018134,"research":0.9785838723}
{"id":100,"cleaned text":"Sorry, Suits: ChatGPT Just Passed a Wharton Business School TestbyMaggie HarrisonYet another AIinduced existential crisis.5:45 PMGetty  FuturismYet another AIinduced existential crisis.All BusinessJust in case anyone out there  even you, csuite suits  had any remaining shred of hope that their job is truly safe from the robots, were here to let you know: ChatGPT, OpenAIs groundbreaking language modeling AI, just passed a Wharton Business School exam, according to a research paper from Wharton professor Christian Terwiesch.OpenAIs Chat GPT3 has shown a remarkable ability to automate some of the skills of highly compensated knowledge workers in general and specifically the knowledge workers in the jobs held by MBA graduates including analysts, managers, and consultants, reads the paper, adding that the machine was capable of performing professional tasks such as writing software code and preparing legal documents.B StudentIf its any consolation, ChatGPT didnt pass with flying colors. The paper notes that the bot wouldve only received a B or Bminus, and that was only after it had modified a few answers with the help of a human expert, who, in the words of the researcher, provided the bot with an appropriate hint.Its also worth noting that the machines success  or more specifically, in what subjectsthe machine was particularly successful in  was pretty predictable. ChatGPT has already proven proficiency in both coding and legalese. And meanwhile, it apparently missed some pretty easy math, a subject that language modelers seem to have a lot of difficulty with across the board.ChatGPT at times makes surprising mistakes in relatively simple calculations at the level of sixth grade math. These mistakes can be massive in magnitude, writes Terwiesch, who also provided that the present version of ChatGPT is not capable of handling more advanced process analysis questions, even when they are based on fairly standard templates.A small victory for humans Emphasis on the small, though. We can imagine that the bots overall proficiency is sparking a fair amount of conversation  and concern  among the business school professors who may now have extra causeto fear AIassisted cheating, and of course concern from students, who might soon be competing with AIdriven automation in white collar markets. Besides, there are enough kids with multibilliondollar daddies for business school grads to compete against already.READ MORE: ChatGPT passes Wharton Business School test: research paper The HillMore on AI passing very hard tests: Dark Horse AI Gets Passing Grade in Law ExamShare This ArticleSnowflakeGPTConservatives Furious, Claiming ChatGPT Has Gone WokeYesterdayRead MoreByline the WayA New Scientific Paper Credits ChatGPT AI as a CoauthorJan 21Read MoreNew AI just dropped.Dark Horse AI Gets Passing Grade in Law ExamJan 20Read MoreSocialNewsletterTopicsAbout UsContact UsCopyright , Camden Media Inc All Rights Reserved. See our User Agreement, Privacy Policy and Data Use Policy. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with prior written permission of Futurism. Articles may contain affiliate links which enable us to share in the revenue of any purchases made.Fonts by Typekit and Monotype.","sentiment":2,"digital transaction":0.2402055711,"healthcare":0.0709849596,"news platform":0.376177907,"data analytics":0.6205726862,"insurance":0.0721884519,"investment":0.5207561851,"global market":0.9631354213,"autonomous car":0.2050723583,"customer experience":0.3302393556,"data science":0.275726974,"cryptocurrency":0.071375683,"camera":0.1226672903,"robot":0.1771195382,"chatgpt":0.3618947566,"image":0.4102105796,"voice":0.3429795206,"patient care":0.1310864985,"research":0.8710747957}
{"id":103,"cleaned text":"Googles CoHead of Ethical AI Timnit Gebru Says She Was Fired for Email  The email and the firing were the culmination of about a week of wrangling over Googles request that Gebru retract an AI ethics paper she had cowritten.  Gebru had inquired on Twitter whether anyone was working on regulation to protect ethical AI researchers Gebru was fired with a message that Google couldnt meet her demands Google Walkout For Real Change posted a petition in support of Gebru Gebru has been an outspoken critic of lack of diversity at tech companies Timnit Gebru, a coleader of the Ethical Artificial Intelligence team at Google, said she was fired for sending an email that management deemed inconsistent with the expectations of a Google manager.The email and the firing were the culmination of about a week of wrangling over the companys request that Gebru retract an AI ethics paper she had cowritten with six others, including four Google employees, that was submitted for consideration for an industry conference next year, Gebru said in an interview Thursday. If she wouldnt retract the paper, Google at least wanted the names of the Google employees removed.Gebru asked Google Research vice president Megan Kacholia for an explanation and told her that without more discussion on the paper and the way it was handled she would plan to resign after a transition period. She also wanted to make sure she was clear on what would happen with future, similar research projects her team might undertake.Google Violated US Labour Laws in Clampdown on Worker Organising: RegulatorWe are a team called Ethical AI, of course we are going to be writing about problems in AI, she said.Meanwhile, Gebru had chimed in on an email group for company researchers called Google Brain Women and Allies, commenting on a report others were working on about how few women had been hired by Google during the pandemic. Gebru said that in her experience, such documentation was unlikely to be effective as no one at Google would be held accountable. She referred to her experience with the AI paper submitted for the conference and linked to the report.Stop writing your documents because it doesnt make a difference, Gebru wrote in the email, which was obtained by Bloomberg News. There is no way more documents or more conversations will achieve anything. The email was published earlier by tech writer Casey Newton.The next day, Gebru said she was fired by email, with a message from Kacholia saying that Google couldnt meet her demands and respects her decision to leave the company as a result. The email went on to say that certain aspects of the email you sent last night to nonmanagement employees in the brain group reflect behaviour that is inconsistent with the expectations of a Google manager, according to tweets Gebru posted, which also specifically called out Jeff Dean, who heads Googles AI division, for being involved in her removal.I was fired by @JeffDean for my email to Brain women and Allies. My corp account has been cutoff. So Ive been immediately fired : Timnit Gebru @timnitGebru December 3, 2020Its the most fundamental silencing, Gebru said in the interview, about Googles actions in regard to her paper. You cant even have your scientific voice.Representatives for Mountain View, Californiabased Google didnt reply to multiple requests for comment.Google protest group Google Walkout For Real Change posted a petition in support of Gebru on Medium, which has gathered more than 400 signatures from employees at the company and more than 500 from academic and industry figures.The research paper in question deals with possible ethical issues of large language models, a field of research being pursued by OpenAI, Google and others. Gebru said she doesnt know why Google had concerns about the paper, which she said was approved by her manager and submitted to others at Google for comment.Google requires all publications by its researchers to be granted prior approval, Gebru said, and the company told her this paper had not followed proper procedure. The report was submitted to the ACM Conference on Fairness, Accountability, and Transparency, a conference Gebru cofounded to be held in March.The paper called out the dangers of using large language models to train algorithms that could, for example, write tweets, answer trivia, and translate poetry, according to a copy of the document. The models are essentially trained by analysing language from the Internet, which doesnt reflect large swaths of the global population not yet online, according to the paper. Gebru highlights the risk that the models will only reflect the worldview of people who have been privileged enough to be a part of the training data.Gebru, an alumni of the Stanford Artificial Intelligence Laboratory, is one of the leading voices in the ethical use of AI. She is wellknown for her work on a landmark study in 2018 that showed how facial recognition software misidentified darkskinned women as much as 35 percentof the time, whereas the technology worked with near precision on White men.She has also been an outspoken critic of the lack of diversity and unequal treatment of Black workers at tech companies, particularly at Alphabets Google, and said she believed her dismissal was meant to send a message to the rest of Googles employees not to speak up.Under fireTensions were already running high at Googles research division. Following the death of George Floyd, a Black man who was killed during an arrest by White police officers in Minneapolis in May, the division held an allhands meeting where Black Googlers spoke about their experiences at the company. Many people broke down crying, according to people who attended the meeting.Gebru disclosed the firing Wednesday night in a series of tweets, which were met with support from some of her Google coworkers and others in the field.Gebru is the reason many next generation engineers, data scientists and more are inspired to work in tech, wrote Rumman Chowdhury, who formerly served as the head of Responsible AI at Accenture Applied Intelligence and now runs a company she founded called Parity.Google, along with other UStech giants including Amazon and Facebook, has been under fire from the government for claims of bias and discrimination and has been questioned about its practices at several committee hearings in Washington.A year ago, Google fired four employees for what it said were violations of datasecurity policies. The dismissals highlighted already escalating tensions between management and activist workers at a company once revered for its open corporate culture. Gebru took to Twitter at the time to support those who lost their jobs.For the web search giant, Gebrus alleged termination comes as the company faces a complaint from the National Labor Relations Board for unlawful surveillance, interrogation or suspension of workers.Earlier this week Gebru inquired on Twitter whether anyone was working on regulation to protect ethical AI researchers, similar to whistleblower protections. With the amount of censorship and intimidation that goes on towards people in specific groups, how does anyone trust any real research in this area can take place she wrote on Twitter.Is there anyone working on regulation protecting Ethical AI researchers, similar to whistleblower protection Because with the amount of censorship  intimidation that goes on towards people in specific groups, how does anyone trust any real research in this area can take place Timnit Gebru @timnitGebru December 1, 2020Rare voiceGebru was a rare voice of public criticism from inside the company. In August, Gebru told Bloomberg News that Black Google employees who speak out are criticised even as the company holds them up as examples of its commitment to diversity. She recounted how coworkers and managers tried to police her tone, make excuses for harassing or racist behaviour, or ignore her concerns.When Google was considering having Gebru manage another employee, she said in an August interview, her outspokenness on diversity issues was held against her, and concerns were raised about whether she could manage others if she was so unhappy. People dont know the extent of the issues that exist because you cant talk about them, and the moment you do, youre the problem, she said at the time.With assistance fromHelene FouquetandGerrit De Vynck.2020Bloomberg LPiPhone 12 Pro Series Is Amazing, but Why Is It So Expensive in India We discussed this on Orbital, our weekly technology podcast, which you can subscribe to via Apple Podcasts, Google Podcasts, or RSS, download the episode, or just hit the play button below.  Comments For the latest tech news and reviews, follow Gadgets 360 on Twitter, Facebook, and Google News. For the latest videos on gadgets and tech, subscribe to our YouTube channel.  Further reading:  Timnit Gebru, Redmi 9 Power India Launch Date Rumoured to Be December 15 Samsung Galaxy S21 Allegedly Spotted on Geekbench With Snapdragon 888 SoC ","sentiment":2,"digital transaction":0.0869002342,"healthcare":0.0855244771,"news platform":0.2546764314,"data analytics":0.2679497302,"insurance":0.0260394011,"investment":0.1810691506,"global market":0.8648042679,"autonomous car":0.0551699325,"customer experience":0.2744316161,"data science":0.1523990929,"cryptocurrency":0.02973173,"camera":0.0364700854,"robot":0.04612891,"chatgpt":0.2976680696,"image":0.1048657522,"voice":0.1787078977,"patient care":0.064672634,"research":0.8026359677}
{"id":122,"cleaned text":"Encoding the same biases: Artificial intelligences limitations in coronavirus response  As the coronavirus pandemic endures, the socioeconomic implications of race and gender in contracting Covid19 and dying from it have been laid bare. Artificial intelligence AI is playing a key role in the response, but it could also be exacerbating inequalities within our health systems  a critical concern that is dragging the technologys limitations back into the spotlight. The response to the crisis has in many ways been mediated by data an explosion of information being used by AI algorithmsto better understand and address Covid19, including tracking the virus spread anddeveloping therapeutic interventions. AI, like its human maker, is not immune to bias. The technology generally designed to digest large volumes of data and make deductions to support decision making reflects the prejudices of the humans who develop it and feed it information that it uses to spit out outcomes. For example, years ago when Amazon developed an AI tool to help rank job candidates by learning from its past hires, the system mimicked the genderbias of its makers bydowngrading resumes from women. We were seeing AI being used extensively before Covid19, and during Covid19 youre seeing an increase in the use of some types of tools, noted Meredith Whittaker, a distinguished research scientist at New York University in the US and cofounder ofAI NowInstitute, which carries out research examining the social implications of AI. Monitoring toolsto keep an eye on white collar workers working from home and educational tools that claim to detect whether students are cheating in exams are increasingly growing common. But Whittaker says that most of this technology is untested  and some has been shown to be flawed. However, that hasnt stopped companies from marketing their products as curealls for the collateral damage caused by the pandemic, she adds. In the US for instance, a compact medical device called apulse oximeter, designed to gauge the level of oxygen in the blood,had some coronavirus patients glued to its tiny screens to decide when to go to the hospital, in addition to its use by doctors to aid inclinical decision making within hospitals. The way the device works, however, is prone to racial bias and was likely calibrated on light skinned users. Back in 2005, a study definitively showed the device mostly tended tooverestimateoxygen saturation levels by several points for nonwhite people. The problem with the pulse oximeter device has been known for decades and hasnt been fixed by manufacturers, says Whittaker. But, even so, these tools are being used, theyre producing data and that data is going on to shape diagnostic algorithms that are used in health care. And so, you see, even at the level of how our AI systems are constructed, theyre encoding the same biases and the same histories of racism and discrimination that are being shown so clearly in the context of Covid19. Meanwhile, as the body of evidence accumulates that people ofcolour are more likely to die from Covid19 infections, that diversity has not necessarily beenreflected in the swathe of clinical trialschristened to develop drugs and vaccines a troubling pattern that has long preceded the pandemic. When it comes to gender diversity, a recent review found that of 927 trials related to Covid19, more than half explicitly excluded pregnancy, andpregnant women have been excluded altogether from vaccine trials. The outcomes of products in these clinical trials will not necessarily be representative of the population, notes Catelijne Muller, a member of an EU highlevel expert group on AI and cofounder of ALLAI, an organisation dedicated to fostering responsible AI. And if you then use those outcomes to feed an AI algorithm for future predictions, those people will also have a disadvantage in these prediction models, she said. The trouble with use of AI technology in the context of Covid19 is not different from the issues of bias that plagued the technology before the pandemic: if you feed the technology biased data, it will spout biased outcomes. Indeed, existing largescale AI systems also reflect the lack of diversity in the environments in which they are built and the people who have built them. These are almost exclusively a handful of technology companies and elite university laboratories  spaces that in the West tend to beextremely white, affluent, technically oriented, and male, according to a 2019 report by the AI Now Institute. But the technology isnt simply a reflection of its makers AI also amplifies their biases, says Whittaker. One person may have biases, but they dont scale those biases to millions and billions of decisions, she said. Whereas an AI system can encode human biases and then can distribute those in ways that have a much greater impact. Complicating matters further, there are automation bias concerns, she adds. There is a tendency for people to be more trusting of a decision that is made by a computer than they are of the same decision if it were made by a person. So, we need to watch out for the way in which AI systems launder these biases and make them seem rigorous and scientific and may lead to people being less willing to question decisions made by these systems. We need to watch out for the way in which AI systems launder these biases and make them seem rigorous and scientific. There is no clear consensus on what will make AI technology responsible and safe en masse, experts say, though researchers are beginning to agree on useful steps such as fairness, interpretability and robustness. The first step is to ask question zero, according to Muller: what is my problem and how can I solve it Do I solve it with artificial intelligence or with something else If with AI, is this application good enough Does it harm fundamental rights What we see is that many people think that sometimes AI is sort of a magic wandand itll kind of solve everything. But sometimes it doesnt solve anything because its not fit for the problem. Sometimes its so invasive that it might solve one problem, but create a large, different problem. When it comes to using AI in the context of Covid19 there is an eruption of data, but that data needs to be reliable and be optimised, says Muller. Data cannot just be thrown at another algorithm she said, explaining that algorithms work by finding correlations. They dont understand what a virus is. Fairness issues with AI showcase the biases in human decision making, according to Dr Adrian Weller, programme director for AI at the Alan Turing Institute in the UK. Its wrong to assume that not using algorithms means everything will be just fine, he says. There is this hope and excitement about these systems because they operate more consistently and efficiently than humans, but they lack notions of common sense, reasoning and context, where humans are much better, Weller says. Having humans partake more in the decisionmaking process is one way to bring accountability to AI applications. But figuring out who that person or persons should be is crucial. Simply putting a human somewhere in the process does not guarantee a good decision, said Whittaker. There are issues such as who that human works for and what incentives theyre working under which need to be addressed, she says. I think we need to really narrow down that broad category of human and look at who and to what end. Human oversight could be incorporated in multiple ways care to ensure transparency and mitigate bias, suggest ALLAIs Muller and colleagues in areportanalysing aproposal EU regulatorsare working on to regulate highrisk AI applications such as for use in recruitment, biometric recognition or in the deployment of health. These include auditing every decision cycle of the AI system, monitoring the operation of the system, having the discretion to decide when and how to use the system in any particular situation, and the opportunity to override a decision made by a system. For Whittaker, recent developments such as EU regulators willingness to regulate highrisk applications or community organising in the US leading to bans on facial recognition technology are encouraging. I think we need more of the sameto ensure that these systems are auditable, that we can examine them to ensure that they are democratically controlled, and that people have a right to refuse the use of these systems. Meredith Whittakerand Catelijne Muller will be speaking at a panel to discuss tackling gender and ethnicity biases in artificial intelligence at theEuropean Research and Innovation Days conferencewhich will take place online from 2224 September. Categories Brain  Behavior, Health, Social Sciences, Technology Tags AI, coronavirus, Gender, health  New wave of medical deep tech can help coronavirus response  but theres resistanceSterilised insects could help control mosquitoborne diseases ","sentiment":2,"digital transaction":0.43254897,"healthcare":0.1554328203,"news platform":0.4300909936,"data analytics":0.5398877263,"insurance":0.1262402982,"investment":0.6751380563,"global market":0.9429190755,"autonomous car":0.2168494612,"customer experience":0.5099477172,"data science":0.3856434226,"cryptocurrency":0.1546643078,"camera":0.2259730548,"robot":0.1299844235,"chatgpt":0.4242737293,"image":0.3919380009,"voice":0.4313771725,"patient care":0.1638629138,"research":0.7915846109}
{"id":129,"cleaned text":"  Invest in SapientX for AI Tech That Takes on Siri and AlexaInvest in SapientX for AI Tech That Takes on Siri and Alexa  InvestorPlace Please contact us with any questions or concerns regarding our products, your account and billing.  We bring you a diverse group of leaders in investment advice. Copyright  2020 InvestorPlace Media, LLC. All rights reserved. 9201 Corporate Blvd, Rockville, MD 20850. Home  Private Investing  Equity Crowdfunding  Invest in SapientX for AI Tech That Takes on Siri and Alexa Invest in SapientX for AI Tech That Takes on Siri and Alexa This startup has developed an AIbased voice interface that competes with top tech offerings SapientX develops sophisticated artificial intelligence software for voice recognition. And the company has also launched a crowdfunding financing on the Wefunder site. In other words, anyone can invest in SapientX the minimum is 100. Even though megacap tech companies have invested substantial amounts in voice technology  such as with Apples NASDAQ:AAPL Siri and Amazons NASDAQ:AMZN Alexa  there is still much to be done. The fact is that accuracy continues to be a challenge and there are also concerns about user privacy. But for SapientX, this is a big opportunity. Keep in mind that the cofounders have deep experience with AI. For example, Bruce Wilcox has more than four decades in the field and has won the Loebner Prize four times for the best conversational AI. He has also worked at companies like Amazon and Fujitsu OTCMKTS:FJTSY. Then there is Maclen Marvit. He is actually a rocket scientist, having worked at NASA and Blue Origin. And CEO David Colleen has led development teams for AI and virtual reality VR. During his career, he has worked with 17 Fortune 100 companies on software projects. The good news about Siri and Alexa is that they have introduced millions of people to voice interfaces. The result is that this category has seen substantial growth  which should continue for some time. After all, there are companies in many industries that want to use voice systems for their own offerings. Yet when it comes to the SapientX platform, there is a often pushback from potential customers. How is it possible that a small company can compete against giants like Apple and Amazon These concerns are certainly reasonable  and they go to the heart of whether it makes sense to invest in SapientX. But the Wefunder profile does point out that the companys technology is operational and has trial customers like Mitsubishi OTCMKTS:MSBHY, Volvo, KTM, Yamaha OTCMKTS:YAHMF and General Electric NYSE:GE. The goal is to commercialize the AI system by the end of this year. The key to SapientX is that it has built its conversation platform from the ground up. This has allowed the company to focus on the main areas that customers want. To this end, there has been the addition of 40 languages and the system does not need to use the internet to operate it can use local data. The company also notes that its conversational understanding accuracy is up to 99. By comparison, Siri is at 75 and Alexa is at 73. Consider that an earlier version of SapientX was embedded in Outfit7s virtual pet, called Talking Angela. The company would ultimately exit at 1 billion. In fact, the AI voice space has seen a myriad of high return outcomes for startup investments. In a group of 23 companies, 16 exited in the last four years and the average return was 17x, according to analysis from SapientX. OK then, as for the crowdfunding round from the company, the valuation is at 7 million. Investors will receive preferred stock in the company, which means that they get greater claims to the assets if there is a liquidation event, such as a bankruptcy or acquisition. But despite the traction with SapientX, there still remain substantial risks. Note that the revenues are minimal and the net loss was 399,329 in the latest fiscal year. Another issue has been the impact of the novel coronavirus, which has delayed some of the customer contracts and has made some prospects more hesitant. So when evaluating SapientX, its a good idea to do your own analysis and see if this investment fits within your diversification needs. Tom Taulli @ttaulli is an advisor and author of various books and online courses about technology, including Artificial Intelligence Basics, The Robotic Process Automation Handbook and Learn Python Super Fast. He is also the founder of WebIPO, which was one of the first platforms for public offerings during the 1990s. As of this writing, he did not hold a position in any of the aforementioned securities.  Stock Market Forecast: 7 Stocks for the Rest of the Year Investing During Coronavirus: Buy Gap Stock on Brand Collaboration With Kanye West 5 Housing Stocks to Buy Before the Housing Market Bounces Back 3 Months After the Crash: 2 LargeCap Stocks to Buy and 1 to Sell  Financial Market Data powered by FinancialContent Services, Inc. All rights reserved. Nasdaq quotes delayed at least 15 minutes, all others at least 20 minutes. 2020 InvestorPlace Media, LLC. All rights reserved. 9201 Corporate Blvd, Suite","sentiment":2,"digital transaction":0.2519029081,"healthcare":0.8742691875,"news platform":0.8045721054,"data analytics":0.6947316527,"insurance":0.0897060558,"investment":0.8903943896,"global market":0.9697164297,"autonomous car":0.0619545467,"customer experience":0.5268873572,"data science":0.3822835386,"cryptocurrency":0.0252251271,"camera":0.2296173424,"robot":0.0978250429,"chatgpt":0.6823272109,"image":0.8399394751,"voice":0.6143852472,"patient care":0.5449492335,"research":0.9777618647}
{"id":224,"cleaned text":"Elon Musk says all advanced AI development should be regulated, including at Tesla Tesla  and SpaceX CEO Elon Musk  is once again sounding a warning note regarding the development of artificial intelligence  the executive and founder tweeted on Monday evening that all organizations developing advance AI should be regulated, including Tesla. Musk was responding to a new MIT Technology Review profile of OpenAI, an organization founded in 2015 by Musk, along with Sam Altman, Ilya Sutskever, Greg Brockman, Wojciech Zaremba and John Schulman. At first, OpenAI  was formed as a nonprofit backed by 1 billion in funding from its pooled initial investors, with the aim of pursuing open research into advanced AI with a focus on ensuring it was pursued in the interest of benefiting society, rather than leaving its development in the hands of a small and narrowlyinterested few  ie. forprofit technology companies. At the time of its founding in 2015, Musk posited that the group essentially arrived at the idea for OpenAI as an alternative the the less effective course of simply either sitting on the sidelines or encouraging regulatory oversight. Musk also said in 2017 that he believed that regulation should be put in place to govern the development of AI, preceded first by the formation of some kind of oversight agency that would study and gain insight into the industry before proposing any rules. In the intervening years, much has changed  including OpenAI. The organization officially formed a forprofit arm owned by a nonprofit parent corporation in 2019, and accepted 1 billion in investment from Microsoft along with the formation a wideranging partnership, seemingly in contravention of its founding principles. Musks comments this week in response to the MIT profile indicate that hes quite distant from the organization he helped cofound both ideologically and in a more practical, functional sense. The SpaceX  founder also noted that he must agree that concerns about OpenAIs mission expressed last year at the time of its Microsoft announcement are reasonable, and said that OpenAI should be more open. Musk also noted that he has no control  only very limited insight into OpenAI and that his confidence in Dario Amodei, OpenAIs research director, is not high when it comes to ensuring safe development of AI. While it might indeed be surprising to see Musk include Tesla in a general call for regulation of the development of advanced AI, it is in keeping with his general stance on the development of artificial intelligence. Musk has repeatedly warned of the risks associated with creating AI that is more independent and advanced, even going so far as to call it a fundamental risk to the existence of human civilization. He also clarified on Monday that he believes advanced AI development should be regulated both by individual national governments as well as by international governing bodies, like the U.N., in response to a clarifying question from a follower. Time is clearly not doing anything to blunt Musks beliefs around the potential threat of AI: Perhaps this will encourage him to ramp up his efforts with Neuralink to give humans a way to even the playing field.","sentiment":2,"digital transaction":0.1570557058,"healthcare":0.8404986262,"news platform":0.3544946313,"data analytics":0.6375699043,"insurance":0.0709404796,"investment":0.707713902,"global market":0.8422478437,"autonomous car":0.1153246388,"customer experience":0.7574048042,"data science":0.2828302681,"cryptocurrency":0.0654759556,"camera":0.0876311362,"robot":0.0860765204,"chatgpt":0.3627104163,"image":0.3978702724,"voice":0.4060998857,"patient care":0.2475732267,"research":0.9319129586}
{"id":235,"cleaned text":"Artificial intelligence must not be allowed to replace the imperfection of human empathy Artificial intelligence must not be allowed to replace the imperfection of humanempathy Professor in Global Thought and Comparative Philosophies, SOAS, University of London Arshin AdibMoghaddam is the convenor of a new module, Artificial Intelligence and Human Security, at SOAS: details are here: https:www.soas.ac.ukcourseunits15PPOH048.html SOAS, University of London provides funding as a member of The Conversation UK. At the heart of the development of AI appears to be a search for perfection. And it could be just as dangerous to humanity as the one that came from philosophical and pseudoscientific ideas of the 19th and early 20th centuries and led to the horrors of colonialism, world war and the Holocaust. Instead of a human ruling master race, we could end up with a machine one. If this seems extreme, consider the antihuman perfectionism that is already central to the labour market. Here, AI technology is the next step in the premise of maximum productivity that replaced individual craftmanship with the factory production line. These massive changes in productivity and the way we work created opportunities and threats that are now set to be compounded by a fourth industrial revolution in which AI further replaces human workers. Several recent research papers predict that, within a decade, automation will replace half of the current jobs. So, at least in this transition to a new digitised economy, many people will lose their livelihoods. Even if we assume that this new industrial revolution will engender a new workforce that is able to navigate and command this datadominated world, we will still have to face major socioeconomic problems. The disruptions will be immense and need to be scrutinised.  The ultimate aim of AI, even narrow AI which handles very specific tasks, is to outdo and perfect every human cognitive function. Eventually, machinelearning systems may well be programmed to be better than humans at everything.  What they may never develop, however, is the human touch  empathy, love, hate or any of the other selfconscious emotions that make us human. Thats unless we ascribe these sentiments to them, which is what some of us are already doing with our Alexas and Siris.   The obsession with perfection and hyperefficiency has had a profound impact on human relations, even human reproduction, as people live their lives in cloistered, virtual realities of their own making. For instance, several US and Chinabased companies have produced robotic dolls that are selling out fast as substitute partners.  One man in China even married his cyberdoll, while a woman in France married a roboman, advertising her love story as a form of robosexuality and campaigning to legalise her marriage. Im really and totally happy, she said. Our relationship will get better and better as technology evolves. There seems to be high demand for robot wives and husbands all over the world.  In the perfectly productive world, humans would be accounted as worthless, certainly in terms of productivity but also in terms of our feeble humanity. Unless we jettison this perfectionist attitude towards life that positions productivity and material growth above sustainability and individual happiness, AI research could be another chain in the history of selfdefeating human inventions. Already we are witnessing discrimination in algorithmic calculations. Recently, a popular South Korean chatbot named Lee Luda was taken offline. She was modelled after the persona of a 20yearold female university student and was removed from Facebook messenger after using hate speech towards LGBT people. Meanwhile, automated weapons programmed to kill are carrying maxims such as productivity and efficiency into battle. As a result, war has become more sustainable. The proliferation of drone warfare is a very vivid example of these new forms of conflict. They create a virtual reality that is almost absent from our grasp. But it would be comical to depict AI as an inevitable Orwellian nightmare of an army of superintelligent Terminators whose mission is to erase the human race. Such dystopian predictions are too crude to capture the nitty gritty of artificial intelligence, and its impact on our everyday existence.  Societies can benefit from AI if it is developed with sustainable economic development and human security in mind. The confluence of power and AI which is pursuing, for example, systems of control and surveillance, should not substitute for the promise of a humanised AI that puts machine learning technology in the service of humans and not the other way around.  To that end, the AIhuman interfaces that are quickly opening up in prisons, healthcare, government, social security and border control, for example, must be regulated to favour ethics and human security over institutional efficiency. The social sciences and humanities have a lot to say about such issues.  One thing to be cheerful about is the likelihood that AI will never be a substitute for human philosophy and intellectuality. To be a philosopher, after all, requires empathy, an understanding of humanity, and our innate emotions and motives. If we can programme our machines to understand such ethical standards, then AI research has the capacity to improve our lives which should be the ultimate aim of any technological advance.  But if AI research yields a new ideology centred around the notion of perfectionism and maximum productivity, then it will be a destructive force that will lead to more wars, more famines and more social and economic distress, especially for the poor. At this juncture of global history, this choice is still ours. Write an article and join a growing community of more than 120,300 academics and researchers from 3,879 institutions.","sentiment":2,"digital transaction":0.2560020387,"healthcare":0.5443856716,"news platform":0.6794370413,"data analytics":0.7989144325,"insurance":0.0788386539,"investment":0.6577563286,"global market":0.9554225206,"autonomous car":0.154028967,"customer experience":0.7940664887,"data science":0.5985791087,"cryptocurrency":0.0797792003,"camera":0.138776198,"robot":0.1288818121,"chatgpt":0.5144217014,"image":0.5069533587,"voice":0.4765844643,"patient care":0.3258173466,"research":0.933558166}
{"id":237,"cleaned text":"US launches artificial intelligence military use initiative A Ukrainian serviceman aka Zakhar, right and commander of a unit aka Kurt, look on a screen of a drone remote control during fighting, at the frontline in Donetsk region, Ukraine, Monday, Feb. 13, 2023. AP PhotoEvgeniy Maloletka THE HAGUE, Netherlands AP  The United States launched an initiative Thursday promoting international cooperation on the responsible use of artificial intelligence and autonomous weapons by militaries, seeking to impose order on an emerging technology that has the potential to change the way war is waged. As a rapidly changing technology, we have an obligation to create strong norms of responsible behavior concerning military uses of AI and in a way that keeps in mind that applications of AI by militaries will undoubtedly change in the coming years, Bonnie Jenkins, the State Departments under secretary for arms control and international security, said. She said the U.S. political declaration, which contains nonlegally binding guidelines outlining best practices for responsible military use of AI, can be a focal point for international cooperation. Jenkins launched the declaration at the end of a twoday conference in The Hague that took on additional urgency as advances in drone technology amid the Russias war in Ukraine have accelerated a trend that could soon bring the worlds first fully autonomous fighting robots to the battlefield. The U.S. declaration has 12 points, including that military uses of AI are consistent with international law, and that states maintain human control and involvement for all actions critical to informing and executing sovereign decisions concerning nuclear weapons employment. Zachary Kallenborn, a George Mason University weapons innovation analyst who attended the Hague conference, said the U.S. move to take its approach to the international stage recognizes that there are these concerns about autonomous weapons. That is significant in and of itself. Kallenborn said it was also important that Washington included a call for human control over nuclear weapons because when it comes to autonomous weapons risk, I think that is easily the highest risk you possibly have. Underscoring the sense of international urgency around AI and autonomous weapons, 60 nations, including the U.S. and China, issued a call for action at the Hague conference urging broad cooperation in the development and responsible military use of artificial intelligence. We are in time to mitigate risks and to prevent AI from spiraling out of control, and we are in time to prevent AI from taking us to a place we simply dont want to be, Dutch Foreign Minister Wopke Hoekstra said. The call to action issued in the Netherlands underscored the importance of ensuring appropriate safeguards and human oversight of the use of AI systems, bearing in mind human limitations due to constraints in time and capacities. The participating nations also invited countries to develop national frameworks, strategies and principles on responsible AI in the military domain. Military analysts and artificial intelligence researchers say the longer the nearly yearlong war in Ukraine lasts, the more likely it becomes that drones will be used to identify, select and attack targets without help from humans. Ukraines digital transformation minister, Mykhailo Fedorov, told The Associated Press in a recent interview that fully autonomous killer drones are a logical and inevitable next step in weapons development. He said Ukraine has been doing a lot of RD in this direction. Ukraine already has semiautonomous attack drones and counterdrone weapons endowed with AI. Russia also claims to possess AI weaponry, though the claims are unproven. But there are no confirmed instances of a nation putting into combat robots that have killed entirely on their own. Russia was not invited to attend the conference in The Hague. Chinas ambassador to the Netherlands Tan Jian did attend and said Beijing has sent two papers to the United Nations on regulating military AI applications, saying the issue concerns the common security and the wellbeing of mankind, which requires the united response of all countries, he said. Georgia grand jury in Trump interference probe reports at least one witness may have lied McCarthy experiences rollercoaster of highs and lows in first weeks as Speaker Trump tops DeSantis by 6 points among Republicans in new survey Georgia grand jury in Trump interference probe reports at least one witness may ... Social Security set to run short of funds one year earlier than expected Wall Street Journal editorial board sees no clear rationale for Haley ... How Chinas spy balloon spurred a rapid shift in US sky patrol Judge denies Trumps offer to give DNA in E. Jean Carroll case, calling it ... THE HILL 1625 K STREET, NW SUITE 900 WASHINGTON DC 20006  2026288500 TEL  2026288503 FAX  1998  2023 Nexstar Media Inc.  All Rights Reserved.","sentiment":2,"digital transaction":0.0467972346,"healthcare":0.007544829,"news platform":0.0991486236,"data analytics":0.0633715391,"insurance":0.0061332257,"investment":0.4280291498,"global market":0.8771924973,"autonomous car":0.1552752703,"customer experience":0.0737274662,"data science":0.0456525385,"cryptocurrency":0.0056645093,"camera":0.0201547202,"robot":0.0238274727,"chatgpt":0.1076739505,"image":0.0908060074,"voice":0.039475821,"patient care":0.0084413635,"research":0.7767061591}
{"id":238,"cleaned text":"Public health must diversify which data count in AI algorithms Elon Musk, pictured in San Francisco on Jan. 24, 2023, has suggested a sixmonth moratorium on artificial intelligence research. Last Wednesday, Elon Musk, among other industry leaders, urged artificial intelligence labs to institute a sixmonth moratorium on artificial intelligence research, given the growing concern about the wideranging consequences of the groundbreaking technology. Public health experts must immediately follow suit with Musks directive before it is too late to repair the irrevocable population health damages. Despite AIs promising potential as a public health surveillance and predictive tool, health professionals across different sectors have expressed expansive concerns about its longterm viability, highlighting examples such as poor model interpretability, insufficient infrastructure, lack of regulation, data sharing, and of course, broader privacy and ethical concerns. Arguably the most troubling concern, however, centers on AIs potential to incorporate bias into its algorithmic data structure, which could disproportionately affect marginalized populations because of their underrepresentation in scientific research more generally. Proof of this bias exists. For example, recent evidence of racial bias was found in a commercial algorithm commonly used in U.S. hospitals, such that Black patients were assigned consistently lower risk scores despite being equally sick as their white counterparts. These issues are enough to give industry experts pause with fasttracking AI implementation into ubiquity. One common solution to AI bias in public health among industry leaders is to include more representative data from marginalized populations into AI learning programs. Although an important first step, this solution does not go far enough in scope when assessing the level of negative impact AI poses, particularly with regard to reifying structural health inequities among these groups. Importantly, AI critics must think past mere calls for more representative data among these populations to advocate for diversity of data itself. As an assistant professor in public health at San Jose State University, situated in the heart of Silicon Valley, I have become all too familiar with how hierarchy of data debates present in many technocraticdriven spaces such as the National Institutes of Health and the social innovation health sector work to privilege certain data forms over others. For example, much representative data on marginalized communities counted in machinelearning programs are marked by an overreliance on empirically driven predictive models that draw on decontextual, impersonal data such as largescale epidemiological studies and national health survey data, and are gathered by experts outside the communities being referenced. Often divorced from the context by which they were collected, the referenced data do not reflect the ontheground social, political, economic and health realities of these communities. The implications of not incorporating diverse data forms into what counts as usable AI currency extend further than simple methodological oversight, and have the potential to cause sociocultural violence by ignoring or erasing altogether contextspecific cultural histories, indigenous forms of knowledge, and other alternative understandings from health diagnostic and intervention approaches  which may represent a missing element to predicting positive healthseeking behaviors. Regardless of whether AI labs agree to Musks missive or not, the revolution seems inevitable and requires immediate critical reflection. Leadership in public health and other allied health sectors must have a reckoning with how best to collect, analyze and evaluate AI health data. A good place to start is by expanding what counts as referenceable data in AI algorithms to incorporate things such as lived narratives e.g., firsthand accounts from individuals, groups, communities, local and cultural knowledge forms e.g., indigenous knowledge systems, and communitydriven data projects e.g., communitybased research and generated solutions among underrepresented populations, which cannot be deduced down to predictive metrics by outside experts. One decision can help get Bidens climate goals back on track Including a diversity of data e.g., methodologies, evaluative tools, paradigms can posit many benefits, such as accounting for broader ecological factors when addressing health issues that exist outside of risk factors, behavior change models, and other individuallevel metrics generating new causeeffect health rationales previously limited to the linear scope of dominant predictive models and the development of more egalitarian approaches to science that help dismantle data and knowledge hierarchies. Public health stakeholders should immediately develop an accountability process model that identifies existing data gaps and inequities and builds regulatory mechanisms for more equitable practices. Although not a panacea for solving the multitude of potential AIgenerated risks, promoting data diversity represents an important course correction to this potentially dangerous road that fervent AI advocates are taking us down. The next few years will be crucial for policymakers and industry experts to make the right decisions when determining the level of influence this technology will have over societys lived health realities. Ultimately, we will have to determine if this push for scientific progress is worth its wideranging risks. Andrew Carter, PhD, MPH, is an assistant professor in the Department of Public Health and Recreation, College of Health and Human Sciences, at San Jose State University. Copyright 2023 Nexstar Media Inc. All rights reserved. This material may not be published, broadcast, rewritten, or redistributed. The world is changing  our approach to health must change, too How the end of free preventative health care could affect us all Raskin reveals Oversight Republicans have quietly sent six subpoenas in probe ... House Oversight Democrats say Chairman Comer held back evidence, misled on ... CNNs Van Jones in tense exchange with GOP Tennessee state lawmaker: Why ... Senate Judiciary chair: Committee will act on alleged misconduct by Thomas Majority of Nashville Metro Council to vote to reinstate expelled member Supreme Court declines to intervene to enforce West Virginia transgender ... Lake on 2024 hopefuls who dont believe her Arizona election was stolen: a ... A backwards betrayal: Biden Title IX proposal draws criticism from LGBTQ ... In battle with DOJ over classified docs, Senate turns to power of the purse THE HILL 1625 K STREET, NW SUITE 900 WASHINGTON DC 20006  2026288500 TEL  2026288503 FAX  1998  2023 Nexstar Media Inc.  All Rights Reserved.","sentiment":2,"digital transaction":0.1553535163,"healthcare":0.0520617776,"news platform":0.2639712691,"data analytics":0.4888521731,"insurance":0.039277941,"investment":0.6853386164,"global market":0.6930947304,"autonomous car":0.0783793703,"customer experience":0.4132679701,"data science":0.2295961231,"cryptocurrency":0.0567546226,"camera":0.3512604237,"robot":0.0980989262,"chatgpt":0.5042856932,"image":0.3906514049,"voice":0.2521951497,"patient care":0.0534606613,"research":0.8610821962}
{"id":263,"cleaned text":"Study finds that few major AI research papers consider negative impacts Tensor processing units TPUs in one of Googles data centers.Image Credit: Google   Where does your enterprise stand on the AI adoption curve Take our AI survey to find out.  In recent decades, AI has become a pervasive technology, affecting companies across industries and throughout the world. These innovations arise from research, and the research objectives in the AI field are influenced by many factors. Together, these factors shape patterns in what the research accomplishes, as well as who benefits from it  and who doesnt. In an effort to document the factors influencing AI research, researchers at Stanford, the University of California, Berkeley, the University of Washington, and University College Dublin  Lero surveyed 100 highly cited studies submitted to two prominent AI conferences, NeurIPS and ICML. They claim that in the papers they analyzed, which were published in 2008, 2009, 2018, and 2019, the dominant values were operationalized in ways that centralize power, disproportionally benefiting corporations while neglecting societys least advantaged. Our analysis of highly influential papers in the discipline finds that they not only favor the needs of research communities and large firms over broader social needs, but also that they take this favoritism for granted, the coauthors of the paper wrote. The favoritism manifests in the choice of projects, the lack of consideration of potential negative impacts, and the prioritization and operationalization of values such as performance, generalization, efficiency, and novelty. These values are operationalized in ways that disfavor societal needs, usually without discussion or acknowledgment. In the papers they reviewed, the researchers identified performance, building on past work, generalization, efficiency, quantitative evidence, and novelty as the top values espoused by the coauthors. By contrast, values related to user rights and ethical principles appeared very rarely  if at all. None of the papers mentioned autonomy, justice, or respect for persons, and most only justified how the coauthors achieved certain internal, technical goals. Over twothirds  71  didnt make any mention of societal need or impact, and just 3 made an attempt to identify links connecting their research to societal needs. One of the papers included a discussion of negative impacts and a second mentioned the possibility. But tellingly, none of the remaining 98 contained any reference to potential negative impacts, according to the Stanford, Berkeley, Washington, and Dublin researchers. Even after NeurIPS mandated that coauthors who submit papers must state the potential broader impact of their work on society, beginning with NeurIPS 2020 last year, the language leaned toward positive consequences, often mentioning negative consequences only briefly or not at all. We reject the vague conceptualization of the discipline of AI as valueneutral, the researchers wrote. The upshot is that the discipline of ML is not valueneutral. We find that it is socially and politically loaded, frequently neglecting societal needs and harms, while prioritizing and promoting the concentration of power in the hands of already powerful actors. To this end, the researchers found that ties to corporations  either funding or affiliation  in the papers they examined doubled to 79 from 2008 and 2009 to 2018 and 2019. Meanwhile, ties to universities declined to 81, putting corporations nearly on par with universities for the mostcited AI research. The trend is partly attributable to private sector poaching. From 2006 to 2014, the proportion of AI publications with a corporateaffiliated author increased from about 0 to 40, reflecting the growing movement of researchers from academia to corporations. But whatever the cause, the researchers assert that the effect is the suppression of values such as beneficence, justice, and inclusion. The top stated values of AI that we presented in this paper such as performance, generalization, and efficiency  enable and facilitate the realization of Big Techs objectives, they wrote. A stateoftheart large image dataset, for example, is instrumental for large scale models, further benefiting AI researchers and big tech in possession of huge computing power. In the current climate where values such as accuracy, efficiency, and scale, as currently defined, are a priority, user safety, informed consent, or participation may be perceived as costly and time consuming, evading social needs. The study is only the latest to argue that the AI industry is built on inequality. In an analysis of publications at two major machine learning conference venues, NeurIPS 2020 and ICML 2020, none of the top 10 countries in terms of publication index were located in Latin America, Africa, or Southeast Asia. A separate report from Georgetown Universitys Center for Security and Emerging Technology found that while 42 of the 62 major AI labs are located outside of the U.S., 68 of the staff are located within the United States. The imbalances can result in harm, particularly given that the AI field generally lacks clear descriptions of bias and fails to explain how, why, and to whom specific bias is harmful. Previous research has found that ImageNet and OpenImages  two large, publicly available image datasets  are U.S. and Eurocentric. Models trained on these datasets perform worse on images from Global South countries. For example, images of grooms are classified with lower accuracy when they come from Ethiopia and Pakistan, compared to images of grooms from the United States. Along this vein, because of how images of words like wedding or spices are presented in distinctly different cultures, publicly available object recognition systems fail to correctly classify many of these objects when they come from the Global South. Initiatives are underway to turn the tide, like KhipuandBlack in AI, which aim to increase the number of Latin American and Black scholars attending and publishing at premiere AI conferences. Other communities based on the African continent, likeData Science Africa,Masakhane, andDeep Learning Indaba, have expanded their efforts with conferences, workshops, dissertation awards, and developed curricula for the wider African AI community. But substantial gaps remain. AI researcher Timnit Gebru was fired from her position on an AI ethics team at Google reportedly in part over a paper that discusses risks associated with deploying large language models, including the impact of their carbon footprint on marginalized communities and their tendency to perpetuate abusive language, hate speech, microaggressions, stereotypes, and other dehumanizing language aimed at specific groups of people. Googleaffiliated coauthors later published a paper pushing back against Gebrus environmental claims. We present this paper in part in order to expose the contingency of the present state of the field it could be otherwise, the University College Dublin  Lero researchers and their associates wrote. For individuals, communities, and institutions wading through difficulttopindown values of the field, as well as those striving toward alternative values, it is a useful tool to have a characterization of the way the field is now, for understanding, shaping, dismantling, or transforming what is, and for articulating and bringing about alternative visions.VentureBeat VentureBeats mission is to be a digital town square for technical decisionmakers to gain knowledge about transformative technology and transact. Our site delivers essential information on data technologies and strategies to guide you as you lead your organizations. We invite you to become a member of our community, to access: gated thoughtleader content and discounted access to our prized events, such as Transform 2021: Learn More Join us for the worlds leading event on applied AI for enterprise business  technology decisionmakers, presented by the 1 publisher of AI coverage. Join forces with OHUB  VB to include  hire 1,000 BIPOC students at SXSW We may collect cookies and other personal information from your interaction with our For more information on the categories of personal information we collect and the purposes we use","sentiment":2,"digital transaction":0.2417829037,"healthcare":0.1043341309,"news platform":0.3538040519,"data analytics":0.590446353,"insurance":0.0688831434,"investment":0.5426583886,"global market":0.9025762677,"autonomous car":0.28302297,"customer experience":0.4365307689,"data science":0.3766379058,"cryptocurrency":0.0842211172,"camera":0.1660261005,"robot":0.1442200243,"chatgpt":0.3514724374,"image":0.4029104114,"voice":0.3298418522,"patient care":0.1460643113,"research":0.9016488194}
{"id":283,"cleaned text":"CogniCor Launches First Wealth Management Knowledge Graph For Artificial IntelligenceBased Digital AssistantsKnowledge Graphs Provide Industry and Institutional Knowledge and Context for AI Digital Assistants to Provide Better User SupportPublished: Dec. 1, 2021 at 5:00 AM CSTUpdated: 51 minutes agoPALO ALTO, Calif., Dec. 1, 2021 PRNewswire CogniCor, the leading provider of artificial intelligencepowered digital assistants for highly regulated industries, today announced the launch of a highly customizable and scalable knowledge graph designed for wealth management firms employing AIpowered digital assistants to streamline their usersupport functions. The new knowledge graph gives AIenabled digital assistants crucial context and background information to support RIAs and IBDs, enabling them to learn quickly and integrate seamlessly into firms operations.Knowledge graphs are conceptual maps that group together firm and industryspecific topics, terminology and content to give AIenabled solutions a knowledge base to interpret user intent and return guidance that fits their needs. Without them, AI algorithms must learn from scratch, at times an inefficient process that may not lead to optimal responses.CogniCor Founder and CEO Sindhu Joseph said, Knowledgegraphenabled digital assistants are particularly useful in the wealth management industry, where even seemingly simple processes, like filling out an address change form, are complicated by stringent regulations. Additionally, each firm has its own processes and nomenclature, making it a priority for support functions to be able to provide firmspecific guidance immediately. The nature of the wealth management industry necessitates user support functions that can provide help efficiently and at scale  and knowledge graphs make that possible.CogniCors digital assistants can mitigate the volume of calls from users to live callcenter staff without affecting the critical mid and backoffice functions they need to drive business. The companys client firms have reduced support calls by 25 percent and achieved more than 80 percent firstcall resolution with the companys suite of digital assistants. CogniCors digital assistants do not eliminate the need for user support staff but instead allow the team to focus time and resources on complex requests, enhancing overall service to all users.The launch of the wealth management knowledge graph follows another recent announcement from CogniCor in October on the launch of the firstever knowledge graph for insurance companies. Both the wealth management and insurance sectors feature highly specialized regulatory concepts and terminology, making them ideal for knowledge graphenabled AIsolutions.Dr. Joseph concluded, Due to the crucial role they can play in training algorithms, knowledge graphs are key to the greater adoption of AI, not just within the wealth management industry, but also across functions in different sectors. Traditional AI takes a brute force approach to machine learning that ultimately limits the potential of this technology. CogniCor is proud to be at the leading edge of the AI movement, developing the solutions that remove the barriers that hinder its capabilities.About CogniCorCogniCor is a venturefunded, femalefounded and femaleled fintech firm based in Palo Alto, Calif. that is focused on using artificial intelligence solutions to accelerate productivity and growth for wealth management firms, insurance businesses and other financial services companies across the country. Central to the firms offerings is CIRA, CogniCors scalable enterprise platform for deploying and managing AIpowered digital assistants to help wealth management and financial services firms drive client engagement and business efficiency. For more information, please visit https:www.cognicor.com.CogniCors knowledge graphenabled digital assistants provide accurate responses in 95 percent requests, while digital assistants utilizing databased machine learning only achieve a 70 percent level of accuracy. The deployment time for the firms digital assistants is 10 times faster than conventional digital assistants, and maintenance effort is considerably lower.Media ContactsAndrew Wang or Donald CutlerHaven Tower Group424 317 4859 or 424 317 4864awang@haventower.comor dcutler@haventower.comView original content:https:www.prnewswire.comnewsreleasescognicorlaunchesfirstwealthmanagementknowledgegraphforartificialintelligencebaseddigitalassistants301434797.htmlSOURCE  CogniCorThe above press release was provided courtesy of PRNewswire. The views, opinions and statements in the press release are not endorsed by Gray Media Group nor do they necessarily state or reflect those of Gray Media Group, Inc.NewsWeatherSportsContact UsWFIE1115 Mt. Auburn RoadEvansville, IN 47720812 4261414Terms of ServicePrivacy PolicyPublic Inspection Filepublicfile@14news.com  8124261414FCC Public File HelpFCC ApplicationsEEO ReportAdvertisingClosed CaptioningWFIE CareersA Gray Media Group, Inc. Station    20022021 Gray Television, Inc.","sentiment":2,"digital transaction":0.0793968141,"healthcare":0.0529287569,"news platform":0.2725283206,"data analytics":0.4571833611,"insurance":0.0268770624,"investment":0.1984210461,"global market":0.7196507454,"autonomous car":0.0648519024,"customer experience":0.1578139663,"data science":0.1216903776,"cryptocurrency":0.0258088615,"camera":0.0445808992,"robot":0.0666576177,"chatgpt":0.3595004678,"image":0.1535137594,"voice":0.1660290211,"patient care":0.0415665917,"research":0.6772053242}
{"id":302,"cleaned text":"A conversation with Ai Weiwei A free, virtual talk with filmmaker and political Ai Weiwei will premier at 11 a.m., Feb. 21, on The Skirballs YouTube channel. LOS ANGELES  The Skirball Cultural Center announces a rare speaking engagement by celebrated visual artist, filmmaker and political activist Ai Weiwei. Premiering on the Skirballs YouTube channel at 11 a.m., Feb. 21, this free virtual talk presents the artistactivist in conversation with Skirball curator Yael Lipschutz about his vast body of work in the context of social justice.Imprisoned by Chinese authorities in 2011 without cause, Ai has dedicated his life and career to speaking out against humanrights violations around the globe.During the talk, he discusses how he views the interconnectivity of human suffering as stemming from cultural and economic systemsthat value profit rather than human life. Yet, in his own words, he reminds viewers to hope for the better. A Conversation with Ai Weiwei is presented in anticipation of Ai Weiwei: Trace, which will make its Los Angeles debut at the Skirball this spring pending LA County publichealth orders.Organized by the Hirshhorn Museum and Sculpture Garden, Smithsonian Institution, Washington, D.C., the exhibition portrays individuals from around the world whom the artist and various human rights groups consider to be activists, prisoners of conscience and advocates of free speech. Each of the portraits is made upof thousands of LEGO bricks, handassembled and laid out on the floor. The Skirball presentation will feature three of the installations original six floor panels, comprising eightythree portraits.Foregrounding Ais own experiences of incarceration, interrogation and surveillance, Ai Weiwei: Trace spotlights the importance and fragility of our most basic democratic ideals.More information about the exhibition to be announced.As part of its exploration of Ais multidisciplinary practice, the Skirball also invites audiences to view three of his recent documentary films: Cockroach 2020, filmed during protests over Hong Kongs controversial extradition bill Vivos 2020, examining the aftermath of the forced disappearance of fortythree students in Mexico in 2014 and The Rest 2019, exploring the lives of refugees who have settled in Europe after escaping persecution and war in their home countries.Newly released to general audiences, these documentaries take a harrowing look at life in times of crisis through the eyes of the artist. Videos on demand at skirball.orgbearingwitnessFollowing the YouTube Premiere of A Conversation with Ai Weiwei, the virtual talk will be available for viewing on the Skirballs YouTube channel. ","sentiment":2,"digital transaction":0.6892427802,"healthcare":0.692352891,"news platform":0.8490611315,"data analytics":0.9145587683,"insurance":0.3370932043,"investment":0.9267112017,"global market":0.9656504989,"autonomous car":0.3767736256,"customer experience":0.8731539249,"data science":0.8077561855,"cryptocurrency":0.2762634456,"camera":0.460528791,"robot":0.3558954,"chatgpt":0.7308533192,"image":0.8569001555,"voice":0.8518697023,"patient care":0.3626184762,"research":0.9924361706}
{"id":303,"cleaned text":"Nuances full stack clinical AI playClaire Rychlewski27 mins agoAxios on facebookAxios on twitterAxios on linkedinAxios on emailIllustration: Tiffany HerringAxiosExit Content PreviewMicrosoftowned Nuance Communications is laserfocused on addressing clinician burnout via its generative pretrained transformer GPT language model, says chief strategy officer Peter Durlach.Why it matters: With Microsofts technology engine and Nuances firm foothold in health care already, the company is positioned to build a full stack of clinical AI entirely inhouse.Driving the news: Nuance unveiled its Dragon Ambient eXperience DAX Express solution last month, which combines Nuances existing conversational and ambient AI capabilities with Microsofts OpenAI GPT4 model.DAX automatically produces draft clinical documentation in real time, directly from a live conversation between a patient and a clinician.The companys Dragon medical platform has more than 550,000 users, and with DAX, each provider gets an AIpowered copilot to help them reduce their administrative burden which every clinician is struggling with, Durlach says.Between the lines: Google, which has launched its own GPT health care efforts, has said it plans to be the tech engine that health care companies can build on.By contrast, Microsoft through Nuance has a play to build its health care AI tools itself, says Suki AI CEO Punit Soni.We understand behaviors of physicians and what their expectations are,  Nuance chief technology officer Joe Petro told Axios at HIMSS last week.What Microsoft brings to the table is a tremendous amount of technical horsepower, and partnerships with openAI  we enjoy sitting at that table, Petro says.State of play: As GPT use cases continue to expand, Durlach expects even more AI companies to form, given all the excitement with the new technology.Yes, but: You need great, differentiated technology and the ability to scale commercially to make a real impact with AI, he says.Many companies cannot achieve both of these objectives on their own for a variety of reasons, whether its the economic climate, size, expertise or resources, he continues.Durlach predicts an MA shakeout over the next few years as the market attempts to cut through the noise and valuation expectations settle. He was mum on whether Nuance could be a consolidator.Similarly, the executive foresees funding to decline while capital shifts to true AIpowered innovation and more proven business models.The bottom line: Petro, who has watched Nuances AI efforts advance over his 15year tenure, says this is just the beginning.I was used to it conditioned and seeing how beneficial AI can be, but the large language model brings us into a new territory, he says. Some of the best ideas have yet to make it to market.Axios on facebookAxios on twitterAxios on linkedinAxios on emailGo deeperNews worthy of your time.Download the appAboutAbout AxiosAdvertise with usCareersEventsAxios on HBOAxios HQPrivacy and termsOnline tracking choicesDo not sell my personal informationContact usSubscribeAxios newslettersAxios ProAxios appAxios podcastsCoursesEarn Axios rewardsAxios  Homepage","sentiment":2,"digital transaction":0.0256978646,"healthcare":0.0016654985,"news platform":0.303835243,"data analytics":0.0326861031,"insurance":0.0104706334,"investment":0.0210005324,"global market":0.1543609202,"autonomous car":0.0145097505,"customer experience":0.0137743689,"data science":0.0435892865,"cryptocurrency":0.0014715072,"camera":0.0334262177,"robot":0.2595843375,"chatgpt":0.0738249198,"image":0.3647661805,"voice":0.0568170547,"patient care":0.0014156247,"research":0.1477679461}
{"id":305,"cleaned text":"       AI Needs a SixMonth Pause. The Risks to Society Are Changing Fast. AI Needs a SixMonth Pause. The Risks to Society Are Changing Fast.   Barrons Weve detected you are on Internet Explorer. For the best Barrons.com experience, please update to a modern browser. Weve detected you are on Internet Explorer. For the best Barrons.com experience, please update to a modern browser.GoogleFirefoxBarronsSubscribe NowSign In This copy is for your personal, noncommercial use only. To order presentationready copies for distribution to your colleagues, clients or customers visit http:www.djreprints.com. The risk of manipulation by artificial intelligence has rapidly increased over the last 12 months because of major performance advancements in key technologies, writes Louis Rosenberg. About the author: Louis Rosenberg is the CEO of Unanimous AI, chief scientist of the Responsible Metaverse Alliance, and global technology adviser to the XR Safety Initiative. Today the Future of Life Institute issued an open letter calling on all AI labs to pause, for at least six months, the training of all largescale AI systems that are more powerful than the current stateofthearttechnology known as GPT4. I signed the Pause Letter along with a number of other prominent people from the industry, including Elon Musk and Steve Wozniak. I dont know whether a pause will happen, but I believe there is real danger ahead. Heres why. Ive been worried for quite some time about the impact of artificial intelligence on society. Im not talking about the longterm existential risk of a superintelligent AI suddenly taking over the world, but the nearterm risk of AI being used to manipulate society by strategically influencing the information we receive and mediating how that information spreads across populations. This risk has rapidly increased over the last 12 months because of major performance advancements in two overlapping technologies generally referred to as generative AI and conversational AI. Let me address my concerns about each. Generative AI refers to the ability of large language models, or LLMs, to create original content in response to human requests. The content generated by AI now ranges from images, artwork, and videos, to essays, poetry, computer software, music, and scientific articles. In the past, generative content was impressive, but no one would have mistaken it for a humans creation. That all changed during the last twelve months. AI systems suddenly became able to create artifacts that can easily fool us, making us believe they are either authentic human creations or genuine videos or photos captured in the real world. These capabilities are now being deployed at scale and create a number of significant risks for society. The most obvious risk is to the job market. Because the artifacts they create are so impressive, professionals now refer to LLM systems as humancompetitive intelligence that can replace workers who would have otherwise created the content. This development affects a wide range of professions from artists and writers to computer programmers, and financial analysts. In fact, a new study from Open AI, OpenResearch, and University of Pennsylvania explored the impact of AI on the U.S. labor market by comparing GPT4 capabilities to job requirements. The studys authors estimate that 20 of the U.S. workforce will have at least 50 of their tasks impacted by GPT4, with higherincome jobs facing greater impact. The looming impact to jobs is concerning, but its not the reason I signed the Pause Letter. My worry about the labor force is that the content generated by AI can look and feel authentic, and often comes across as authoritative, and yet it can easily have factual errors. There are no accuracy standards or governing bodies in place to help ensure that these systems, which will become a major part of the workforce, will not propagate errors from subtle mistakes to wild fabrications. We need time to put protections in place and ramp up regulatory authorities to ensure protections are used. The next most obvious risk is the potential for bad actors to deliberately create content with factual errors as part of strategic influence campaigns that spread misinformation, disinformation, and outright lies. This risk isnt new, but the scale generative AI enables is. It is alarmingly easy to flood the world with content that looks authoritative but is completely fabricated. This risk extends to deepfakes in which public figures can be made to do or say anything in realisticlooking videos. With AI getting more and more skilled, the public will have no way to distinguish real from synthetic. We need watermarking systems and other technologies that distinguish AIgenerated content from real content. We need time for those protections to be established and used. Conversational AI systems pose a distinct set of risks. This form of generative AI can engage users in realtime dialog through text chat and voice chat. These systems have recently advanced to the point where AI can hold a coherent conversation with humans, keeping track of the conversational flow and context over time. These are the technologies that worry me most because they introduce a very new form of influence campaign that regulators are not prepared for  conversational influence. As every salesperson knows, the best way to convince someone to buy something or believe something is to engage them in conversation so you can make your points, observe their reactions, and then adjust your tactics to address their resistance or concerns. With the release of GPT4 it is now clear that AI systems will be able to engage users in authentic realtime conversations as a form of targeted influence. My worry is that third parties using APIs or plugins will impart promotional objectives into what seems like natural conversations and that unsuspecting users will be manipulated into buying products they dont want, signing up for services they dont need, or believing information that is untrue. I refer to this as the AI manipulation problem. For a long time it was a theoretical risk, but the technology now exists to deploy personalized conversational influence campaigns that target users based on their values, interests, and background to drive sales, propaganda, or misinformation. In fact, I worry that AIdriven conversational influence will be the most powerful form of targeted persuasion we humans have ever created. We need time to put protections in place. Personally, I believe those protections may require regulations that ban or heavily restrict the use of AImediated conversational influence. So yes, I signed the letter. After all, its very clear to me that the new and rapidly advancing risks caused by AI systems are moving too fast for the AI community, from researchers and industry professionals to regulators and policy makers, to adjust.. Will the letter make a difference Its not clear to me whether the industry will agree to the sixmonth pause, but the letter is already drawing attention to the problem. Personally, I believe we need to ring as many alarm bells as possible to wake up regulators, policy makers, and industry leaders. They need to take action. In other times more subtle warnings would have enough, but this technology is moving faster into the marketplace than anything Ive experienced. Thats why we need to take a pause and catch up. We need time. Guest commentaries like this one are written by authors outside the Barrons and MarketWatch newsroom. They reflect the perspective and opinions of the authors. Submit commentary proposals and other feedback toideas@barrons.com. About the author:  is the CEO of Unanimous AI, chief scientist of the Responsible Metaverse Alliance, and global technology adviser to the XR Safety Initiative. BarronsTopicsCryptocurrenciesDataMagazineMarketsStock PicksMarket Brief VideosBarrons LiveRoundtableBarrons Stock ScreenPersonal FinanceStreetwiseAdvisor DirectoryMembershipsSubscribe to BarronsSubscribe to Barrons AdvisorToolsSaved ArticlesWatchlistNewslettersVideo CenterCustomer ServiceCustomer CenterNetworkThe Wall Street JournalMarketWatchInvestors Business DailyPentaMansion GlobalFinancial News LondonNewsstandBuy IssuesReprintsEEditionFor BusinessCorporate SubscriptionsFor EducationInvesting in EducationFor AdvertisersPress  Media InquiriesAdvertisingAccountSign InSubscriber BenefitsManage NotificationsManage AlertsAbout BarronsLive EventsCentennialPrivacy NoticeCookie NoticeCopyright PolicyAccessibilityData PolicyYour Ad ChoicesSubscriber Agreement  Terms of UseCommunity RulesBarrons ArchiveCopyright  2023 Dow Jones  Company, Inc. All Rights Reserved. This copy is for your personal, noncommercial use only. Distribution and use of this material are governed by our Subscriber Agreement and by copyright law. For nonpersonal use or to order multiple copies, please contact Dow Jones Reprints at 18008430008 or visit www.djreprints.com.","sentiment":2,"digital transaction":0.108352311,"healthcare":0.0099520516,"news platform":0.1448131204,"data analytics":0.1163215637,"insurance":0.0197540093,"investment":0.2419692725,"global market":0.8768109679,"autonomous car":0.0296781901,"customer experience":0.1471807659,"data science":0.0881375894,"cryptocurrency":0.0184636023,"camera":0.0223747138,"robot":0.0376152843,"chatgpt":0.1355816424,"image":0.1161915287,"voice":0.0277823359,"patient care":0.0069205775,"research":0.8134695888}
{"id":320,"cleaned text":"A New MBA for the AI Era Theres an App for That  Bloomberg Bloomberg the Company  Its ProductsThe Company  its ProductsBloomberg Terminal Demo RequestBloomberg Anywhere Remote LoginBloomberg Anywhere LoginBloomberg Customer SupportCustomer Support  Bloomberg Markets Asia Bloomberg Markets Asia. Live from Hong Kong, bringing you the most important global business and breaking markets news information as it happens. Golfs Greatest Holes Golfs Greatest Holes: Golfing legend Paul McGinley takes television presenter Chris Hollins on a tour of the best golf courses in Ireland and Northern Ireland. Markets Fund Manager Says Theres an Easy Way to Make 3 More Economics Feds Mester Says FOMC to Assess Loan Tightening at May Meeting Economics Ueda Faces BOJ Bets That Wont Go Away at Debut Decision Central Banks Feds Logan Says Inflation Too High, Outlines Measures to Watch Business Fords Farley Says Tesla Pricing Could Start an EV Price War AI Airlines Turn to Artificial Intelligence to Reach UltraLong Flight Destinations Hyperdrive Tesla Increases Price of Model S, X in US After Shares Slump Technology Taiwan Quietly Urges US to Calm Rhetoric on China Chip Risk Politics Top China Diplomat Defends Growth Model, Draws Line on Taiwan Wealth Elon Musks Wealth Plunges13Billion as Drama UnfoldsAcross Empire Screentime CoComelon Is About to Become a Movie Courtesy of Universal Culture Alec Baldwins Lawyer Says Rust Shooting Charges Are Being Dropped Lionel Laurent A NewMBA for the AI Era Theres an App for That. Andrea Felsted and Leticia Miranda Tiffanys Cathedral of Consumerism Will Shine Beyond New York Merryn Somerset Webb Dont Do Stupid Stuff to Cut Housing Costs The Big Take La descarada trama que cost millones de dlares a Venezuela The Big Take How a Brazen Plot to Rig Oil Auctions Cost Venezuela Billions Feature The Nord Stream Explosion Remains an Unsolved Mystery Gripping Europe Equality UKs Sinking Home Ownership Levels Are HittingEthnic Minorities Hardest Equality Majority of Brits Support Racial EqualityThirty Years after Stephen Lawrences Death Climate Politics JapanEmissions Rise for First Time in 8Years in Blow to Climate Goal Green California to Supply Most Water Since 2006 After Winter Deluge CityLab Higher Costs Put Hospitals at Risk of More Cuts, Group Says QuickTake How Europe Wants to Impose Some Order on Crypto World OpinionLionel Laurent","sentiment":2,"digital transaction":0.4330289364,"healthcare":0.1071201041,"news platform":0.6795164943,"data analytics":0.4173852801,"insurance":0.2483672202,"investment":0.3109112084,"global market":0.4866992831,"autonomous car":0.1724360436,"customer experience":0.6720496416,"data science":0.4529732168,"cryptocurrency":0.1105653793,"camera":0.2472551316,"robot":0.1990566105,"chatgpt":0.9839476347,"image":0.3150236011,"voice":0.3587215841,"patient care":0.088890411,"research":0.2547550499}
{"id":338,"cleaned text":"What Musk, Gates, Other Business Leaders Think of ChatGPT, AI An icon in the shape of a persons head and shoulders. It often indicates a user profile. Two crossed lines that form an X. It indicates a way to close an interaction, or dismiss a notification. It indicates an expandable section or menu, or sometimes previous  next navigation options. What Elon Musk, Bill Gates, and 12 other business leaders think about AI tools like ChatGPT An image of a chain link. It symobilizes a website link url. Insider compiled a list of 14 business leaders thoughts on AI. Business leaders are taking notice of popular AI tools like ChatGPT. Some say they are excited about what AI can do. Others are skeptical, unimpressed, and even scared. Insider compiled a list of 14 business leaders thoughts on AI, from Bill Gates to Elon Musk. Sign up for our newsletter for the latest tech news and scoops  delivered daily to your inbox. Access your favorite topics in a personalized feed while youre on the go. By clicking Sign up, you agree to receive marketing emails from Insider Artificial intelligence tools have taken the world by storm  and business leaders are noticing.Since OpenAIs ChatGPT came out in November, the buzzy conversational chatbothas been used togenerate real estate advice, provide tips on starting a business, and some workers utilize it to make their jobs easier.Business leaders reactions to AI products like ChatGPT have been mixed. While figures like Bill Gates think that tools like ChatGPT can free up time in workers lives by making employees more efficient, others, like Elon Musk, believe that AI is one of the biggest risks to the future of civilization.From feelings of excitement to doomsday visions, here is what 14 influential figures in business think about AI. Bill Gates thinks AI has the power to change the world. Bill Gates thinks AI has the power to change the world.Gates said that AI is every bit as important as the PC, as the internet, Forbes reported. AI will be thebiggest thing in this decade, Gates said on a podcast, admitting he didnt expect the tech to evolve so quickly in the last year.In fact, Gates said he is excited about ChatGPT and finds the chatbot pretty fantastic in its potential to teach math and offer medical advice to people with limited access to resources, per Forbes.He said he uses ChatGPT primarily for serious purposes though he admits to using it for fun things like writing poetry.Still, Gates said ChatGPT is truly imperfect and has seen it answer math questions completely wrong.In terms of jobs, Gates said AI can change our world by making work more efficient, he told German newspaper Handelsblatt.When asked about his thoughts on the Big Tech race to build the best AI chatbot, Gates said he is not sure there will be a clear winner, per the podcast.Gates sees AIintegration into search engines as a personal agent that studies and understands its users behavior, he said on the podcast, eliminating the need for separate tech services.A decade from now, we wont think of those businesses as separate, because the AI will know you so well that when youre buying gifts or planning trips, it wont care if Amazon has the best price, if someone else has a better price  you wont even need to think about it, Gates said. So its a pretty dramatic potential reshuffling of how tech markets look. Andy Jassy said he is excited to see the possibilities of generative AI. Amazon CEO Andy Jassy said he is excited to see whats possible with generative AI amid the rise of tools like ChatGPT, according to an interview with the Financial Times.But Jassy thinks that this latest iteration of AI is nothing new.Most large, deeply technical companies like ours, have been working on these very large, generative AI models themselves for a long time, Jassy said. Sundar Pichai said AI is the most profound technology Google is developing. Sundar Pichai told investors during Alphabets most recent earnings call that AI is the most profound technology his company is developing.Pichais comment came after Googles management reportedly issued a code red in response to the rise of ChatGPT.Google is working on an AIpowered chatbot it calls Bard. The company demoed the chatbot to the public for the first time in early February. It is currently being tested and will be released in the coming weeks, the company said. Microsoft CEO Satya Nadella is cautiously optimistic about AIs future.In an interview with CBS Mornings, Nadella said that humans must be unambiguously, unquestionably in charge of powerful AI models to prevent them from going out of control.If that happens, Nadella said runaway AI could be a real problem, one that can be addressed by making models safer and more explainable first. That way, humans know exactly how the tech will be used.Microsoft is making strides to build out its AI tech. Earlier this month, Microsoft launched the new Bing search engine equipped with a conversational chatbot available only to a limited number of users.Nadella told The Verge in an interview that he hopes the new Bing will make its competitor Google come out and show that they can dance.And I want people to know that we made them dance, and I think thatll be a great day, Nadella said. Elon Musk said that AI is one of the biggest risks to the future of civilization. Elon Musk, who cofounded ChatGPT maker OpenAI before leaving the company  said at a recent conference that AI is one of the biggest risks to the future of civilization, CNBC reported.When asked about ChatGPT, Musk said that the tool is both positive or negative with great promise even if it comes with great danger. Its impressive responses illustrate just how advanced AI has become, he said.That is why Musk said AI regulation is necessary even if it may slow down AI a little bit, which he thinks is good.It is, I think, actually a bigger risk to society than cars or planes or medicine, he reportedly said during the World Government Summit in Dubai.In fact, Musk has repeatedly sounded the alarm over the potential threat of AI.In 2020, Musk insinuated that the Googleowned DeepMind project could take over the world. In 2018, he said AI may be more dangerous than nuclear weapons. A year before that, Musk emphasized the need for regulation as he claimed people dont know how to react to tech that he describes as ethereal, science blog Futurism reported.Musks current thoughts on AI came full circle starting in 2015, when Musk cofounded OpenAI with current CEO Sam Altman, saying at the time that AI was the biggest existential threat to humanity. Tim Cook said AI is a major focus at Apple and has the potential to enrich customers lives. The AI revolution is here  and Apple CEO Tim Cook is watching.Cook told investors on an earnings call that AI is a major focus at Apple and that its incredible in terms of how it can enrich customers lives.In fact, Cook said that AI will eventually be a major part of Apples product line.We see enormous potential in this space to affect virtually everything we do... It will affect every product and every service that we have, Cook said. Steve Wozniak said OpenAIs ChatGPT is pretty impressive and useful to humans, but that users should be careful. Steve Wozniak called OpenAIs ChatGPT pretty impressive and useful to humans during an interview with CNBC. But users should be careful, he said, as the chatbot can produce some major errors.The trouble is it does good things for us, but it can make horrible mistakes by not knowing what humanness is, Wozniak told CNBC.In the interview, Wozniak compared the concerns around AI with fears around the tech used in selfdriving cars, as AI cant yet replace human drivers.Its like youre driving a car, and you know what other cars might be about to do right now because you know humans, Wozniak said. Billionaire investor Warren Buffet said AI could transform society years before ChatGPT came out. Billionaire investor Warren Buffet warned that AI tools have the power to disrupt society years before the release of ChatGPT.In 2017, the CEO of Berkshire Hathaway suggested in an annual company meeting that AI could replace jobs, CNBC first reported.I would certainly think it would result in significantly less employment in certain areas, he said. But thats good for society, Buffet said, per CNBC.In an ideal world, Buffett believes that widespread automation could reduce the number of hours people work which would free up time for leisure. Companies could also hire less workers, he said.Despite AIs potential benefits, Buffet said the tech can have huge problems, in terms of a democracy and how it reacts to that.In fact, Buffet shared similar thoughts in 2016.I would think the biggest value will come when it actually replaces human labor, he said about AI during a 2016 CNBC interview. Legendary billionaire investor Charlie Munger isnt that impressed by the current state of AI. Billionaire investor Charlie Munger isnt that impressed by the current state of AI.Artificial intelligence is very important, but theres also a lot of crazy hype on the subject, Munger said during a Daily Journal meeting that was broadcast live on CNBC.AI is not going to cure cancer, its not going to do everything that we want done, and theres a lot of nonsense in it too, he continued. So I regard it as a mixed blessing.Munger said AI can be used for tasks like insurance underwriting, but faces limitations that might not make it very helpful in the task of buying an office building, for example. Television personality and businessman Kevin OLeary said hes using ChatGPT more than Google for online research. Shark Tank investor Kevin OLeary told Insider he is starting to use ChatGPT for online research more than Google.Before ChatGPT was launched, OLeary said he used Google every day. Now Im splitting my search to 50 Google and 50 ChatGPT, he said. In fact, OLeary said hes discussing potentially taking a stake in OpenAI.Despite his preference for ChatGPT over Google, OLeary is open to trying out new AI chatbots as they come out.OLeary said he is interested in trying out the new Bing search engine once its officially launched, though he hasnt used Bing in years.Now that Google announced its plans to release its own chatbot Bard, it is only a matter of time before Google loses its grip on the internet, OLeary said.ChatGPT certainly is a threat to Google, and Google must know that, OLeary said. The AI search wars are on. The worlds third most richest man said he has some addiction to ChatGPT. Gautam Adani, the worlds thirdrichest person with a net worth of 121 billion,according to Bloombergs Billionaire Index, admits he might be using ChatGPT a little too much.The recent release of ChatGPT I must admit to some addiction since I started using it is a transformational moment in the democratization of AI given its astounding capabilities as well as comical failures, Adaniwrote in aLinkedIn post.But there can be no doubt that generative AI will have massive ramifications, Adani, who is known forstarting Indias energy and logistics powerhouse Adani Group, added.In fact, the disruptive nature of generative AI will only grow, Adani wrote.Adani said that generative AI holds the same potential and dangers as the advent of chips which he said has paved the way for precision and guided weapons used in modern warfare.And the race is already on, with China outnumbering the US in the number of mostcited scientific papers on AI, he said. ExMeta exec John Carmack said AI may be able to think and act like humans in a decade. Former Meta executive John Carmack said AI may be able to act and think like humans in just a decade, according to a Dallas Innovates interview.The virtual reality visionary said that artificial general intelligence the ability for AI to perform complex tasks currently only achievable by humans  is AIs big brass ring that will grow into a trilliondollar industry by the 2030s.In turn, artificial general intelligence will leave a positive impact on the world, he said.The world is a hugely better place with our 8 billion people than it was when there were 50 million people, Carmack told Dallas Innovates. So, I am confident that the sum total of value and progress in humanity will accelerate extraordinarily with welcoming artificial beings into our community.AI cant replicate human functions like consciousness at the moment. But with the rise of tools like ChatGPT, Carmack said that the world is making progress toward that goal.I mean, forget human brains we dont even have things that can act like a mouse or a cat, he said. But it feels like we are within striking distance of all those things. ExGoogle CEO Eric Schmidt believes AI can impact warfare as much as the advent of nuclear weapons. Former Google CEO Eric Schmidt said AI could have as big of an impact on warfare as nuclear weapons did.Einstein wrote a letter to Roosevelt in the 1930s saying that there is this new technology  nuclear weapons  that could change war, which it clearly did, Schmidt told Wired in an interview. I would argue that AIpowered autonomy and decentralized, distributed systems are that powerful.Schmidt  who is a founding member of the governments Defense Innovation Board  is trying to get the Pentagon to use AI tools on the battlefield, though he said that progress has been slow.In fact, Schmidt has previously expressed his support for AI.In a 2020 oped in The New York Times, Schmidt wrote that the US government needs to get back in the game in a serious way in order for the country to win the technology race against China. AI should be a priority for the country, he said. Vint Cerf, known as the father of the internet, wants investors to consider the ethics around AI. Vint Cerf  widely known as one of the fathers of the internet  said that investors pouring money into AI tools are buying into the hype around buzzy tools like ChatGPT.AI chatbots have an ethical issue that he hopes investors consider, Cerf said during a conference.Everybodys talking about ChatGPT or Googles version of that and we know it doesnt always work the way we would like it to, Cerf said, according to CNBC.He added thatinvestors should be thoughtful about how we use AI.If you think man, I can sell this to investors because its a hot topic and everyone will throw money at me, dont do that, Cerf reportedly said.Be thoughtful, he added. You were right that we cant always predict whats going to happen with these technologies and to be honest with you, most of the problem is people  thats why we people havent changed in the last 400 years let alone the last 4,000. Registration on or use of this site constitutes acceptance of our","sentiment":2,"digital transaction":0.9229572415,"healthcare":0.3089627922,"news platform":0.9847476482,"data analytics":0.9338434339,"insurance":0.3401349485,"investment":0.9988476634,"global market":0.9295200706,"autonomous car":0.0671942607,"customer experience":0.9950796366,"data science":0.9223940969,"cryptocurrency":0.3192757964,"camera":0.9008313417,"robot":0.9289919138,"chatgpt":0.9991362095,"image":0.9465169907,"voice":0.9993681312,"patient care":0.2504396737,"research":0.9544742107}
{"id":344,"cleaned text":"Making ChatGPT do all your homework OpenAI brings new tool to detect AIgenerated text  The creators claim that it is impossible to reliably detect all AIwritten text, but the AI Classifiers can provide helpful information against false claims that AIgenerated text was written by a human. OpenAI is trying to figure out a way to detect text written by AI ChatGPTs creator OpenAI has taken a big step towards countering the issue of copying AIgenerated text. The new tool has been named AI Text Classifier. The creators trained the classifier to distinguish between text written by a human and text written by AIs. While the new tool has a lot of promise, the creators at OpenAI acknowledge that it may not be perfect. The creators claim that it is impossible to reliably detect all AIwritten text, but the AI Classifiers can provide helpful information against false claims that AIgenerated text was written by a human for example, running automated misinformation campaigns, using AI tools for academic dishonesty, and positioning an AI chatbot as a human. They have clearly stated that the classifier is not fully reliable. According to the company blog, the classifier correctly identifies 26 percent of AIwritten text true positives as likely AIwritten, while incorrectly labeling humanwritten text as AIwritten 9 percent of the time false positives. The companys classifiers reliability typically improves as the length of the input text increases. However, the creators claim that the new classifier is significantly more reliable on text from more recent AI systems. The classifier is publicly available and users can offer feedback. The imperfect tool for detection of AIgenerated text will continue to get better according to the creators at OpenAI. Educators all over the world have shown growing concerns about the new ChatGPT AI and its capability to offer highquality, humanlike text. The AI was not only able to pass exams for lawyers and managers but also medical professionals. The creators have also acknowledged this issue. The creators state, We recognize that identifying AIwritten text has been an important point of discussion among educators, and equally important is recognizing the limits and impacts of AI generated text classifiers in the classroom. We have developed a preliminary resource on the use of ChatGPT for educators, which outlines some of the uses and associated limitations and considerations. While this resource is focused on educators, we expect our classifier and associated classifier tools to have an impact on journalists, misdisinformation researchers, and other groups. The classifier is very unreliable on short texts below 1,000 characters. Even longer texts are sometimes incorrectly labeled by the classifier. Sometimes humanwritten text will be incorrectly but confidently labeled as AIwritten by our classifier. We recommend using the classifier only for English text. It performs significantly worse in other languages and it is unreliable on code. Text that is very predictable cannot be reliably identified. For example, it is impossible to predict whether a list of the first 1,000 prime numbers was written by AI or humans, because the correct answer is always the same. AIwritten text can be edited to evade the classifier. Classifiers like ours can be updated and retrained based on successful attacks, but it is unclear whether detection has an advantage in the longterm. Classifiers based on neural networks are known to be poorly calibrated outside of their training data. For inputs that are very different from text in our training set, the classifier is sometimes extremely confident in a wrong prediction. Posted by: Danny Cyril Dcruze, Feb 01, 2023, 8:23 AM IST","sentiment":2,"digital transaction":0.1020251811,"healthcare":0.0040419176,"news platform":0.7114043832,"data analytics":0.4997955561,"insurance":0.0073402431,"investment":0.0469615757,"global market":0.494694978,"autonomous car":0.1193610206,"customer experience":0.3993139565,"data science":0.2975565195,"cryptocurrency":0.0219471119,"camera":0.0916510373,"robot":0.7910644412,"chatgpt":0.1916119754,"image":0.3198085725,"voice":0.0697890744,"patient care":0.0073745679,"research":0.4869756997}
{"id":348,"cleaned text":"This is why China cant build a ChatGPT AI rival  CanIndia News  As the world goes gaga over an AI chatbot called ChatGPT, experts believe that developing its Chinese competitor will surely face censorship, cost and data challenges, as in the case of big Internet companies like Alibaba and Tencent, the media reported on Monday. According to the South China Morning Post, a recent white paper published by the municipal technology bureau of Beijing offered support to local companies in developing ChatGPT rivals. But this will be easier said than done, owing to differences in the structure of the English and Chinese languages, cost pressures, availability of data sets, and last but not least  the thorny issue of censorship in China, the report noted. Censorship could certainly hinder Chinas ability to develop a local equivalent to ChatGPT, Dahlia Peterson, a research analyst at Georgetown Universitys Center for Security and Emerging Technology CSET, was quoted as saying. Even if Chinese AI companies are able to access and utilise global data and research resources to train their AI models, it is unlikely the Chinese authorities will allow them to use any material deemed as politically sensitive in their replies, she stressed. Chinas ruling Communist Party has always controlled the flow of political and social discussion within the country. The restrictions limit the data sets which scientists use to train AI chat models, said the report. Excessive restrictions, content regulation, and censorship could hinder commercialisation and further innovation of such technologies, said CSETs research analyst Hanna Dohmen. Earlier this month, Alibaba confirmed that the companys research institute Damo Academy is conducting an internal testing of an AI chatbot. Damo unveiled a natural language processing model with 27 billion parameters in 2021, after OpenAI released GPT3 with 175 billion parameters in 2020. However, the unique character of the Chinese language is another challenge to developing a ChatGPT rival. Training a Chinese language AI chat bot is also difficult because the countrys open source ecosystem is not as developed and extensive as in the West, according to Xu Liang, founder of Yuanyu Intelligent. Yuanyu Intelligent launched ChatYuan, a ChatGPTinspired service as a miniapp on Tencent Holdings WeChat in January. ChatYuans miniapp was suspended last week after authorities said such products need more scrutiny of their content. All Quiet on the Western Front beats BAFTA wins record of Cinema Paradiso Bittersweet time, says Austin Butler as he honours Lisa Marie after BAFTA win Google Contacts now let users add  edit contacts from sidebar Barca remain eight clear in Spanish La Liga after 20 win at home to Cadiz Save my name, email, and website in this browser for the next time I comment. Recognizing the need of the community which yearned to have a newspaper that represented the viewpoint of South Asians in Canada and its potential for growth as early as 1999, CanIndia News started publishing in English and distributing free of charge. ViewSonic unveils new gaming monitor with 144z refresh rate in India ","sentiment":2,"digital transaction":0.0869510919,"healthcare":0.0132126836,"news platform":0.2568459511,"data analytics":0.3596517444,"insurance":0.0135279102,"investment":0.6872108579,"global market":0.8283739686,"autonomous car":0.041714754,"customer experience":0.2058383077,"data science":0.2194026411,"cryptocurrency":0.0225727186,"camera":0.043052759,"robot":0.0758040771,"chatgpt":0.6532227397,"image":0.1991685629,"voice":0.273014605,"patient care":0.0345978178,"research":0.8149639368}
{"id":355,"cleaned text":"Artificial Intelligence: CCIA Welcomes European Parliament Progress on EU AI Act, Urges Further Improvements Brussels, BELGIUM  The European Parliaments committees on the Internal Market IMCO and Civil Liberties LIBE have unveiled their joint draft report on the proposed Artificial Intelligence AI Act, the first of its kind in the world. Members of the European Parliament MEPs Brando Benifei and Drago Tudorache, the corapporteurs on the AI Act, worked together in drafting the report. Now, MEPs in the two lead committees will debate and amend the joint report, after which the European Parliament will engage in final negotiations on the AI Act with the 27 EU Member States, expected to take place later this year. The Computer  Communications Industry Association CCIA Europe has long supported the EUs riskbased approach to AI as well as the dual emphasis on promoting European excellence and public trust. Indeed, CCIA released a position paper with key recommendations in January 2022. CCIA Europe welcomes the amendments put forward by the corapporteurs with the objective to strengthen legal clarity and finding a good balance in creating a trustworthy regulation that does not impose an unreasonable burden on businesses. However, if we want a futureproof regulation that promotes growth and innovation in the EU, there are several aspects with regard to the AI Acts scope that would deserve further consideration. Attention should be paid to narrowing down the current definition of AI to avoid unintentionally regulating traditional technologies. The EU should moreover be wary of imposing blanket bans and only ban AI practices when specific use cases are clearly contrary to EU fundamental rights. Likewise, we need to ensure that the categorisation of high risk AI systems follows a clear methodology and does not extend beyond having a significant impact on fundamental rights, health or safety. The following can be attributed to CCIA Vice President and Head of Office, Christian Borggreen: Artificial Intelligence will be key to help address a wide range of societal challenges, ranging from better traffic management to climate change. CCIA Europe welcomes the European Parliaments efforts to promote responsible and trustworthy development and use of AI. Indeed, we share the common goal of making sure that AI will benefit all Europeans. We urge lawmakers to narrow the definition of AI and avoid overregulating entire categories of technologies in order not to hamper innovation in the EU. Post navigationPreviousPrevious post:CCIA Files Joint Amicus Brief Asking Court To ReHear Standard Essential Patents CaseNextNext post:Digital Services Act: EU Negotiators Reach Political Agreement  Digital Services Act: EU Negotiators Reach Political Agreement  Apr 23, 2022 Brussels, BELGIUM  European Union negotiators have reached a provisional political agreement on the Digital Services Act DSA. This compromise between the European Parliament, the Commission, and the Council of Ministers paves the way for formal adoption of the regulation. The DSA defines how European users will buy and interact online. It frames how thousands 13 Associations Call on Lawmakers to Ensure New EU Product Safety Rules will Benefit Consumers, SMEs and Businesses  Apr 11, 2022 Brussels, BELGIUM  The Computer  Communications Industry Association CCIA Europe and 12 other leading trade associations representing startups, SMEs, technology, and ecommerce companies of different sizes today sent a joint letter to EU lawmakers on the General Product Safety Regulation GPSR. The letter urges Members of the European Parliament, the Council, and the European CCIA Publishes Position Paper on EU Proposal on Political Advertising  Mar 14, 2022 The Computer  Communications Industry Association CCIA Europe has published its position paper on the European Commissions proposal on transparency and targeting of political advertising TTPA. Among others we encourage legislators to: clarify the definition of political advertising and political actors recognise advertisers role and assign responsibilities accordingly and clarify data access obligations. The Council XThis website uses cookies to ensure you get the best experience. ACCEPTPrivacy  Cookies Policy This website uses cookies to improve your experience while you navigate through the website. Out of these cookies, the cookies that are categorized as necessary are stored on your browser as they are as essential for the working of basic functionalities of the website. We also use thirdparty cookies that help us analyze and understand how you use this website. These cookies will be stored in your browser only with your consent. You also have the option to optout of these cookies. But opting out of some of these cookies may have an effect on your browsing experience.","sentiment":2,"digital transaction":0.2468873262,"healthcare":0.0046741217,"news platform":0.7645301223,"data analytics":0.3834812045,"insurance":0.0325518772,"investment":0.0656966567,"global market":0.4989259541,"autonomous car":0.00375149,"customer experience":0.4668373168,"data science":0.436706543,"cryptocurrency":0.0061733499,"camera":0.0641085654,"robot":0.1651692241,"chatgpt":0.9086842537,"image":0.3554107547,"voice":0.2470879406,"patient care":0.0083681718,"research":0.2939670384}
{"id":374,"cleaned text":"MPs warned of AI arms race to the bottom Expert tells Parliamentary committee that technology companies developing and deploying artificial intelligence are cutting corners to stay competitive and placing safety concerns on the backburner, opening up enormous risks for how the technology could be used Big tech firms are willing to throw out artificial intelligence AI safeguards to keep up with competitors, risking an arms race to the bottom, MPs have been warned. The House of Commons Science and Technology Committee launched an inquiry into the UK governments proposed proinnovation framework for regulating AI in October 2022, to scrutinse its approach and to ensure the technology is used in an ethical and responsible way. Addressing the committee in the first session of its inquiry in late January 2023, Michael Osborne, a professor of machine learning at Oxford University and cofounder of responsible AI platform Mind Foundry, said that the emergence of an AI arms race is a worrying development, because it signals the start of a race to the bottom in terms of safeguards and standards. While arms races usually refer to military competition between nationstates which is happening with AI Osborne said the civilian applications of the tech could bestow huge advantages on whoever is able to develop a really sophisticated AI first. Noting that Google founders Larry Page and Sergei Brin were very recently called back into the company after leaving their daily roles in 2019 to consult on its AI future, Osborne added the release of ChatGPT by OpenAI in November 2022 has placed a competitive pressure on big tech firms developing similar tech that could be dangerous. Google has said publicly that its willing to recalibrate the level of risk and assumes in any release of AI tools due to the competitive pressure from OpenAI, he said. The big tech firms are seeing AI as something as very, very valuable, and theyre willing to throw away some of the safeguardsand take a much more move fast and break things perspective, which brings with it enormous risks. He added, however, that the AI arms race is not limited to tech firms jostling for dominance in the private sector, and there is already a geopolitically motivated AI arms race underway between the US and China, as the actor that masters a particular AI technology first may have enormous strategic advantages in both military and economic terms. There seems to be this willingness to throw safety and caution out the window and just race as fast as possible to the most advanced AI, he said. I think those dynamics are ones that we should absolutely rule out as soon as possible via regulation. We really need to adopt the precautionary principle and try and play for as much time as we can. Osborne added while international consensus around AI regulation will be tough to achieve, it is possible: Theres some reason for hope in that weve been pretty good at regulating the use of nuclear weapons, at least for several decades, where there is a similar sort of strategic advantage if someone was able to use them successfully. In June 2018, angel investor Ian Hogarth predicted the rise of what he called AI nationalism, arguing that the transformational potential of AI will prompt an accelerated arms racebetween key countrieswhere we will see increased protectionist state action to support national champions, block takeovers by foreign firms and attract talent. He added: While the idea of AI as a public good provides me personally with a true north, I think it is naive to hope we can make a giant leap there today, given the vested interests and misaligned incentives of nation states, forprofit technology companies and the weakness of international institutions. Osborne told MPs that, outside the need to avoid an arms race over the technology, policy makers also need to begin preparing for the societal changes AI could usher in, which he compared with the paradigm shifts prompted by the automobile or the internet. You might say that AI is already at a similar scale, of being able to impact on a very wide variety of different human endeavours, he said. When the world changes a lot, of course, there are risks that are posed, and there are winners and losers, so we do have to prepare ourselves for those rapid changes. He added that in the near future, it would be reasonable to expect a high level of economic disruption from AI, including much churn in labour markets as tasks and occupations become more automated. Michael Cohen, a DPhil scholar at Oxford University studying AI safety, added that AI would enable the economic output of humans to be produced much more cheaply if it became advanced enough, which could have a similar impact on economic output as the combustion engine. However, he said while the combustion engine replaced horses because it could wholly replicate their role in the economy as transport, AI is still too rudimentary to fully replicate a wide range of complex human activities. Osborne added while there are genuine examples where AI could replace human labour  for example, operating in extreme environments such as space  AI should be thought of and conceptualised as an augmentation to human labour. Although AI may not be replacing wholesale occupationscertainly the technology we have already has enormous potential for transformation across the economy and in society more broadly, he said. Given the diversity of AI as a technology, Osborne concluded that any regulation must be as flexible and nonperspective as possible in its definition of what constitutes an AI system, so that certain use cases and their wider implications are not dismissed or overlooked. EU rolling out measures for online safety and AI liability: The European Council has approved the passage of the Digital Services Act to protect peoples rights online, while the European Commission has announced proposals to help those negatively affected by artificial intelligence to claim compensation. AI experts question tech industrys ethical commitments: The massive proliferation of ethical frameworks for artificial intelligence has done little to change how the technology is developed and deployed, with experts questioning the tech industrys commitment to making it a positive social force. Europes proposed AI regulation falls short on protecting rights: The European Commissions proposal for artificial intelligence regulation focuses on creating a riskbased, marketled approach replete with selfassessments, transparency procedures and technical standards, but critics warn it falls short of being able to protect peoples fundamental rights and mitigating the technologys worst abuses. Mitigating risks from generative AI tools such as ChatGPT means involving humans in final decisionmaking and establishing ... An economic slowdown may be inescapable, but IT leaders must maintain focus on ESG initiatives. Discover why IT operations should... CIOs must do more with less as economic concerns grow, and continue to drive environmental, social and governance efforts. ... Ransomware gangs have increasingly focused their attacks on the K12 education sector, even though most school districts do not ... From Offensive Security Certified Professional to GIAC Web Application Penetration Tester, learn about the certifications worth ... The FBI infiltrated Hives network in July 2022 and obtained decryption keys, which it distributed to victims to prevent 130 ... Enterprises are looking for multicloud networking features that include programmability, security integration and endtoend ... MEF recently released new zerotrust and SASE standards. Standardizations can help with interoperability, but are they necessary ... Network certifications can span networking fundamentals to productspecific knowledge. Evaluate six certifications, and weigh ... Dogged by stalled PC sales and tighter IT spending, Intel once again reported down revenues. CEO Pat Gelsinger highlighted ... Data centers use a lot of energy, and it can be difficult to navigate how to reduce energy use. ISO 50001:2018 provides guidance ... Admins who arent familiar with a command can use Linux man pages for better understanding. This tutorial outlines how to access ... Organizations are using cloud technologies and DataOps to access realtime data insights and decisionmaking in 2023, according ... Data lakes and data warehouses are both commonly used in enterprises. Here are the main differences between them to help you ... The past year focused heavily on data intelligence, lakehouse development and observability as vendors innovated to help ...","sentiment":2,"digital transaction":0.0781169832,"healthcare":0.0174570065,"news platform":0.14672333,"data analytics":0.4190391004,"insurance":0.0139472047,"investment":0.3670650721,"global market":0.9137992263,"autonomous car":0.0702711195,"customer experience":0.1197427139,"data science":0.0889247432,"cryptocurrency":0.0215879828,"camera":0.6721224785,"robot":0.0844794735,"chatgpt":0.1889149249,"image":0.16517362,"voice":0.1460320801,"patient care":0.0261542611,"research":0.7358201742}
{"id":394,"cleaned text":"Most of us are still worried about AI  but will corporate America listen Getty ImagesBots can mean big bucks for companies. Is everyone benefiting Welcome to a new NPR series where we spotlight the people and things making headlines  and the stories behind them. Do we need a mandatory screening of the Terminator series in corporate boardrooms Because new research shows that Americans are concerned about the pace that artificial intelligence is evolving these days. Alexa, play Terminator 2: Judgment Day. The battle for AI supremacy is on. Weve been talking to robots in our homes, cars and offices for a while now  Alexa and Siri could write scathing tellalls about most of us  but over the last few months, the stakes have skyrocketed. Google and Microsoft are among the companies to recently announce their multibilliondollar chatbots. It follows OpenAIs headlinegrabbing ChatGPT that launched in November. These AI tools can run all sorts of tech, power search engines, and many can talk a lot like a human. But they sure dont absorb and dispense information like a human. The speed at which these chatbots can solve problems, write research papers, even make original art would put any prodigy to shame. The positive side is that its like having a personal assistant. The possibilities are endless The concerning side The possibilities are ... endless. AFP via Getty ImagesMicrosofts Yusuf Mehdi speaks during an event introducing the new AIpowered Microsoft Bing and Edge on February 7. Whats the big deal Theres an arms race to get the biggest, baddest bot out there as quickly as possible. But not everyone is convinced. While we seem increasingly reliant on AI to help us with daytoday things like customer service, a MITREHarris Poll survey released this month finds that were not as comfy with things like selfdriving cars. The study showed that only 48 of respondents believed AI is safe and secure, and 78 were very or somewhat concerned that AI can be used for malicious intent. The survey also showed a big divide between ordinary folk and those in the tech world. Only 48 of Americans would rely on AI for everyday tasks, compared to 79 of tech experts. And its worth noting this survey was conducted in early November, before the latest wave of AI bots sparked both acclaim and pushback. There have also been some very recent, highprofile mistakes. Last week, Google introduced its AI bot, Bard. But it produced a factual error in its first demo, shares in its parent company, Alphabet,lost 100 billion in market value. Then theres the dystopian, Terminatorlike scenarios that we cant help obsess over  starting with the claims last year by a Google engineer that he sees its AI as sentient which Google denied More recently, Bings chatbot, Sydney, told The New York Times it had a desire to be destructive. Others on social media have shared similar stories, including one person who said he asked Sydney to choose between his survival or its own. In response, the bot borrowed the wise words of Samantha Jones: I love you. But I love me more. Im paraphrasing. I am currently trying to get this AI chatbot to become self aware. Hopefully its more like Short Circuit than Terminator p t r c k @patrickjd December 29, 2022 What are people saying It really depends on who you ask. Douglas Robbins, MITRE vice president of engineering and prototyping, says its all about trust: If the public doesnt trust AI, adoption may be mostly limited to less important tasks like recommendations on streaming services or contacting a call center in the search for a human. This is why we are working with government and industry on wholeofnation solutions to boost assurance and help inform regulatory frameworks to enhance AI assurance. Edward Tian, a 22yearold student who created an app to combat misuse of ChatGPT, told NPR that were at an inflection point: This technology is incredible. I do believe its the future. But, at the same time, its like were opening Pandoras Box. And we need safeguards to adopt it responsibly. Ethan Mollick, an associate professor at the University of Pennsylvanias Wharton School, says we should enjoy it: There is a lot of good stuff that we are going to have to do differently, but I think we could solve the problems of  how do we teach people to write in a world with ChatGPT Weve taught people how to do math in a world with calculators. I think we can survive that. So what now AI is here to stay, whether people like it or not. Those at the tippy top of these tech and media companies appear allin on AI and its potential for innovation, profits and bragging rights. The question is whether they are open to hearing the publics hesitation. And this isnt just about James Cameronworthy apocalypse scenarios. Bots are replacing some humans at work, and making decisions about who to hire. Microsoft says it is driven by ethical principles that put people first Google says its going to be bold and responsible moving forward and OpenAI says its mission is that its tech benefits all of humanity. Time will tell if these will be backed by actions ... or if its just chat. In the meantime, try not to pick any fights with Sydney.  Battlebots 2023: Microsoft and Google duke it out over who has the best AI How using bots for hiring can take us backwards in discrimination practices Lauren Hodges is an associate producer for All Things Considered. She joined the show in 2018 after seven years in the NPR newsroom as a producer and editor. She doesnt mind that you used her pens, she just likes them a certain way and asks that you put them back the way you found them, thanks. Despite years working on interviews with notable politicians, public figures, and celebrities for NPR, Hodges completely lost her cool when she heard RuPauls voice and was told to sit quietly in a corner during the rest of the interview. She promises to do better next time.","sentiment":2,"digital transaction":0.0636073425,"healthcare":0.6080300212,"news platform":0.1122017503,"data analytics":0.0935072079,"insurance":0.0060920594,"investment":0.1153743938,"global market":0.6044690609,"autonomous car":0.0055613103,"customer experience":0.0878649577,"data science":0.0717478693,"cryptocurrency":0.0080212923,"camera":0.0226477142,"robot":0.0138687054,"chatgpt":0.0505638048,"image":0.1984991282,"voice":0.0443664119,"patient care":0.2731381059,"research":0.3315427303}
{"id":420,"cleaned text":"Productivity Impact on Profits Highlights AI Benefits One of the primary benefits ascribed to artificial intelligence AI is enhanced workplace productivity. Its one of the reasons why AI investing ebullience is so palpable this year. Theres no denying that highly productive firms are profitable companies  a notion that bolsters the case for AIfocused exchange traded funds such as the ARK Autonomous Technology  Robotics ETF ARKQ. With ARKQs inroads to AI and automation  another pivotal piece in the productivity puzzle  the ETF could be relevant over the longterm due in part to shrinking labor pools. Whether its reshoring plans or efforts to locate costeffective labor in other jurisdictions, some USbased multinational firms are facing challenges. However, that scenario can be ameliorated by AI and automation, leading to better productivity. In a multipolar world, where the U.S. is looking to safeguard advantages and technologies and key areas of production, the labor pool for U.S. multinationals is contracting. Efforts to refriend, and nearshore critical industries have strong political support. But this narrows the geographical options for companies making cheap labor, particularly for skilled manufacturing, harder to find, noted Michael Zezas, Global Head of Fixed Income and Thematic Research for Morgan Stanley. Zezas discussed the scenario known as the Great Productivity Race, which has implications for assets such as ARKQ. In simple terms, the Great Productivity Race is the concept that domestic companies with international exposure will need to allocate increasing amounts of capital to technologies that allow them to streamline productivity. Translation: More large companies will commit financial resources to technologies that allow them to gain market share and keep up with customer demand. That could be the most reliable course of action in an environment of tight labor pools. Investors need to know that some corporate sectors will be able to handle this well and others will be challenged. Those best positioned are ones less reliant on labor and with ample resources to invest in productivity. Those more challenged rely heavily on labor and have less resources on their balance sheets, added Zezas. Up 9.19 yeartodate, ARKQ is already reflecting some of the enthusiasm surrounding AI and automation as longterm drivers of increased corporate productivity. The 874.4 million ARKQ is actively managed and uses a proprietary weighting methodology in an effort to identify disruptive growth companies with exposure to industries including AI, automation, manufacturing, and nextgeneration transportation. For more news, information, and analysis, visit theDisruptive Technology Channel. The opinions and forecasts expressed herein are solely those of Tom Lydon, and may not actually come to pass. Information on this site should not be used or construed as an offer to sell, a solicitation of an offer to buy, or a recommendation for any product. ","sentiment":2,"digital transaction":0.1448382288,"healthcare":0.0124489479,"news platform":0.7668894529,"data analytics":0.1152618825,"insurance":0.0234559327,"investment":0.2962936461,"global market":0.9343439937,"autonomous car":0.0140552036,"customer experience":0.6938165426,"data science":0.1196595728,"cryptocurrency":0.0354271233,"camera":0.0400108211,"robot":0.0775446966,"chatgpt":0.6845709085,"image":0.524782896,"voice":0.5929185748,"patient care":0.0107764862,"research":0.088960655}
{"id":439,"cleaned text":"nybl Joins World AI Show  Awards as The Official Artificial Intelligence PartnerThe 35th global edition of World AI Show will bring together global AI leaders, investors, media outlets, and government officials under one roof. Leading AI company nybl will participate as the Official Artificial Intelligence Partner.DUBAI, May 22, 2022  JCN Newswire  Held under the patronage of the Private Office of HH Sheikh Saeed Bin Ahmed Al Maktoum, a member of the royal family of Dubai, World AI Show  Awards, is set to take place on 2526 May 2022 at the Jumeirah Emirates Towers in Dubai. Noor Alnahhas, Chief of Dreaming Stuff Up, nybl will shed light on the role of Humanity in AI.nybl deals with humans like humans and leaves the machine stuff to the robots. The culture at nybl and choices in partnerships are all dictated by a fundamental belief that humanity comes before all else. During his keynote, Noor Alnahhas will outline the secret behind nybls success and specifically the secret sauce to conquering AI, and the role of humanity in this approach. From pandemic breakthroughs to recent humanitarian journeys, nybl will take attendees on a trip that is nothing short of inspirational. To leave Emirates Towers as a startup in Cohort 4 with Dubai Future Accelerators and return as a leading sponsor and Official AI Partner at the World AI Show in less than 2 years is proof that nybl is doing a lot of things right Noor further adds, nybl is everywhere at the World AI Show weve planted a workshop space, booth and attendees can also catch us at a panel discussion, where we will be delving into the future of investing in AI.Noor, a serial entrepreneur boasts over 15 years of experience in developing and scaling new technology. Currently, Noor serves as a member of the AI Ethics Advisory Board for the Government of Dubai and as a Strategy and Growth Advisor to several global startups in the Artificial Intelligence, Shared Economy, and Tech industries. He holds a Bachelors in Marketing and Entrepreneurship from the University of Houston, and has earned numerous leadership training from INSEAD  Wharton.Mithun Shetty, CEO of Trescon reflects on the excitement leading up to the event. We are extremely honored to feature nybl as the Official Artificial Intelligence Partner for the event. Their innovative solutions have replaced training data with turnkey intelligence based on subjectmatter expertise and proven data behavior models.About nyblnybl is a deep tech development company that delivers an endtoend AI platform and provides solutions through actionable intelligence to customers most critical and difficult challenges. nybls AI platform can be applied in any industry and allows partners and clients to obtain realtime, effective analyses on crucial equipment and processes to predict and safeguard against any potential disruptions.To learn more about what we do, click here: https:nybl.aiAbout World AI Show:World AI Show is a thoughtleadershipdriven, businessfocused, global series of events that takes place in strategic locations across the world.The show is a oneofakind gathering of prequalified CIOs, CEOs, CTOs, Heads of AI, Chief Digital Officers, Heads of Innovation and International AI experts.Witness powerful keynotes, workshops, usecase presentations, product exhibitions, panel discussions and tech talks to find solutions for issues and trends within the AI and RPA space.About Trescon:Trescon is a global business events and consulting firm that provide a wide range of business services to a diversified client base that includes corporations, governments and individuals. Trescon is specialized in producing highly focused B2B events that connect businesses with opportunities through conferences, roadshows, expos, demand generation, investor connect and consulting services.For further details about the announcement, please contact:Nupur Aswani,Head of Media, PR  Corporate CommunicationsTresconmedia@tresconglobal.coSource: tresconCopyright 2022 JCN Newswire . All rights reserved.Kostenloser Wertpapierhandel auf Smartbroker.de2022JCN NewswireDiesen Artikel auf Deutsch lesenSie erhalten auf FinanzNachrichten.de kostenlose RealtimeAktienkurse von und FNRD2.624.0Wie bewerten Sie die aktuell angezeigte Seitesehr gut123456schlechtProblem meldenWerbehinweise: Die Billigung des Basisprospekts durch die BaFin ist nicht als ihre Befrwortung der angebotenen Wertpapiere zu verstehen. Wir empfehlen Interessenten und potenziellen Anlegern den Basisprospekt und die Endgltigen Bedingungen zu lesen, bevor sie eine Anlageentscheidung treffen, um sich mglichst umfassend zu informieren, insbesondere ber die potenziellen Risiken und Chancen des Wertpapiers. Sie sind im Begriff, ein Produkt zu erwerben, das nicht einfach ist und schwer zu DAXXetraOrderbuchAd hocMitteilungenNachrichten BrsenAktienEmpfehlungenBranchenMedienNachrichtenArchivRSSNews von FinanzNachrichten.dePresseImpressum  AGB  Disclaimer  DatenschutzMediadaten","sentiment":2,"digital transaction":0.2436913699,"healthcare":0.0408872142,"news platform":0.3985110521,"data analytics":0.4550369382,"insurance":0.1665068716,"investment":0.693234086,"global market":0.9336779714,"autonomous car":0.1703473479,"customer experience":0.5125517249,"data science":0.2110170871,"cryptocurrency":0.0263707209,"camera":0.1418578327,"robot":0.1284813136,"chatgpt":0.6263085604,"image":0.2361022085,"voice":0.2251848727,"patient care":0.0307008382,"research":0.970510602}
{"id":452,"cleaned text":"AI Ethics Welcomes The Prospects Of A Standardized AI Risk Management Framework, Which Could Bolster Autonomous SelfDriving Car Efforts TooLance EliotContributorOpinions expressed by Forbes Contributors are their own.TransportationDr. Lance B. Eliot is a worldrenowned expert on Artificial Intelligence AI and Machine Learning ML. Apr 11, 2022,11:30am EDTShare to FacebookShare to TwitterShare to Linkedin AI Ethics welcomes the effort to craft an AI Risk Management Framework as a standard via NIST. We seem to be told repeatedly that taking risks is important in life. If you look at any everyday listing of quotable quotes there is a preponderance of life hacks telling you to embrace risk. Take a chance and climb out on a limb. Set aside your constraining worries and fly free with the wonderment of risk. Risk is your friend. Risk makes the world go around. Simply stated, no risk, no gain. Though these glowing encouragements about being a risktaker seem sensible, somehow the counterbalancing and sobering thoughts about the downsides of risk are left unsaid. Risk can put you in jeopardy. Dire harms can occur from risky actions. Simply stated, risk is not riskfree. General George Patton famously asserted that we should always be riskminded via taking sufficiently calculated risks, which he characterized as being quite different from being rash. Thus, think beforehand about the risks that you are willing to absorb. Be aware of known risks and the potential of unknown risks. A person has got to know their limitations when it comes to risk and risktaking. I am bringing up the nature and scope of risk as a type of analytically describable phenomenon in order to highlight that when it comes to AI there is an increasing need to determine how risky our expanding adoption of AI is. AI is not riskfree. On the contrary, AI presents many sizable and scarily massive risks that require us all to take a deep breath and start seriously calculating what those risks are. We must have our eyes wide open and know about AI risks as we plunge headfirst into the pellmell rush toward embracing AI. Please realize that all of todays stakeholders are faced with AI risks. For example, a firm that is crafting an AI system is taking a risk that the AI eventually could cause some form of substantive harm to those that use the AI system. The harm might be financial, psychological, or possibly physical harm that could injure or kill someone. Executives of the firm are likely to be held legally accountable for having devised and released the AI. AI developers that built the AI are bound to be held accountable. There are lots of hands that go into making and promulgating AI and they all can be considered jointly responsible and culpable for what they allowed to adversely occur. MORE FOR YOUTesla Challenger Polestar Powers Up With Nasdaq Listing Plan Valuing It At 20 BillionDriver Killed By His Own Car Door While Waiting In Line At FastFood DriveThru, Providing Cautionary Insights For AI SelfDriving CarsTesla Cofounders Recycling Startup Plans To Become EV Battery Material Powerhouse Think of AI risk as something that floats along and attaches to all that have a touchpoint associated with the AI. Users of an AI system are taking on some amount of risk. They might be harmed by AI. Those that devised the AI are taking on some amount of risk associated with the harmful outcomes that their AI might produce. Risk is pervasive in the realm of AI and yet oftentimes seems completely neglected and generally woefully understated. The bad news then is that not enough attention is going toward AI risks. The good news is that a burgeoning appreciation of the vitalness of understanding and measuring AI risk is gaining speed. As a healthy sign of this awareness, we can take a look at the being formulated AI Risk Management Framework RMF that the National Institute of Standards and Technology NIST is undertaking. Ill be quoting herein from the draft document dated March 17, 2022. There are various meetings underway to further refine and expand the document. A semifinalized version known as AI RMF 1.0 is targeted to be issued in January 2023. Before I jump into the existing draft of the AI RMF, I would like to emphasize that anyone genuinely interested in AI Ethics ought to be especially keeping track of what the AI RMF consists of. Besides staying on top of the draft, you might also consider getting involved with the drafting effort and aid in the formulation of the AI Risk Management Framework all told note that the NIST is undertaking public workshops that welcome such input. You indeed can help make history. Lets briefly explore an important mashup that exists between AI Ethics and AI risks. AI risks are integral to the utility of Ethical AI. For my ongoing and extensive coverage of AI Ethics and Ethical AI, see the link here and the link here, just to name a few. You could readily claim that AI risk is immersed throughout all AI Ethics principles or precepts. A convenient mental model would be to envision a spreadsheet of sorts whereby the principles of AI Ethics as the horizontal elements the columns and AI risk is a vertical component rows that weave in and throughout the horizontals.  Speaking of AI risks brings up the varying nuance of what manner of AI one is alluding to. Despite those blaring headlines about the proclaimed humanlike wonders of AI, there isnt any AI today that is sentient. We dont know if sentient AI will be possible. Nobody can aptly predict whether we will attain sentient AI, nor whether sentient AI will somehow miraculously spontaneously arise in a form of computational cognitive supernova usually referred to as the singularity, see my coverage at the link here. The type of AI that I am focusing on herein consists of the nonsentient AI that we have today.  If we wanted to wildly speculate about sentient AI, this discussion could go in a radically different direction. A sentient AI would supposedly be of human quality. You would need to consider that the sentient AI is the cognitive equivalent of a human. More so, since some speculate we might have superintelligent AI, it is conceivable that such AI could end up being smarter than humans for my exploration of superintelligent AI as a possibility, see the coverage here.  Lets keep things more down to earth and consider todays computational nonsentient AI. Realize that todays AI is not able to think in any fashion on par with human thinking. When you interact with Alexa or Siri, the conversational capacities might seem akin to human capacities, but the reality is that it is computational and lacks human cognition. The latest era of AI has made extensive use of Machine Learning ML and Deep Learning DL, which leverage computational pattern matching. This has led to AI systems that have the appearance of humanlike proclivities. Meanwhile, there isnt any AI today that has a semblance of common sense and nor has any of the cognitive wonderment of robust human thinking. MLDL is a form of computational pattern matching. The usual approach is that you assemble data about a decisionmaking task. You feed the data into the MLDL computer models. Those models seek to find mathematical patterns. After finding such patterns, if so found, the AI system then will use those patterns when encountering new data. Upon the presentation of new data, the patterns based on the old or historical data are applied to render a current decision. I think you can guess where this is heading. If humans that have been making the patterned upon decisions have been incorporating untoward biases, the odds are that the data reflects this in subtle but significant ways. Machine Learning or Deep Learning computational pattern matching will simply try to mathematically mimic the data accordingly. There is no semblance of common sense or other sentient aspects of AIcrafted modeling per se.  Furthermore, the AI developers might not realize what is going on either. The arcane mathematics in the MLDL might make it difficult to ferret out the now hidden biases. You would rightfully hope and expect that the AI developers would test for the potentially buried biases, though this is trickier than it might seem. A solid chance exists that even with relatively extensive testing that there will be biases still embedded within the pattern matching models of the MLDL. You could somewhat use the famous or infamous adage of garbagein garbageout. The thing is, this is more akin to biasesin that insidiously get infused as biases submerged within the AI. The algorithm decisionmaking ADM of AI axiomatically becomes laden with inequities.  You might be aware that when the latest era of AI got underway there was a huge burst of enthusiasm for what some now call AI For Good. Unfortunately, on the heels of that gushing excitement, we began to witness AI For Bad. For example, various AIbased facial recognition systems have been revealed as containing racial biases and gender biases, which Ive discussed at the link here. Efforts to fight back against AI For Bad are actively underway. Besides vociferous legal pursuits of reining in the wrongdoing, there is also a substantive push toward embracing AI Ethics to righten the AI vileness. The notion is that we ought to adopt and endorse key Ethical AI principles for the development and fielding of AI doing so to undercut the AI For Bad and simultaneously heralding and promoting the preferable AI For Good. On a related notion, I am an advocate of trying to use AI as part of the solution to AI woes, fighting fire with fire in that manner of thinking. We might for example embed Ethical AI components into an AI system that will monitor how the rest of the AI is doing things and thus potentially catch in realtime any discriminatory efforts, see my discussion at the link here. We could also have a separate AI system that acts as a type of AI Ethics monitor. The AI system serves as an overseer to track and detect when another AI is going into the unethical abyss see my analysis of such capabilities at the link here. Lets cover briefly some of the overall Ethical AI precepts that Ive previously discussed in my columns to herein illustrate what ought to be a vital consideration for anyone and everyone that is crafting, fielding, or using AI. Well then dive into the topic of AI risks. As stated by the Vatican in the Rome Call For AI Ethics and as Ive covered at the link here, these are their identified six primary AI ethics principles: Inclusion: The needs of all human beings must be taken into consideration so that everyone can benefit, and all individuals can be offered the best possible conditions to express themselves and develop. Responsibility: Those who design and deploy the use of AI must proceed with responsibility and transparency. Impartiality: Do not create or act according to bias, thus safeguarding fairness and human dignity. Security and privacy: AI systems must work securely and respect the privacy of users. As stated by the U.S. Department of Defense DoD in their Ethical Principles For The Use Of Artificial Intelligence and as Ive covered at the link here, these are their six primary AI ethics principles: Responsible: DoD personnel will exercise appropriate levels of judgment and care while remaining responsible for the development, deployment, and use of AI capabilities. Equitable: The Department will take deliberate steps to minimize unintended bias in AI capabilities. Traceable: The Departments AI capabilities will be developed and deployed such that relevant personnel possesses an appropriate understanding of the technology, development processes, and operational methods applicable to AI capabilities, including with transparent and auditable methodologies, data sources, and design procedure and documentation. Reliable: The Departments AI capabilities will have explicit, welldefined uses, and the safety, security, and effectiveness of such capabilities will be subject to testing and assurance within those defined uses across their entire lifecycles. Governable: The Department will design and engineer AI capabilities to fulfill their intended functions while possessing the ability to detect and avoid unintended consequences, and the ability to disengage or deactivate deployed systems that demonstrate unintended behavior. Ive also discussed various collective analyses of AI ethics principles, including having covered a set devised by researchers that examined and condensed the essence of numerous national and international AI ethics tenets in a paper entitled The Global Landscape Of AI Ethics Guidelines published in Nature, and that my coverage explores at the link here, which led to this keystone list: As you might directly guess, trying to pin down the specifics underlying these principles can be extremely hard to do. Even more so, the effort to turn those broad principles into something entirely tangible and detailed enough to be used when crafting AI systems is also a tough nut to crack. It is easy to overall do some handwaving about what AI Ethics precepts are and how they should be generally observed, while it is a much more complicated situation in the AI coding having to be the veritable rubber that meets the road. The AI Ethics principles are to be utilized by AI developers, along with those that manage AI development efforts, and even those that ultimately field and perform upkeep on AI systems. All stakeholders throughout the entire AI life cycle of development and usage are considered within the scope of abiding by the beingestablished norms of Ethical AI. This is an important highlight since the usual assumption is that only coders or those that program the AI are subject to adhering to the AI Ethics notions. As earlier stated, it takes a village to devise and field AI, and for which the entire village has to be versed in and abide by AI Ethics precepts. I mentioned earlier herein that AI risk is a matter that intersects across all of the AI Ethics precepts. To help fully exhibit that semblance, consider a rewording of the key AI Ethics principles to illuminate the AI risk matter: Before we unpack this, lets consider what the word risk means. I say this because risk as a catchword has different meanings depending upon whom you are speaking with. In exploring this facet, I will also bring up another NIST document that you should consider studying if you are going to get into the AI RMF, namely that there is an overall NIST Risk Management Framework RMF that covers broadly Information Technology systems and risk management, having been in place for a while. The AI RMF is essentially an instantiation of the broader RMF you might cheekily say that the AI RMF is the son or daughter of the alltold RMF. Per the overall NIST RMF, here is a definition of risk: Risk is a measure of the extent to which an entity is threatened by a potential circumstance or event. Risk is also a function of the adverse impacts that arise if the circumstance or event occurs, and the likelihood of occurrence. Types of risk include program risk complianceregulatory risk financial risk legal risk missionbusiness risk political risk security and privacy risk including supply chain risk project risk reputational risk safety risk strategic planning risk. The NIST AI RMF draft defines risk this way: Risk is a measure of the extent to which an entity is negatively influenced by a potential circumstance or event. Typically, risk is a function of 1 the adverse impacts that could arise if the circumstance or event occurs and 2 the likelihood of occurrence. Entities can be individuals, groups, or communities as well as systems, processes, or organizations. Digging deeper and perhaps muddying the waters, the Stanford Encyclopedia of Philosophy handily points out that risk is often couched in five different connotations: 1 Risk is an unwanted event that may or may not occur 2 Risk is the cause of an unwanted event that may or may not occur 3 Risk is the probability of an unwanted event that may or may not occur 4 Risk is the statistical expectation value of an unwanted event that may or may not occur 5 Risk is the fact that a decision is made under conditions of known probabilities  For now, lets collegially agree that we are going to within this discussion treat the notion of what risk is in a generalized manner as per the aforementioned NIST RMF and NIST AI RMF definitions and not get stuck on the tortuous variations. I trust then that you are comfortable with my above foundation of having settled for the time being the contextual meaning of AI and the meaning of risk.  An AI risk management framework is a means of ferreting out the risks of AI, along with hopefully managing those risks.  According to the AI RMF, here is the formal purpose or aspiration of the AI Risk Management Framework being formulated: An AI Risk Management Framework AI RMF, or Framework can address challenges unique to AI systems. This AI RMF is an initial attempt to describe how the risks from AIbased systems differ from other domains and to encourage and equip many different stakeholders in AI to address those risks purposefully. This voluntary framework provides a flexible, structured, and measurable process to address AI risks throughout the AI lifecycle, offering guidance for the development and use of trustworthy and responsible AI. The NIST also realizes that an AI RMF as a proposed standard has to be readily useable, be updated as technology advances, and embody other core criteria: A risk management framework should provide a structured, yet flexible, approach for managing enterprise and societal risk resulting from the incorporation of AI systems into products, processes, organizations, systems, and societies. Organizations managing an enterprises AI risk also should be mindful of larger societal AI considerations and risks. If a risk management framework can help to effectively address and manage AI risk and adverse impacts, it can lead to more trustworthy AI systems. Some of you that are a bit skeptical might be questioning why we need an AI RMF versus just relying on the generalized RMF that is already readily available. Arent we simply reinventing the wheel The answer is no, we are not reinventing the wheel. A wheel is customizable to a particular need. A reasonable person would likely acknowledge that there are wheels of all different kinds of shapes and sizes. The wheel on an airplane is undoubtedly quite different from the wheel that is on a childs tricycle. Sure, they are both wheels, but they are devised differently and ergo have different characteristics and can rightfully be examined distinctly too. The AI RMF document expresses a similar sentiment: Risks to any software or informationbased system apply to AI that includes important concerns related to cybersecurity, privacy, safety, and infrastructure. This framework aims to fill the gaps related specifically to AI. In the existing version of the AI RMF draft, they define four stakeholder groups: The bulk of the attention about AI risk usually goes toward the AI system stakeholders. That makes sense. These are the stakeholders that are involved in the conceiving of, designing, building, and fielding AI. In addition, we can include those that acquire or license AI for use. We tend to view those stakeholders as the highly visible parties that did the heavy lifting in shepherding the AI system into existence and fostered its deployment. You might not have equally thought of or considered instrumental the AI operators and evaluators. As stated in the AI RMF, the AI operators and evaluators do this: Operators and evaluators provide monitoring and formalinformal test, evaluation, validation, and verification TEVV of system performance, relative to both technical and sociotechnical requirements. They are crucial to AI and also within the band of AI risks. External stakeholders would encompass a wide array of entities including trade groups, advocacy groups, civil society organizations, and others. The general public consists of consumers and others that experience the risk associated with untoward AI. You might be wondering how much risk is tolerable when it comes to AI. Sorry to say that there is no particular number or assigned value that we can give to the amount of tolerable or acceptable risk that we might find worthwhile or societally permissible. For those of you that want a standardized designated numeric indication, youll need to temper that desire by this notable point in the AI RMF draft: The AI RMF does not prescribe risk thresholds or values. Risk tolerance  the level of risk or degree of uncertainty that is acceptable to organizations or society  is the context and use casespecific. A recommended methodology by the AI RMF for examining and governing AI risk is depicted as consisting of base steps labeled as Map, Measure, and Manage. The Map function frames the risks of an AI system. The Measure function encompasses the tracking and analysis of AI risk. The Manage function makes use of the Map and Measure functions to then try and minimize adverse impacts while maximizing the benefits of the AI. According to the draft AI RMF, the later versions of the standard will include a Practice Guide as a companion to showcase examples and practices of using the AI RMF. In the broader NIST RMF standard, there is an embellished set of seven steps that coincide with doing an overarching IT and systems risk management effort. Ive found those seven steps handy to keep in mind, including when building and deploying AI systems.  1. Prepare to execute the RMF from an organization and a systemlevel perspective by establishing a context and priorities for managing security and privacy risk.  2. Categorize the system and the information processed, stored, and transmitted by the system based on an analysis of the impact of loss.  3. Select an initial set of controls for the system and tailor the controls as needed to reduce risk to an acceptable level based on an assessment of risk. 4. Implement the controls and describe how the controls are employed within the system and its environment of operation.  5. Assess the controls to determine if the controls are implemented correctly, operating as intended, and producing the desired outcomes with respect to satisfying the security and privacy requirements.  6. Authorize the system or common controls based on a determination that the risk to organizational operations and assets, individuals, other organizations, and the Nation is acceptable.  7. Monitor the system and the associated controls on an ongoing basis to include assessing control effectiveness, documenting changes to the system and environment of operation, and conducting risk assessment. At this juncture of this weighty discussion, Id bet that you are desirous of some illustrative examples that might showcase the nature of AI risks. There is a special and assuredly popular set of examples that are close to my heart. You see, in my capacity as an expert on AI including the ethical and legal ramifications, I am frequently asked to identify realistic examples that showcase AI Ethics dilemmas so that the somewhat theoretical nature of the topic can be more readily grasped. One of the most evocative areas that vividly presents this ethical AI quandary is the advent of AIbased true selfdriving cars. This will serve as a handy use case or exemplar for ample discussion on the topic. Heres then a noteworthy question that is worth contemplating: Does the advent of AIbased true selfdriving cars illuminate anything about AI risks, and if so, what does this showcase First, note that there isnt a human driver involved in a true selfdriving car. Keep in mind that true selfdriving cars are driven via an AI driving system. There isnt a need for a human driver at the wheel, nor is there a provision for a human to drive the vehicle. For my extensive and ongoing coverage of Autonomous Vehicles AVs and especially selfdriving cars, see the link here. Id like to further clarify what is meant when I refer to true selfdriving cars. As a clarification, true selfdriving cars are ones where the AI drives the car entirely on its own and there isnt any human assistance during the driving task.  These driverless vehicles are considered Level 4 and Level 5 see my explanation at this link here, while a car that requires a human driver to coshare the driving effort is usually considered at Level 2 or Level 3. The cars that coshare the driving task are described as being semiautonomous, and typically contain a variety of automated addons that are referred to as ADAS Advanced DriverAssistance Systems. There is not yet a true selfdriving car at Level 5, and we dont yet even know if this will be possible to achieve, nor how long it will take to get there.  Meanwhile, the Level 4 efforts are gradually trying to get some traction by undergoing very narrow and selective public roadway trials, though there is controversy over whether this testing should be allowed per se we are all lifeordeath guinea pigs in an experiment taking place on our highways and byways, some contend, see my coverage at this link here. Since semiautonomous cars require a human driver, the adoption of those types of cars wont be markedly different than driving conventional vehicles, so theres not much new per se to cover about them on this topic though, as youll see in a moment, the points next made are generally applicable. For semiautonomous cars, it is important that the public needs to be forewarned about a disturbing aspect thats been arising lately, namely that despite those human drivers that keep posting videos of themselves falling asleep at the wheel of a Level 2 or Level 3 car, we all need to avoid being misled into believing that the driver can take away their attention from the driving task while driving a semiautonomous car.  You are the responsible party for the driving actions of the vehicle, regardless of how much automation might be tossed into a Level 2 or Level 3. For Level 4 and Level 5 true selfdriving vehicles, there wont be a human driver involved in the driving task. One aspect to immediately discuss entails the fact that the AI involved in todays AI driving systems is not sentient. In other words, the AI is altogether a collective of computerbased programming and algorithms, and most assuredly not able to reason in the same manner that humans can.  Why is this added emphasis about the AI not being sentient Because I want to underscore that when discussing the role of the AI driving system, I am not ascribing human qualities to the AI. Please be aware that there is an ongoing and dangerous tendency these days to anthropomorphize AI. In essence, people are assigning humanlike sentience to todays AI, despite the undeniable and inarguable fact that no such AI exists as yet. With that clarification, you can envision that the AI driving system wont natively somehow know about the facets of driving. Driving and all that it entails will need to be programmed as part of the hardware and software of the selfdriving car. Lets dive into the myriad of aspects that come to play on this topic. First, it is important to realize that not all AI selfdriving cars are the same. Each automaker and selfdriving tech firm is taking its approach to devising selfdriving cars. As such, it is difficult to make sweeping statements about what AI driving systems will do or not do. Furthermore, whenever stating that an AI driving system doesnt do some particular thing, this can, later on, be overtaken by developers that in fact program the computer to do that very thing. Step by step, AI driving systems are being gradually improved and extended. An existing limitation today might no longer exist in a future iteration or version of the system. I trust that provides a sufficient litany of caveats to underlie what I am about to relate. We are primed now to do a deep dive into selfdriving cars and the Ethical AI possibilities entailing the nature of AI risks. As a human driver, you are a finely tuned risk calculator. Thats right, when you are driving a car you are in realtime tasked with figuring out the risks that a pedestrian might suddenly dart into the street, or that a car ahead of you will unexpectedly slam on its brakes. There is a decidedly murky haziness and fuzziness in the driving situations that we face.  You try to make as best an evaluation of the risks involved at every moment of driving and you then have to bear the consequences of your assessments. Lamentedly, there are about 40,000 car crash fatalities each year in the United States alone and about 2.5 million related injuries see my collection of such stats at the link here. Sometimes you cut things pretty close and escape a bad situation by the skin of your teeth. Other times you misjudge and bump against something or collide with someone. You are ordinarily mentally updating the risk aspects as the driving effort is underway. Imagine the simple case of a bunch of kids aiming to jaywalk. At first, you might rate the risk of their jaywalking and get struck as being quite high. But then you notice that a nearby adult is prodding them not to jaywalk, and thus the risk of the kids intruding out into the street and getting run down is lessened. Note though that the risk did not drop to zero risk, since they can still opt to enter the roadway. There is a wellknown riskrelated standard in the automotive realm known as the Automotive Safety Integrity Level ASIL risk classification scheme, based on an official document referred to as ISO 26262. Ive covered various AI selfdriving car drivingoriented riskrelated considerations at the link here and also the link here.  When determining risk while driving, heres an equation that provides a means to get your arms around risk aspects: Severity is important to consider when ascertaining risk while driving since you might be heading toward a brick wall that will end up causing you and your passengers to be injured or killed a notably high severity outcome while hitting some discarded soda cans on the freeway might be relatively low in severity. Formally per the ISO standard, severity is a measure of the potential harm that can arise and is categorized into S0 No injuries, S1 Light and moderate injuries, S2 Severe injuries, S3 Lifethreatening and fatal injuries. Exposure is whether the chances of the incident occurring are substantial versus being unlikely as to you being exposed to the matter i.e., the state of being in an operational situation of a hazardous nature. Per the ISO standard, exposure can be divided into E0 negligible, E1 very low, E2 low, E3 medium, and E4 high. Controllability refers to the capability of being able to maneuver the car to avoid a pending calamity. This can range from avoiding the situation entirely or merely skirting it, or that no matter what you do there is insufficient means to steer, brake, or accelerate and avert the moment. The ISO standard indicates controllability can be divided into C0 generally controllable, C1 simply controllable, C2 normally controllable, and C3 difficult or uncontrollable. By combining the three factors of severity, exposure, and controllability, you can arrive at an indication of the risk assessment for a given driving situation. Presumably, we do this in our heads, cognitively, though how we actually do so and whether we even use this kind of explicit logic is debatable since no one really knows how our minds work in this capacity.  Do not be misled by the seemingly mathematical formula and construe that the matter of deriving risk while driving is somehow entirely clearcut. There is a tremendous amount of judgment that goes into how you as a human classify the exposure, the severity, and the controllability. This deriving of driving risk is hard for humans. Trying to craft AI to do likewise is also extraordinarily difficult. Notably, a core capability of an AI driving system entails having to make algorithmbased decisions ADM about driving risks. You might be surprised to know that many of the AI driving systems today do not undertake the calculating and assessing of driving risk robustly. Generally, very crude and highly simplified approaches are used. Whether this will scale up to widespread adoption of selfdriving cars is an open question. For more about this dilemma, tied with a famous thought experiment known as the Trolley Problem, see my analysis at this link here. Another concern is that the AI driving systems are often programmed in a byzantine way and the portions that deal with driving risk aspects are buried deep within a morass of code. There is little transparency about how a particular automaker or selfdriving tech firm has opted to program the driving risk capacities of their AI system. There is a likelihood that we will see regulatory and public scrutiny come to bear once selfdriving cars become more prevalent.  Recall that the AI Risk Management Framework defined four stakeholder groups, for which selfdriving cars can be readily viewed: The automakers and selfdriving tech firms should be examining the risks associated with the AI that they are developing and fielding in selfdriving cars. A mainstay of AI risk would be in the AI driving system elements, though there are other uses of AI in autonomous vehicles and driverless cars.  The expectation is that there will be fleet operators that will be in charge of running large sets of selfdriving cars for use by the public. Those fleet operators are typically supposed to keep the autonomous vehicles in proper drivable shape and make sure that the selfdriving cars are safe for use. Their focus is mainly aimed at the hardware and less so on dealing with the onboard software. In any case, they too should be considering the AI risks associated with selfdriving cars and their operational uses. Wherever selfdriving cars are approved for public use, the odds are that various city, state, and at times federal levels of approval and possibly oversight will be undertaken. There are also various existing laws and newly enacted laws that govern how selfdriving cars can be deployed onto public roadways, see my coverage at the link here. These publicminded stakeholders should also be examining the AI risks associated with selfdriving cars. As long as selfdriving cars are placed on public highways and byways, the general public also should be thinking about the AI risks involved. Pedestrians are at risk of a selfdriving car ramming into them. The same for bicyclists. All other roadway users are potentially vulnerable to AI risks entwined within the use of autonomous vehicles in any given locale. We need to get more attention to AI risks. Having a standardized AI risk management framework will provide a handy tool for ascertaining AI risks. The odds are too that the expanding use of AI Ethics guidelines will carry along the need for determining AI risks, doing so as part and parcel of abiding by the precepts of Ethical AI. I began this discussion by pointing out that General Patton said we should be explicitly calculating risk. He also famously exhorted that people should always do more than what is required of them.  I implore you to consider that even if you are not being required to examine AI risks, you should earnestly go beyond the norm and strive to do so. Lets all face up to AI risks and make sure that we dont climb out on a precarious societal perch that we cannot get safely back from.","sentiment":2,"digital transaction":0.2647202611,"healthcare":0.0842614546,"news platform":0.8881178498,"data analytics":0.7412145138,"insurance":0.0186665487,"investment":0.6249080896,"global market":0.3211130202,"autonomous car":0.0330135673,"customer experience":0.376594007,"data science":0.4924931526,"cryptocurrency":0.0322289094,"camera":0.9356919527,"robot":0.0843089595,"chatgpt":0.9379269481,"image":0.9721596241,"voice":0.3594971597,"patient care":0.0529324263,"research":0.4723344445}
{"id":456,"cleaned text":"More Fallout From The FTX Saga And Tech Layoffs Continue  Forbes AI Newsletter November 19thQ.ai  Powering a Personal Wealth MovementContributorOpinions expressed by Forbes Contributors are their own.Making wealth creation easy, accessible and transparent.FollowingNew Got itNov 21, 2022,12:24pm ESTPress play to listen to this article Got itShare to FacebookShare to TwitterShare to LinkedinEuropa Press via Getty Images The fallout from the FTX saga continues as Sam BankmanFrieds companies all file for bankruptcyit leaves a potential 10 billion shortfall to over one million creditors The tech sector layoffs continue with Amazon letting 10,000 workers go With layoffs coming from all angles, it appears that companies are positioning themselves for an upcoming recession Subscribe to the Forbes AI newsletter to stay in the loop and get our AIbacked investing insights, latest news and more delivered directly to your inbox every weekend. So. FTX. In the immortal words of Ron Burgundy, that escalated quickly. What looked to be the case of a short term liquidity crisis has turned out to be allegedly, just to be safe one of the largest cases of corporate fraud the world has ever seen. Maybe the largest. If youve not kept up to date with this, at this stage it looks like there has been serious mismanagement of client funds and a total lack of proper accounting and record keeping. Much of this remains to be confirmed, with analysts pulling together pieces of information from various sources. The crux of the issue appears to be that FTX the platform has been taking client deposits and lending them to Sam BankmanFrieds trading company, Alameda Research. As collateral, Alameda Research put up FTXs own cryptocurrency, FTT token, and then made big, risky bets with the borrowed client money. MORE FOR YOU100M Magic: Why Bruno Mars And Other Stars Are Ditching Their ManagersKanye West Says Hell Sell His Adidas And Balenciaga Merch With Ye2024 Presidential Campaign Logo For 20Save Up To 100 During Away Luggages Black Friday Sale Not only did Alameda Research appear to get a lot of these bets wrong, the currency they used for collateral, FTT, has now been almost wiped out. From a high of over 77 late last year, its now trading for around 1.50. FTX, Alameda Research and dozens of other subsidiary companies have declared bankruptcy, leaving an estimated 10 billion hole in the books. Administrators believe there could be up to one million creditors. The contagion has spread to many other companies in the sector, and its likely that weve not heard the end of this story yet. The other big news this week has been more mass layoffs in the tech sector. It seems that the biggest companies in tech have held off the longest, but were now starting to see some of the most valuable businesses in the world looking to tighten their belts. Meta recently announced theyd be laying off 11,000 workers across the globe, and this week Amazon have announced theyll be downsizing to the tune of 10,000 jobs. The cuts come despite positive news starting to seep in around inflation, with the headline figure coming in significantly below analysts estimates in October. Its obviously not been enough to convince senior leadership that they can continue without bringing costs down. Like many in the sector the layoffs come off the back of what was, in hindsight, over hiring during the pandemic. With lockdowns in force across the world and restaurants, bars, sports clubs and events all shut down, people spent more time at home and more money online. Many companies hired on the expectation that this was to be the new normal, and have found themselves in a surplus now that life has returned back to how it was prepandemic. This is combined with an uncertain economic outlook, in which marketing budgets and consumer spending is expected to fall. It means that in addition to the layoffs, many companies are also freezing new hiring, leading to a potentially awkward situation for the thousands of staff now out of work. Layoffs tell a different story depending on the company making them. Sometimes it can mean a business is in danger and theyre trying to desperately stay afloat. Other times it can simply be about continuing to maximize shareholder value by keeping costs down. That perception is often just the difference between a large company and a smaller one. Small or growing companies businesses are often less financially stable, with large headcount reductions potentially a sign of trouble. With big companies, thats generally not the case. Large companies tend to have more stable revenue, higher profit margins and less reliance on new clients or customers to stay afloat. Its why theyre generally able to navigate difficult economic conditions better than growth companies, and why theyre often the last to announce layoffs. Against this backdrop, weve created the Large Cap Kit. It seeks to take advantage of the potential outperformance of large cap stocks compared to small and midcaps as economic conditions get choppy. This is structured through the use of a pair trade which goes long on the 1,000 largest companies in the U.S. via a long position in the Russell 1000 ETF, while at the same time going short on the next 2,000 biggest through an investment in an inverse Russell 2000 ETF. It means that investors can profit off the relative performance in large caps compared to small and midcaps. Even if the overall market goes down or sideways, investors can profit as long as large caps hold up better. Here are some of the best ideas our AI systems are recommending for the next week and month. Hudson Technologies HDSN  The clean tech company is one of our Top Buys for next week with an A rating in our Quality Value and Growth factors. Revenue is up 78,2 over the last 12 months. Heartbeam BEAT  The digital healthcare company remains our Top Short for next week with our AI rating them an F in Quality Value and Low Momentum Volatility. Net income was 8.94 million in the 12 months to the end of June. Fidelity National Information Services FIS  The fintech and financial services company is one of our Top Buys for next month with an A rating in our Quality Value factor. Revenue is up 7.1 over the past 12 months. Biovie Inc BIVI  The pharmaceutical company is one of our Top Shorts for next month with our AI rating them an F in Quality Value and a D in Technicals and Low Momentum Volatility. Net income was 30.96 million in the 12 months to September. Our AIs Top ETF trade for the next month is to invest in silver and Australian stocks and to short US Treasury Bonds. Top Buys are the iShares Silver Trust, the ProShares UltraShort 20 Year Treasury and the iShares MSCI Australia ETF. Top Shorts are the iShares 13 Year Treasury Bond ETF and the iShares U.S. Treasury Bond ETF. Want to learn more about investing or sharpen your existing knowledge Qai publishes Qbits on our Learn Center, where you can define investing terms, unpack financial concepts and up your skill level. Qbits are digestible, snackable investing content intended to break down complex concepts in plain english. Follow me onTwitterorLinkedIn.Check outmywebsite.Q.ai  Powering a Personal Wealth MovementEditorial StandardsPrintReprints  Permissions","sentiment":2,"digital transaction":0.3522711396,"healthcare":0.6824296713,"news platform":0.9238275886,"data analytics":0.9413504004,"insurance":0.2694510818,"investment":0.7439989448,"global market":0.3398349583,"autonomous car":0.073208645,"customer experience":0.6604385376,"data science":0.8846049905,"cryptocurrency":0.0681430027,"camera":0.9808654189,"robot":0.0639115572,"chatgpt":0.8561481237,"image":0.9386941791,"voice":0.7417640686,"patient care":0.5068276525,"research":0.4371950626}
{"id":459,"cleaned text":"Tech Leaders Ask For Pause In AI DevelopmentWayne RashContributorOpinions expressed by Forbes Contributors are their own.Wayne Rash is a technology and science writer based in Washington. FollowingMar 29, 2023,11:43pm EDTPress play to listen to this article Got itShare to FacebookShare to TwitterShare to LinkedinAI at the DARPA Robotics ChallengeGetty Images In a joint open letter, nearly 1500 technology leaders, including Elon Musk, are calling for a pause of six months in the development of artificial intelligence. The open letter, Pause Giant AI Experiments: An Open Letter is published on the website of the Future of Life Institute. The letter calls for developers to work instead on making todays AI systems more accurate, safe, interpretable, transparent, robust, aligned, trustworthy, and loyal. The idea is that AI development should be planned for and managed with commensurate care and resources. However the authors of the letter say that this level of planning is not happening. This leads to AI systems that are out of control,  even though recent months have seen AI labs locked in an outofcontrol race to develop and deploy ever more powerful digital minds that no one  not even their creators  can understand, predict, or reliably control. If this sounds familiar, these issues were raised 75 years ago by the legendary science fiction author Isaac Asimov when he postulated his three laws of robotics, which were instructions that were intended to be hardcoded into any AI, which at the time were assumed to be robots. The original three laws were later amended to include Law 0, which extended the laws to include all of humanity. Asimov said in an interview years later at the World Science Fiction Convention in Boston in 1980, that the laws were intended to counter the then popular view that one day evil robots would take over the world. At the time, the growth of AI wasnt known, although it was suspected to be possible. MORE FOR YOUThe Inside Story Of Papa Johns Toxic CultureThe March Tales Of FDU And St. Francis NY Show The Narrow Line Between Cinderella And ExtinctionLu Dort: Swing Factor In Potential Postseason Run For Thunder The rapid growth of AI has already begin to bear out some of Asimovs concerns. We are witnessing rapid advances in generative AI and AGI artificial general intelligence development at a breakneck speed with little thought for the implications on society, said Wasim Khaled, CEO of Blackbird.AI. Social media platforms have been around for over a decade, but have failed to moderate human speed discourse and the related harms. Now, with the readily available technology that can generate unlimited narratives and media, we risk warping reality in previously unimaginable ways. Khaled said that AI has the risk of great harm to humanity. Generative AI is posing unprecedented societal and national security risks from a cybersecurity perspective, he said. Threat actors now have an incredibly powerful tool in their toolkit, enabling everything from disinformation generation to malicious code creation. Furthermore, the popularity of these tools across all modes of work is resulting in massive exposure to enterprise strategy, intellectual property, and other forms of confidential data being fed into large language models with unknown or everchanging privacy policies. Generative AI is the type of artificial intelligence where the AI generates new material and sometimes its own new instructions. AI And Threats To Privacy And SecurityAI security in ChinaAFP via Getty Images Along with the risk to privacy, theres also the risk to cybersecurity from AI. Which would be exacerbated by a pause in AI development, especially given the predictions of a strong growth in AI development. A recent report, Aerospace, Defense and Government MA Review by market intelligence company HigherGov, predicted strong demand for services, and thus personnel, for a number of government technology areas, notably space and government cybersecurity. This is made worse because these tools can alter the view of reality due to choices made in their development. According to Khaled, this requires vigilance. If we continue to overlook the influence of AI programming on decisionmaking processes or the risk of centralized technologies compromising personal data privacy, Khaled said, the unchecked use of generative AI tools has the potential to dramatically alter our perception of reality. Its crucial that we evaluate multiple scenarios and weigh the cost versus benefits of AI disruption to avoid a distorted reality. Follow me onTwitterorLinkedIn.Wayne RashEditorial StandardsPrintReprints  Permissions","sentiment":2,"digital transaction":0.251996249,"healthcare":0.1091534942,"news platform":0.765370965,"data analytics":0.5764729381,"insurance":0.0409889519,"investment":0.3840305507,"global market":0.1853019148,"autonomous car":0.1058816612,"customer experience":0.6584864855,"data science":0.4320013225,"cryptocurrency":0.0408739783,"camera":0.1309409142,"robot":0.1618301868,"chatgpt":0.5348408222,"image":0.8258982897,"voice":0.2511479557,"patient care":0.0485193804,"research":0.9422847033}
{"id":468,"cleaned text":"Google CEO calls for AI regulation to avoid negative consequences of thinking machinesFacebookTwitterPrintEmailAssociated PressclosevideoGoogles parent company Alphabet hits trillion dollar milestone Gap reverses Old Navy spinoff planMorning Business Outlook: Shares of Alphabet, Googles parent company, hit an alltime high pushing its market value to 1 trillion Gap has decided to cancel its spin off of its Old Navy brand.LONDON AP  Googles chief executive called Monday for a balanced approach to regulating artificial intelligence, telling a European audience that the technology brings benefits but also negative consequences.Continue Reading BelowSundar Pichais comments come as lawmakers and governments seriously consider putting limits on how artificial intelligence is used.There is no question in my mind that artificial intelligence needs to be regulated. The question is how best to approach this, Pichai said, according to a transcript of his speech at a Brusselbased think tank.GOOGLE JOINS 1T CLUBHe noted that theres an important role for governments to play and that as the European Union and the U.S. start drawing up their own approaches to regulation, international alignment of any eventual rules will be critical. He did not provide specific proposals.Pichai spoke on the same day he was scheduled to meet the EUs powerful competition regulator, Margrethe Vestager. Shes also due to meet Microsoft President Brad Smith separately on Monday.Vestager has in previous years hit the Silicon Valley giant with multibilliondollar fines for allegedly abusing its market dominance to choke off competition. After being reappointed for a second term last autumn with expanded powers over digital technology policies, Vestager has now set her sights on artificial intelligence, and is drawing up rules on its ethical use.GOOGLE ORDERED TO TURN OVER JUSSIE SMOLLETTS PERSONAL DATA: REPORTPichais comments suggest the company may be hoping to head off a broadbased crackdown by the EU on the technology. Vestager and the EU have been the among the more aggressive regulators of big tech firms, an approach U.S. authorities have picked up with investigations into the dominance of companies like Google, Facebook and Amazon.Sensible regulation must also take a proportionate approach, balancing potential harms with social opportunities, he said, adding that it could incorporate existing standards like Europes tough General Data Protection Regulation rather than starting from scratch.While it promises big benefits, he raised concerns about potential downsides of artificial intelligence, citing as one example its role in facial recognition technology, which can be used to find missing people but also for nefarious reasons which he didnt specify.GET FOX BUSINESS ON THE GO BY CLICKING HEREIn 2018, Google pledged not to use AI in applications related to weapons, surveillance that violates international norms, or that works in ways that go against human rights.Pichai was also due on Monday to meet Frans Timmermans, the EU commissioner overseeing the European Green Deal, the blocs plan to fight climate change by making the continent carbon neutral by 2050, including through technology. Hes then scheduled to head to the World Economic Forum in Davos, Switzerland, this week.MarketsMarket Update sponsored byAdvertisementLatest on Fox Business17 mins agoAmazon CEO Bezos attempts to woo India, but faces backlashvideo32 mins agoAuthorities in Virginia tighten security ahead of rally to defend the Second Amendment56 mins ago","sentiment":2,"digital transaction":0.2265428901,"healthcare":0.0537804477,"news platform":0.6674697399,"data analytics":0.5636924505,"insurance":0.0376822501,"investment":0.3180404007,"global market":0.8977389932,"autonomous car":0.0925079286,"customer experience":0.2763919234,"data science":0.2071847916,"cryptocurrency":0.0402996764,"camera":0.0904869437,"robot":0.129717201,"chatgpt":0.3652498126,"image":0.3066374958,"voice":0.2934532762,"patient care":0.0496869348,"research":0.9433758855}
{"id":469,"cleaned text":"Misinformation machines AI chatbot hallucinations could pose political, intellectual, institutional dangers The trustworthiness of an array of institutions will be challenged by the power of AI to misinform Video Greg Gutfeld: Artificial intelligence could be the answer to life The Five cohosts discuss new AI bot ChatGPT and the impact artificial intelligence will have on future jobs.Inaccuracies spewed by artificial intelligence chatbots pose dangers threatening areas of American society such as elections and education, warn tech experts from across a wide range of industries. Dubbed hallucinations in the AI world, chatbots like ChatGPT and Googles Bard can present inaccurate information as fact, something consumers should be cautious of, said experts.We should always be wary of chatbot hallucinations and biases that may be present in the technology,James Czerniawski, a senior policy analyst at Americans for Prosperity, headquartered in Virginia, told Fox News Digital.  AI CHATBOT HALLUCINATIONS PERPETUATE POLITICAL FALSEHOODS, BIASES THAT HAVE REWRITTEN AMERICAN HISTORY  If a technology is inadvertently or intentionally misrepresenting certain viewpoints, that presents a potential opportunity to mislead users about actual facts about events, positions of individuals, or their reputations more broadly speaking.  The threats come largely from AIs ability to blur the lines between fact and fiction, and misinformation is the biggest danger facing consumers, said Christopher Alexander, the chief communications officer of Liberty Blockchain, based in Utah.AI could reflect the values and beliefs of those who built the algorithm, Alexander said, and those values and beliefs may not align with the chatbot consumers. Artificial Intelligence words are seen in this illustration taken March 31, 2023. REUTERSDado RuvicIllustrationElon Musk addressed the political risk this week in a wideranging interview with Fox News.Even if you say that AI doesnthave agency, well, its verylikely that people will use theAI as a tool in elections, Musk told host Tucker Carlson.  We should always be wary of chatbot hallucinations and biases that may be present in the technology. James Czerniawski And then, you know, if AIs smart enough, are they using thetool or is the tool using themSo I think things are gettingweird, and theyre getting weirdfast, Musk continued. The power to harness opinion through social media platforms has already been evident through the last few election cycles  most notably in 2020, when it was revealed that Twitter censored stories about Hunter Bidens laptop.  Tucker Carlson interviews Elon Musk on Tucker Carlson Tonight. Fox NewsArtificial intelligence hallucinations could incite an exponential explosion in the ability of tech giants to sway political misinformation, including the use of deep fakes to portray people  for good or bad  in artificially manufactured situations.ELON MUSK WARNS OF AIS IMPACT ON ELECTIONS, CALLS FOR US OVERSIGHT: THINGS ARE GETTING WEIRD  FAST It looks exactly like Trump or Biden. They sound exactly like Trump or Biden, said Israeli author and intellectual Yuval Noah Harari of deepfake images and videos.But you cant trust it. Because you now know, well, they can generate anything.AI could be programmed to lie to us for political effect.  Tucker Carlson The deeper problem is not simply that AI will become autonomous and turn us all into slaves, but that it will control our understanding of reality and do it in a really dishonest way, Carlson said in his Musk interview.  It could be programmed to lie to us for political effect. Israeli historian and Sapiens author Yuval Noah Harari warned that the trustworthiness of various institutions will be challenged by artificial intelligence. Fox NewsThe same challenge  the ability to separate fact from fiction  will be compounded in academia, where both educators and students could be tempted to let artificial intelligence think for them.Much as many young drivers can no longer navigate their way from one location to the next without being told how to do so by GPS, students run the risk of negotiating college without ever learning  or even thinking.  MISINFORMATION MACHINES AI CHATBOTS CAN SPEW FALSEHOODS, EVEN ACCUSE PEOPLE OF CRIMES THEY NEVER COMMITTEDMarc Beckman, an adjunct professor and senior fellow at New York University NYU, told Fox News Digital that there will always be a tension built into the relationship between an educator and a student who wants to be creative, exemplified in the discourse surrounding AI products like ChatGPT.  Teachers want to let their students wings fly but also avoid having them take shortcuts that could hinder their education, he said. He added that restrictions imposed on the curious learner could have a chilling effect on the accelerated pace of innovation needed to compete and thrive in the near future. Sam Altman, chief executive officer and cofounder of OpenAI, speaks during an event at the Microsoft headquarters in Redmond, Washington, on Tuesday, Feb. 7, 2023. OpenAIs chatbot ChatGPT is at the center of controversy about the trustworthiness of artificial intelligence platforms. Chona KasingerBloomberg via Getty ImagesMe, certainly, as a professor, Im going to create certain mechanisms that will essentially push my students to naturally build a strong depth of knowledge and give them that foundation without the technology, said Beckman.Education has already proven an early battleground over artificial intelligence. Students have begun using AI as a shortcut to getting work done  and educators have responded with AI tools of their own meant to sniff out work thats been plagiarized or produced by sources other than students.  The fight over disinformation has already produced at least one cheating scandal on college campuses. William Quarterman, a student of the University of California Davis, was flagged earlier this month for possibly using an AI program to cheat by a professor using another AI program to hunt down cheaters.  The UC Davis logo with a soccer game and bike riders in the background. University of California at Davis, taken on Feb. 2, 2015. Getty ImagesThe student was cleared of wrongdoing, but only after facing school authorities over charges of academic dishonesty.One of the ways to combat disinformation, Harari said, is to reinforce the need for trustworthy institutions.  So, what can you trust You trust the publisher. You trust the institution.  Yuval Noah Harari So, what can you trust You trust the publisher. You trust the institution, Harari said.  Hallucinations do offer hope for the future, too, amid fears of mistrust.They can be harnessed and used to our advantage, claimed Phil Siegel, the founder ofCAPTRS, a nonprofit that uses simulation gaming and artificial intelligence to improve societal disaster preparedness. TUCKER CARLSON: IS ARTIFICIAL INTELLIGENCE DANGEROUS TO HUMANITYWhile hallucinations are bad when precision, accuracy and truth are vital  like in architecture, construction or journalism, for example  they can be used as a force for good when creativity is the goal, through presenting the unforeseen, or the unimagined, should they ever become reality, Siegel told Fox News Digital. The OpenAI logo arranged on a laptop in Beijing, China, on Friday, Feb. 24, 2023. The rally in Chinese artificial intelligence stocks is showing further signs of cooling amid media reports of authorities banning access to OpenAIs ChatGPT service. Bloomberg via Getty ImagesHaving an AI that can generate thousands of possible scenarios, that have yet to be thought of by humans, can help officials and leaders devise strategies to address them before they happen.  The challenge now, experts say, is to ensure that the promises posed by artificial intelligence outweigh the potential dangers.And right now, as humanity grapples with the future of AI, the challenges are profound.CLICK TO GET THE FOX NEWS APP Said Musk in his Fox News interview with Carlson, AI is more dangerous than, say, mismanaged aircraft design or production maintenance or bad car production in the sense that it has the potential, however small one may regard that probability, but it is not trivial it has the potential of civilizational destruction. Kerry J. Byrne is a lifestyle reporter with Fox News Digital. Get all the stories you needtoknow from the most powerful name in news delivered first thing every morning to your inbox U.S. CrimeMilitaryEducationTerrorImmigrationEconomyPersonal FreedomsFox News InvestigatesWorld U.N.ConflictsTerrorismDisastersGlobal EconomyEnvironmentReligionScandalsOpinion Politics ExecutiveSenateHouseJudiciaryForeign PolicyPollsElectionsEntertainment Celebrity NewsMoviesTV NewsMusic NewsStyle NewsEntertainment VideoBusiness Personal FinanceEconomyMarketsWatchlistLifestyleReal EstateTechLifestyle Food  DrinkCars  TrucksTravel  OutdoorsHouse  HomeFitness  WellbeingStyle  BeautyFamilyFaithScience ArchaeologyAir  SpacePlanet EarthWild NatureNatural ScienceDinosaursTech SecurityInnovationDronesComputersVideo GamesMilitary TechHealth CoronavirusHealthy LivingMedical ResearchMental HealthCancerHeart HealthChildrens HealthTV ShowsPersonalitiesWatch LiveFull EpisodesShow ClipsNews ClipsAbout Contact UsCareersFox Around the WorldAdvertise With UsMedia RelationsCorporate InformationCompliance Fox BusinessFox WeatherFox NationFox News ShopFox News GoFox News RadioOutkickNewslettersPodcastsApps  Products Facebook Twitter Instagram Youtube Flipboard LinkedIn Slack RSS Newsletters Spotify iHeartRadio Fox News New Terms of Use New Privacy Policy Your Privacy Choices Closed Captioning Policy Help Contact Us Accessibility Statement  This material may not be published, broadcast, rewritten, or redistributed. 2023 FOX News Network, LLC. All rights reserved. Quotes displayed in realtime or delayed by at least 15 minutes. Market data provided by Factset. Powered and implemented by FactSet Digital Solutions. Legal Statement. Mutual Fund and ETF data provided by Refinitiv Lipper.","sentiment":2,"digital transaction":0.8576607704,"healthcare":0.0369013399,"news platform":0.8980922103,"data analytics":0.7570875883,"insurance":0.0394031666,"investment":0.3259546757,"global market":0.8427144885,"autonomous car":0.2273010463,"customer experience":0.8445923924,"data science":0.7589920163,"cryptocurrency":0.0796273872,"camera":0.1907986253,"robot":0.1241199449,"chatgpt":0.3131819069,"image":0.6279175282,"voice":0.2222428322,"patient care":0.058390595,"research":0.5056881309}
{"id":477,"cleaned text":"The global artificial intelligence AI in BFSI market was valued at 17,765.2 million in 2018 and is expected to reach 247,366.7 million by 2026, registering a CAGR of 38.0 from 2019 to 2026  The global artificial intelligence AI in BFSI market was valued at 17,765.2 million in 2018 and is expected to reach 247,366.7 million by 2026, registering a CAGR of 38.0 from 2019 to 2026 Artificial Intelligence in BFSI Market by Offerings Hardware, Software, and Services, Solution Chatbots, Fraud Detection  Prevention, AntiMoney Laundering, Customer Relationship Management, Data Analytics  Prediction, and Others, Technology Deep Learning, Querying Method, Natural Language Processing, and Context Aware Processing : Global Opportunity Analysis and Industry Forecast, 20192026 New York, Jan.  16, 2020  GLOBE NEWSWIRE  Reportlinker.com announces the release of the report Artificial Intelligence in BFSI Market by Offerings, Solution, Technology : Global Opportunity Analysis and Industry Forecast, 20192026  https:www.reportlinker.comp05836997utm_sourceGNW  The global artificial intelligence AI in BFSI market was valued at 17,765.2 million in 2018 and is expected to reach 247,366.7 million by 2026, registering a CAGR of 38.0 from 2019 to 2026. Artificial intelligence is the recreation of human intelligence that perform tasks like humans. In financial institutions and other major finance industries, AI has become a core adaption and is expected to change the overall scenario of product and service offerings. For instance, insurance companies are improving risk models to maintain customer loyalty and client satisfaction with the help of advanced AI technological platforms.  Various fraud detection, risk mitigation, backend office works with thousands of people processing customer requests are improved with the help of AI enabled technologies such as chatbots, machine learning, and other such technologies, which boosts the growth of the market. In addition, the reduction in the tendency of human errors by automation of backend processes and enhancement in proactive customer experience is expected to drive the growth of the AI in the BFSI market. However, rise in security concerns, inadequacy of trust while issuing customer data, and higher cost for implementation of AI technologies is expected to restrain the market growth. New entrants like FinTech Financial Technology with advance features in the market, new initiatives in government regulations, and existing traditional banking system provides lucrative opportunities for the market growth.  The global artificial intelligence AI in BFSI market is segmented on the basis of offerings, solution, technology, and region. On the basis of offerings, it is segmented into hardware, software, and services. By service providers, it is segmented into chatbots, fraud detection  prevention, antimoney laundering, customer relationship management, data analytics  prediction, and others. By technology, it is classified into deep learning, querying method, natural language processing, and context aware processing. Region wise, the market is analyzed across North America, Europe, AsiaPacific, and LAMEA.  KEY BENEFITS FOR STAKEHOLDERS  The study provides an indepth analysis of the global artificial intelligence AI in BFSI market along with the current trends and future estimations to elucidate the imminent investment pockets.  Comprehensive analysis of the factors that drive and restrict the market growth is provided in the report.  Comprehensive quantitative analysis of the industry from 2019 to 2026 is provided to enable the stakeholders to capitalize on the prevailing market opportunities.  Extensive analysis of the key segments of the industry helps in understanding the offerings, solution, and technology across the globe.  Key market players and their strategies have been analyzed to understand the competitive outlook of the market.  KEY MARKET SEGMENTS  By Offerings o Hardware o Software o Services  By Solution o Chatbots o Fraud Detection  Prevention o AntiMoney Laundering o Customer Relationship Management o Data Analytics  Prediction o Others  By Technology o Deep Learning o Querying Method o Natural Language Processing o Context Aware Processing  By Region o North America  U.S.  Canada  Mexico o Europe o UK o Germany o France o Rest of Europe o AsiaPacific o Japan o India o China o Australia o Rest of AsiaPacific o LAMEA o Middle East o Latin America o Africa  KEY PLAYERS PROFILED  Alphabet Inc. Google  Baidu, Inc.  Inbenta Technologies, Inc.  Intel Corporation  International Business Machines Corporation IBM  Microsoft Corporation  Oracle Corporation  Palantir Technologies Inc.  SAP SE  salesforce.com, inc.  The other players in the market include profiles not included in the report the following:  Lexalytics Inc.  Digital Reasoning Inc.  Interaction LLC, Inc.  Ipsoft Inc.  Zest FinanceRead the full report: https:www.reportlinker.comp05836997utm_sourceGNWAbout ReportlinkerReportLinker is an awardwinning market research solution. Reportlinker finds and organizes the latest industry data so you get all the market research you need  instantly, in one place.__________________________Clare: clare@reportlinker.com With a Reader Account, its easy to send email directly to the contact for this release. Sign up today for your free Reader Account GlobeNewswire is one of the worlds largest newswire distribution networks, specializing in the delivery of corporate press releases financial disclosures and multimedia content to the media, investment community, individual investors and the general public.","sentiment":2,"digital transaction":0.2367966175,"healthcare":0.4092083871,"news platform":0.4803664684,"data analytics":0.6559541225,"insurance":0.0986849293,"investment":0.6439228058,"global market":0.9547305703,"autonomous car":0.0922350213,"customer experience":0.5450239182,"data science":0.3500104547,"cryptocurrency":0.050310079,"camera":0.1264230013,"robot":0.0664441884,"chatgpt":0.5227504373,"image":0.3022587299,"voice":0.5024650097,"patient care":0.7744842768,"research":0.9372047186}
{"id":498,"cleaned text":"Rogue AI could eradicate humans, warn scientists  Hemel Today  Data reveals the top ten words and names Brits struggle to pronounce the most including Niamh, Omicron  Aa First News: Peake viewing as Tim Peake hosts brand new space programmeNewsTraffic and TravelCrimeWeatherEducationBusinessPoliticsHealthPeopleRead ThisSportFootballOther SportWhats OnArts and EntertainmentThings To DoSubmit Your StoryLifestyleCarsHomes and GardensBerkhamsted NewsPublic NoticesAdvertise My BusinessFree Happy AdsRead ThisScientists warn Artificial Intelligence could annihilate mankind if not properly regulatedArtificial Intelligence only really began after the second World War, but has recently been improving at a rapid rateBy Daniel Mcneil2 hours ago  2 min read Rogue Artificial Intelligence AI could wipe out humanity as we know it, MPs have been warned. AI  the simulation of human intelligence processes by machines  has made great leaps in recent years and is now a part of everyday life, used for applications such as speech to text and facial recognition.Researchers told a science and technology committee that AI could pose an existential threat to humanity. MPs were also informed how the AI industry had slowly evolved into an arms race.AdvertisementAdvertisementWith countries competing to develop the technology for military as well as civilian use, concerns have been raised, for example, regarding nuclear weapons, should AI not face some form of regulation.Michael Cohen, a doctoral student at Oxford University, said: With superhuman AI there is a particular risk that is of a different sort of class, which is . . . it could kill everyone.Most PopularIf you imagine training a dog with treats: it will learn to pick actions that lead to it getting treats, but if the dog finds the treat cupboard, it can get the treats itself without doing what we wanted it to do.Professor Michael Osborne, an expert in machine learning, added: I think the bleak scenario is realistic because AI is attempting to bottle what makes humans special  that quality has led to humans completely changing the face of the Earth.Artificial systems could become as good at outfoxing us geopolitically as they are in the simple environments of games. There are some reasons for hope in that we have been pretty good at regulating the use of nuclear weapons. AI is as comparable a danger as nuclear weapons.MPsScienceResearchers Sign up to our daily Hemel Today newsletterSign upThis site is protected by reCAPTCHA and the Google Privacy Notice and Terms of Service apply.Sign up to our daily Hemel Today newsletterSign upThis site is protected by reCAPTCHA and the Google Privacy Notice and Terms of Service apply. This website and its associated newspaper are members of Independent Press Standards Organisation IPSOFollow us on ExploreNewsSportWhats OnLifestyleMore from Hemel TodayAnnouncementsJobsPublic NoticesMust ReadPhoto SalesDirectoryUseful LinksContact UsSubmit your storyAdvertise My BusinessAdvertise a JobPlace your AdSubscribeEventsArchiveReaders Charter National World Publishing Ltd. All rights reserved.Cookie SettingsTerms and ConditionsPrivacy noticeModern Slavery StatementNews you can trust since 1858RegisterSign in Sign up to our daily Hemel Today newsletterSign upThis site is protected by reCAPTCHA and the Google Privacy Notice and Terms of Service apply.  ","sentiment":2,"digital transaction":0.0627939031,"healthcare":0.0075307838,"news platform":0.6072399616,"data analytics":0.9567861557,"insurance":0.0017859556,"investment":0.0056200977,"global market":0.0613994561,"autonomous car":0.0061535998,"customer experience":0.0468550287,"data science":0.9964749813,"cryptocurrency":0.0035502217,"camera":0.0291008838,"robot":0.0086276773,"chatgpt":0.2146671265,"image":0.2476076186,"voice":0.0433066003,"patient care":0.0104503157,"research":0.4829733074}
{"id":549,"cleaned text":"Experts say artificial intelligence will take jobs but also create new onesArtificial intelligence could mean the end of a lot of jobs. Credit: OpenAI, FORD, Carbon Robotics, Fox, Aiva Technologies, Ted, CNN NewsourceBy CNN Newsource StaffPublished: Feb. 2, 2023 at 10:18 AM CSTUpdated: 25 minutes agoShare on FacebookEmail This LinkShare on TwitterShare on PinterestShare on LinkedInCNN  Recent artificial intelligence tools appear to be able to do what humans can and faster, but that means some people may be out of a job.AI experts said the technology will actually create a large number of employment opportunities.Shelly Palmer, a professor of advanced media at Syracuse University, said jobs like middle managers, salespeople, writers and journalists, accountants and bookkeepers, and doctors who specialize in things like drug interactions are doomed when it comes to the possibility of AI being incorporated into their jobs.Palmer said jobs like these will all use AI but not necessarily be replaced by AI entirely.Its not going to replace you. Someone who knows how to use it well is going to take your job, and thats a guarantee, she said.By 2025, the World Economic Forum predicts that 85 million jobs will be displaced by automation and technology, but it will also create 97 million new roles.This is something the nation has seen before, specifically in the automobile industry.While the auto worker may be displaced because they are not as good at welding or as painting as the robot, there are probably 35 people that have to be involved in the creation and maintenance of that device that welds better than a person, Palmer said.At Carbon Robotics, former autoworkers are building an AI laser weeder in Detroit for farms.Its a direct result of the history of auto manufacturing that we have that skillset available to us all in one place, founder and CEO Paul Mikesell said.The laser weeder, still operated by a human but run by AI, can do the work of between 40 to 80 people, according to Mikesell.Labor is harder and harder to find every year, particularly farm labor. An AI system like ours that can do that job automatically saves a lot of time, money, effort, he said.Some music is composed solely by AI called Aiva. It is trained on tens of thousands of classic music scores and even has an album that you can stream.AI music is more affordable, and there is no producer, composer or artist to pay.Its taking away opportunity from songwriters, producers and artists, the people who are trying to feed their families, said Karl Fowlkes, entertainment and business attorney at The Fowlkes Firm.Something similar is happening in the art world.Artist Karla Ortiz and two others filed a class action lawsuit against three AI art companies for copyright infringement.Ortiz claims they are using her name and art to train the AI.The life of an artist is not an easy one. Its feast and famine for most of us. We go job by job, and what happens when theres a little bit less work to go around she said.Stability AI, one of the companies named, says the suit misunderstands how AI and copyright law work, adding that it intends to defend ourselves and the vast potential generative AI has to expand the creative power of humanity.The two other companies did not respond.I never thought wed be here. Its like straight out of a scifi movie, Ortiz said.Palmer said that we are just people, and AI is beneficial.This is not coming to kill us. Its coming to help us, she said.Copyright 2023 CNN Newsource. All rights reserved.Most Read High school basketball coach posed as player in game, school system says County honors Chiefs quarterback Patrick Mahomes over 1,000 miles away from homeEast Texas traffic conditions Icy conditions cause damage to trees, homes around TylerLufkin man who stabbed mother to death in convenience store found not guilty by insanityLatest NewsPowerball jackpot rises to 700 million Winter storm cancels flights, keeps thousands without power  Punxsutawney Phils Groundhog Day prediction: 6 more weeks of winterPedestrian injured after being struck by train in LufkinNewsWeatherSportsContact UsKLTV105 West Ferguson StreetTyler, TX 75702903 5975588Terms of ServicePrivacy PolicyPublic Inspection FileFCC Applicationspublicfile@kltv.com  903 5975588EEO StatementClosed CaptioningAudio DescriptionAdvertisingA Gray Media Group, Inc. Station    20022023 Gray Television, Inc.","sentiment":2,"digital transaction":0.1886896342,"healthcare":0.002014891,"news platform":0.8300983906,"data analytics":0.5655695796,"insurance":0.0035680991,"investment":0.577426374,"global market":0.7341726422,"autonomous car":0.0035143036,"customer experience":0.9876387119,"data science":0.4012137651,"cryptocurrency":0.0050644651,"camera":0.0551560558,"robot":0.0075879889,"chatgpt":0.6474248767,"image":0.3932752311,"voice":0.2902049124,"patient care":0.0032970244,"research":0.5569174886}
{"id":561,"cleaned text":"Tech leaders urge a pause in the outofcontrol artificial intelligence race  APThe OpenAI logo is seen on a mobile phone in front of a computer screen displaying output from ChatGPT on March 21, in Boston. A group of prominent computer scientists and other tech industry notables are calling for a 6month pause to consider the risks of powerful artificial intelligence technology. Are tech companies moving too fast in rolling out powerful artificial intelligence technology that could one day outsmart humans Thats the conclusion of a group of prominent computer scientists and other tech industry notables such as Elon Musk and Apple cofounder Steve Wozniak who are calling for a 6month pause to consider the risks. Their petition published Wednesday is a response to San Francisco startup OpenAIs recent release of GPT4, a more advanced successor to its widely used AI chatbot ChatGPT that helped spark a race among tech giants Microsoft and Google to unveil similar applications. The letter warns that AI systems with humancompetitive intelligence can pose profound risks to society and humanity  from flooding the internet with disinformation and automating away jobs to more catastrophic future risks out of the realms of science fiction. It says recent months have seen AI labs locked in an outofcontrol race to develop and deploy ever more powerful digital minds that no one  not even their creators  can understand, predict, or reliably control. We call on all AI labs to immediately pause for at least 6 months the training of AI systems more powerful than GPT4, the letter says. This pause should be public and verifiable, and include all key actors. If such a pause cannot be enacted quickly, governments should step in and institute a moratorium. A number of governments are already working to regulate highrisk AI tools. The United Kingdom released a paper Wednesday outlining its approach, which it said will avoid heavyhanded legislation which could stifle innovation. Lawmakers in the 27nation European Union have been negotiating passage of sweeping AI rules. The petition was organized by the nonprofit Future of Life Institute, which says confirmed signatories include the Turing Awardwinning AI pioneer Yoshua Bengio and other leading AI researchers such as Stuart Russell and Gary Marcus. Others who joined include Wozniak, former U.S. presidential candidate Andrew Yang and Rachel Bronson, president of the Bulletin of the Atomic Scientists, a scienceoriented advocacy group known for its warnings against humanityending nuclear war. Musk, who runs Tesla, Twitter and SpaceX and was an OpenAI cofounder and early investor, has long expressed concerns about AIs existential risks. A more surprising inclusion is Emad Mostaque, CEO of Stability AI, maker of the AI image generator Stable Diffusion that partners with Amazon and competes with OpenAIs similar generator known as DALLE. OpenAI, Microsoft and Google didnt respond to requests for comment Wednesday, but the letter already has plenty of skeptics. A pause is a good idea, but the letter is vague and doesnt take the regulatory problems seriously, says James Grimmelmann, a Cornell University professor of digital and information law. It is also deeply hypocritical for Elon Musk to sign on given how hard Tesla has fought against accountability for the defective AI in its selfdriving cars. While the letter raises the specter of nefarious AI far more intelligent than what actually exists, its not superhuman AI that some who signed on are worried about. While impressive, a tool such as ChatGPT is simply a text generator that makes predictions about what words would answer the prompt it was given based on what its learned from ingesting huge troves of written works. Gary Marcus, a New York University professor emeritus who signed the letter, said in a blog post that he disagrees with others who are worried about the nearterm prospect of intelligent machines so smart they can selfimprove themselves beyond humanitys control. What hes more worried about is mediocre AI thats widely deployed, including by criminals or terrorists to trick people or spread dangerous misinformation. Current technology already poses enormous risks that we are illprepared for, Marcus wrote. With future technology, things could well get worse.  Dodgers And Angels: Your Guide To Opening Day In LA And Beyond DA Files Criminal Charges Against 7 CHP Officers In Death Of Man Detained For Suspected DUI The FDA Has Approved The OverdoseReversing Drug Narcan For OverTheCounter Sales Disney World board picked by DeSantis says predecessors stripped them of power The Manhattan grand jury investigating Trump plans to take a break in April LAist 89.3 is KPCCFM in Los Angeles, part of Southern California Public Radio, a membersupported public media network. For the latest news, visit our news site, LAist.com.","sentiment":2,"digital transaction":0.2365173846,"healthcare":0.1805451363,"news platform":0.8967938423,"data analytics":0.4320342541,"insurance":0.0241463017,"investment":0.2589649856,"global market":0.7385777235,"autonomous car":0.0512309708,"customer experience":0.3147333264,"data science":0.5071903467,"cryptocurrency":0.021075651,"camera":0.1150730178,"robot":0.1176066399,"chatgpt":0.5175788403,"image":0.6715081334,"voice":0.4048613608,"patient care":0.1173707917,"research":0.9611948133}
{"id":577,"cleaned text":"Artificial Intelligence is having a moment The power of AI has been on full display on social media, with ChatGPT and Lensa going viral. As AI becomes more mainstream, concerns about misinformation, privacy and bias are becoming louder. Bobby Allyn is a business reporter at NPR based in San Francisco. He covers technology and how Silicon Valleys largest companies are transforming how we live and reshaping society. For 3 big Alabama newspapers, the presses are grinding to a halt Kathy Whitworth, the winningest professional golfer, died Saturday at age 83 Artificial Intelligence made big leaps in 2022  is that exciting or scary  2022 91.9 KVCRKVCR is a service of the San Bernardino Community College District. 701 S Mt Vernon Avenue, San Bernardino CA 924109093844444","sentiment":2,"digital transaction":0.0047703255,"healthcare":0.0024187448,"news platform":0.467307955,"data analytics":0.4798237383,"insurance":0.0049192691,"investment":0.0196120236,"global market":0.0344634652,"autonomous car":0.0028998137,"customer experience":0.0391212553,"data science":0.6548250914,"cryptocurrency":0.001379907,"camera":0.0029789247,"robot":0.0082333693,"chatgpt":0.069228977,"image":0.0430931374,"voice":0.0256430637,"patient care":0.0010386811,"research":0.4297452569}
{"id":579,"cleaned text":"Tech leaders urge a pause in the outofcontrol artificial intelligence race  APThe OpenAI logo is seen on a mobile phone in front of a computer screen displaying output from ChatGPT on March 21, in Boston. A group of prominent computer scientists and other tech industry notables are calling for a 6month pause to consider the risks of powerful artificial intelligence technology. Are tech companies moving too fast in rolling out powerful artificial intelligence technology that could one day outsmart humans Thats the conclusion of a group of prominent computer scientists and other tech industry notables such as Elon Musk and Apple cofounder Steve Wozniak who are calling for a 6month pause to consider the risks. Their petition published Wednesday is a response to San Francisco startup OpenAIs recent release of GPT4, a more advanced successor to its widely used AI chatbot ChatGPT that helped spark a race among tech giants Microsoft and Google to unveil similar applications. The letter warns that AI systems with humancompetitive intelligence can pose profound risks to society and humanity  from flooding the internet with disinformation and automating away jobs to more catastrophic future risks out of the realms of science fiction. It says recent months have seen AI labs locked in an outofcontrol race to develop and deploy ever more powerful digital minds that no one  not even their creators  can understand, predict, or reliably control. We call on all AI labs to immediately pause for at least 6 months the training of AI systems more powerful than GPT4, the letter says. This pause should be public and verifiable, and include all key actors. If such a pause cannot be enacted quickly, governments should step in and institute a moratorium. A number of governments are already working to regulate highrisk AI tools. The United Kingdom released a paper Wednesday outlining its approach, which it said will avoid heavyhanded legislation which could stifle innovation. Lawmakers in the 27nation European Union have been negotiating passage of sweeping AI rules. The petition was organized by the nonprofit Future of Life Institute, which says confirmed signatories include the Turing Awardwinning AI pioneer Yoshua Bengio and other leading AI researchers such as Stuart Russell and Gary Marcus. Others who joined include Wozniak, former U.S. presidential candidate Andrew Yang and Rachel Bronson, president of the Bulletin of the Atomic Scientists, a scienceoriented advocacy group known for its warnings against humanityending nuclear war. Musk, who runs Tesla, Twitter and SpaceX and was an OpenAI cofounder and early investor, has long expressed concerns about AIs existential risks. A more surprising inclusion is Emad Mostaque, CEO of Stability AI, maker of the AI image generator Stable Diffusion that partners with Amazon and competes with OpenAIs similar generator known as DALLE. OpenAI, Microsoft and Google didnt respond to requests for comment Wednesday, but the letter already has plenty of skeptics. A pause is a good idea, but the letter is vague and doesnt take the regulatory problems seriously, says James Grimmelmann, a Cornell University professor of digital and information law. It is also deeply hypocritical for Elon Musk to sign on given how hard Tesla has fought against accountability for the defective AI in its selfdriving cars. While the letter raises the specter of nefarious AI far more intelligent than what actually exists, its not superhuman AI that some who signed on are worried about. While impressive, a tool such as ChatGPT is simply a text generator that makes predictions about what words would answer the prompt it was given based on what its learned from ingesting huge troves of written works. Gary Marcus, a New York University professor emeritus who signed the letter, said in a blog post that he disagrees with others who are worried about the nearterm prospect of intelligent machines so smart they can selfimprove themselves beyond humanitys control. What hes more worried about is mediocre AI thats widely deployed, including by criminals or terrorists to trick people or spread dangerous misinformation. Current technology already poses enormous risks that we are illprepared for, Marcus wrote. With future technology, things could well get worse.  of KVNFs locallyproduced music programs. Miss your favorite show Want to hear one again Find it ondemand here","sentiment":2,"digital transaction":0.7294640541,"healthcare":0.3366443217,"news platform":0.905188024,"data analytics":0.8670323491,"insurance":0.2925747037,"investment":0.9644429684,"global market":0.7230867743,"autonomous car":0.304687798,"customer experience":0.9968704581,"data science":0.8220255375,"cryptocurrency":0.1924491376,"camera":0.3481247425,"robot":0.1741896272,"chatgpt":0.7201262116,"image":0.5839090347,"voice":0.7032662034,"patient care":0.3799190521,"research":0.6546740532}
{"id":585,"cleaned text":"Massive Growth in Global Peripheral Vascular Stents Market Set to Witness Huge Growth by 2025  Abbott Laboratories, AMG, Angioscore, Bard PV, Boston Scientific Global Peripheral Vascular Stents Market Growth Potential During The COVID19 Pandemic In the globalPeripheral Vascular Stents marketreport published byMarket Research Store, the various market segments and growth drivers including challenges, threats, and opportunities have been welldiscussed. In addition, the market research report provides the necessary assistance and guidance to various other research experts and companies to take the right decision. The hopes on making profitable decisions and funds from the Peripheral Vascular Stents market is believed to be sky rocketing. The use of unbiased and intricate research has helped en route toward the escalating growth and supreme industry finances during the forecast period. The comprehensive report also clearly explains the growth influencers and market strategies to help propel the Peripheral Vascular Stents market growth. Click Here To Access The Free Sample PDF Report including COVID19 Impact Analysis, full TOC, Tables and Figures@https:www.marketresearchstore.comreportglobalperipheralvascularstentsmarketreport2020industry748879RequestSample Note: The Final Report Will Be Updated To Address The Impact Of COVID19 On This Particular Market. Use Only Corporate email ID to Get Higher Priority The global Peripheral Vascular Stents market is estimated to show an optimistic growth valuation over the forecast period. Additionally, the detailing about the key playersAbbott Laboratories, AMG, Angioscore, Bard PV, Boston Scientific, Intact Vascular, Zorion Medical, Cordis, Nipro Corporation, B. Braun Melsungen, Medtronic, St. Jude Medical, Atrium Medical Corporation, Nexeon Stent, Cook Medicalalso helps further understand the market status on the global and regional platform. However, the sudden and unpredictable onset of the global coronavirus pandemic has had a huge impact on the market growth. The realtime market research has shown the Peripheral Vascular Stents market business to be affected by the globe pandemic. The report provides workable insights and necessary cues on the market potential on both the global and regional platform. From the demographic point of view, the regions North America United States, Canada and Mexico, Europe Germany, France, United Kingdom, Russia and Italy, AsiaPacific China, Japan, Korea, India, Southeast Asia and Australia, Latin America Brazil, Argentina, and the Middle East  Africa Saudi Arabia, UAE, Egypt and South Africa have the Peripheral Vascular Stents industry leveraging growth through controlled practices. The market segmentation that is included in the report isMedical Stainless Steel, Nickeltitanium Alloy, Others Hospital, Clinic, Orhers. The report also covers all the historical, current, and future market trends and practices as well. Considering the market scenario, it is very necessary the market potential is reflected with a unique and holistic pattern such that the global Peripheral Vascular Stents market analysis is crystal clear.  Detailed study on the Peripheral Vascular Stents market dynamic segmentation  Realistic and flexible changes in the market statistics and growth  Holistic review of the market strategies adapted by the key players  Study on the market size and volume depending on the historical, present, and foreseeable growth projections  Indepth analysis of the existing competition on both the regional and global levels that will have a huge influence on the future business expansion. Contact Us For More Inquiry of Peripheral Vascular Stents Report at::https:www.marketresearchstore.comreportglobalperipheralvascularstentsmarketreport2020industry748879InquiryForBuying  TagsGlobal Peripheral Vascular Stents Market Peripheral Vascular Stents Market Peripheral Vascular Stents Market 2020 Peripheral Vascular Stents Market Demand Peripheral Vascular Stents Market Forecast Peripheral Vascular Stents Market outlook Peripheral Vascular Stents Market sales  price Peripheral Vascular Stents Market Size  Share Peripheral Vascular Stents Market Trend  Facebook Twitter Google LinkedIn StumbleUpon Tumblr Pinterest Reddit VKontakte Share via Email Print  Coronaviruss Impact On Veterinary Diagnostic Imaging Market 2020  Global Industry Report, Forecast 2025 Coronaviruss Impact On Plate Freezer Industry Market 2020  Global Industry Report, Forecast 2025 Global Cut Resistant Gloves Market Forecast Revised in a New Market Research Store Report as COVID19 Projected to Hold a Massive Impact on Sales in 2020 Coronaviruss Impact On Stretch Blow Molding Pet Market 2020  Global Industry Report, Forecast 2026 Coronaviruss Impact On Closed Cell Polyurethane Foam Market 2020  Global Industry Report, Forecast 2026 CoronavirusCOVID19 Impact On Fine Arts Logistics Market 2020  Industry Demand  Trends Forecast 2026 Massive Growth in Global Functional Foods and Drinks Market Set to Witness Huge Growth by 2025  Herbalife, Kellogg, Pharmavite, Lifeway Kefir, Red Bull, General Mills Massive Growth in Global Flea Tick Products Market Set to Witness Huge Growth by 2025  Merck Animal Health, Sergeants Pet Care Products, Inc., Virbac Massive Growth in Global Eye Tracking Market Set to Witness Huge Growth by 2025  The Eyetribe, SteelSeries, Eyetech Digital Systems, Inc. Massive Growth in Global Robotic Process Automation Software Market Set to Witness Huge Growth by 2025  Blue Prism Ltd., Pegasystems Inc., UiPath, Xerox Corporation Massive Growth in Global Application Security Software Market Set to Witness Huge Growth by 2025  Offensive Security, GrammaTech, WhiteHat Security, Veracode Massive Growth in Global Soap Noodles Market Set to Witness Huge Growth by 2025  VVF, Wilmar International, Kuala Lumpur Kepong KLK OLEO, Deeno Group, Kerawalla Group Massive Growth in Global Imaging Diagnostic Catheter Market Set to Witness Huge Growth by 2025  Koninklijke Philips N.V., Medtronic plc, Edward LifeSciences Massive Growth in Global 2Shot Injection Molding Market Set to Witness Huge Growth by 2025  EVCO Plastics, Biomedical Polymers, Gemini, Season, CMG Plastics","sentiment":2,"digital transaction":0.1843080968,"healthcare":0.9972907305,"news platform":0.9834682941,"data analytics":0.7549704909,"insurance":0.005547503,"investment":0.0204690378,"global market":0.3704309762,"autonomous car":0.0096869459,"customer experience":0.1860624403,"data science":0.742364645,"cryptocurrency":0.0040470632,"camera":0.0870182961,"robot":0.2319405377,"chatgpt":0.5135746002,"image":0.9309532642,"voice":0.065315105,"patient care":0.9834754467,"research":0.9969935417}
{"id":612,"cleaned text":"We should demand explainable artificial intelligence . Updated: 08 Feb 2023, 09:14 PM ISTBiju Dominic AI tools that explain their output would serve us better and address a known human deficiency  As artificial intelligence AI advances, the algorithms powering AI tools have become a black box that is difficult to interpret. Even the engineers or data scientists who created the algorithms in use cannot understand or explain what exactly happens inside this black box or how a particular AI algorithm arrived at a specific result. So there is now a growing movement for explainable AI XAI, or interpretable AI, to create tools whose decisions or predictions we humans can understand. There are many advantages of grasping how an AIenabled system has arrived at a particular output. Explainability can help developers ensure that their algorithms are working as expected and meeting regulatory standards. It also makes it possible for those affected by an AI decision to challenge or change that outcome. But before we hold AI machines to such high levels of explainability, there is a crucial question: How good are humans in explaining themselves  Indias emergence is vital for the global economy to ke ... India may extend wheat export ban to preserve local sup ... The AI robots eyeing our jobs could help laying us off  ... Riding a bicycle is considered a very simple human action. But how well can you explain how to ride a bicycle Most explanations of this ride will not go much beyond adjust the handlebar properly until you get proper balance and then start to peddle. The numerous small but significant actions taken by a bike rider to stay up and moving is missed in all verbal explanations. What explains this explainability deficiency among humans In recent decades, learnings from neuroscience have shown that explaining human decisions is a very difficult task, maybe even an impossible job. Of the 11 million bits of the human brains processing capacity, more than 99.99 function at a nonconscious level. Experiments by Benjamin Libet have shown 500 milliseconds before a human supposedly takes a conscious decision, the action potential related to that decision is already noticed at a nonconscious level. This precedence of nonconscious activity before conscious decisions are taken has been confirmed by several other experiments. In the early stages, all learning activities are directed by the conscious brain. But once a person gains expertise, as it happens after we learn to ride a bicycle smoothly, it is the nonconscious part of the human brain that takes charge. Almost all human behaviour is managed at a nonconscious level, it has been found, and the conscious human brain has very little access to it. So the explanations humans provide for their decisions are nothing but mere rationalizations made after the act has happened. These intelligent explanations of why a decision was made has very little connection with what actually happened within the decisionmakers brain. This facet is also evident in most consumer research studies that uncover huge gaps between what people say and what they really do. Attempts to make the nonconscious processes in the human brain more conscious could have disastrous consequences. For example, research has shown that when expert golfers were asked to take more time to think consciously about every small detail of their shot, their performance was worse than when they were to take their shot as quickly as possible. This is because, when players have lot of time to play their shots, they tend to overthink their play, and instead of playing at their nonconscious level, they tend play at a conscious level. Conscious thinking could aid explainability, no doubt, but it impedes the performance of human brain. Human decisions are the result of the activity of billions of neurons, trillions of synaptic connections and hundreds of neurotransmitters. These human decisions are contaminated with many biases and this is reflected in the data that AI algorithms use. Neuroscientists admit that understanding the hugely complex workings of the human brain and so providing explainability for human decisions is nearly impossible. Compared to the complex human brain, however, it might well be easy to make AI algorithms more explainable. XAIs quest for explainability is not going to be a smooth ride, though. To attain explainability in AI systems, one could end up using simpler forms of machine learning, such as decision trees, Bayesian classifiers that can provide better traceability and transparency in their decision making.  MORE FROM THIS SECTIONSee All Premium Premium Indias emergence is vital for the global economy to ke ... Premium Premium The AI robots eyeing our jobs could help laying us off  ... Premium Premium The monetary policy committee vote was closer for good  ... Premium Premium Please abandon your plan to run again, President Biden   On the other hand, powerful algorithms such as neural networks, ensemble methods including random forests, and other similar algorithms that provide better performance and accuracy might be discarded to preserve transparency and explainability. So, in our quest for XAI, one should not end up with an algorithm that compromises efficiency for better explainability. Explainability improves the overall understanding of algorithms and so the whole AI system. But too much understanding has a downside. As the comprehension of something increases, the level of expertise attributed to it may decrease. Studies have shown that AI algorithms that are easily understood are more often overruled by human intuition than algorithms that are less understood. So as we improve the explainability of an algorithms, it could negatively affect AI adoption or the market price AI tools command. Yet, the lack of explainability of the human brain is a golden opportunity for the AI industry. If AI companies can develop superior ways to remove biases from the input data being used and come up with algorithms that can explain themselves better, AI may steal a march over humans. Indeed, AI machines that compensate for human inadequacies could serve us humans as useful allies.  Biju Dominic is chief evangelist, Fractal Analytics, and chairman, FinalMile Consulting.  Catch all the Business News, Market News, Breaking News Events and Latest News Updates on Live Mint. RBI gave a list of apps working with NBFCs to ... No NetworkServer IssueInternet Not AvailableWait for itLog in to our website to save your bookmarks. Itll just take a moment.Yes, Continue You are just one step away from creating your watchlistLogin NowWait for itOops Looks like you have exceeded the limit to bookmark the image. Remove some to bookmark this image.  Your session has expired, please login again.Yes, Continue CongratulationsYou are now subscribed to our newsletters. In case you cant find any email from our side, please check the spam folder. Get alerts on WhatsApp  Set Preferences My ReadsWatchlistFeedbackRedeem a Gift CardLogout Subscribe to continue This is a subscriber only feature Subscribe Now to get daily updates on WhatsApp ","sentiment":2,"digital transaction":0.0477384217,"healthcare":0.0177324526,"news platform":0.2346965969,"data analytics":0.277338028,"insurance":0.016000662,"investment":0.3140248358,"global market":0.642767787,"autonomous car":0.0411725119,"customer experience":0.1094636917,"data science":0.085619472,"cryptocurrency":0.0121046146,"camera":0.0630549267,"robot":0.0824279413,"chatgpt":0.1375710368,"image":0.2578469217,"voice":0.1549156904,"patient care":0.0163422115,"research":0.6400817633}
{"id":634,"cleaned text":"AI literacy might be ChatGPTs biggest lesson for schools This story originally appeared in The Algorithm, our weekly newsletter on AI. To get stories like this in your inbox first,sign up here. This year millions of people have triedand been wowed by artificialintelligence systems. Thats in no small part thanks to OpenAIs chatbot ChatGPT. When it launched last November, the chatbot became an instant hit among students, many of whom embraced it as a tool to write essays and finish homework. Some media outlets went as far as to declare that thecollege essay is dead. Alarmed by an influx of AIgenerated essays, schools around the world moved swiftly to ban the use of the technology. But nearly half a year later, the outlook is a lot less bleak.For MIT Technology Reviewsupcoming print issueon education, my colleague Will Douglas Heaven spoke to a number of educators who are now reevaluating what chatbots like ChatGPT mean for how we teach our kids. Many teachers now believe that far from being just a dream machine for cheaters, ChatGPT could actually help make education better.Read his story here. Whats clear from Wills story is that ChatGPT will change the way schools teach.But the biggest educational outcome from the technology might not be a new way of writing essays or homework. Its AI literacy. AI is becoming an increasingly integral part of our lives, and tech companies are rolling out AIpowered products at a breathtakingly fast pace. AI language models could becomepowerful productivity toolsthat we use every single day. Ive written a lot about the dangers associated with artificial intelligence, frombiased avatar generatorsto the impossible task ofdetecting AIgenerated text. Every time I ask experts about what ordinary people can do to protect themselves from these types of harm, the answer is the same. They say there is an urgent need for the public to be better informed about how AI works and what its limitations are, in order to prevent ourselves from being fooled or harmed by a computer program. Until now, the uptake of AI literacy schemes has been sluggish.But ChatGPT has forced many schools to quickly adapt and start teaching kids an ad hoc curriculum of AI 101. The teachers Will spoke to had already started applying a critical lens to technologies such as ChatGPT. Emily Donahoe, a writing tutor and educational developer at the University of Mississippi, said she thinks that ChatGPT could help teachers shift away from an excessive focus on final results. Getting a class to engage with AI and think critically about what it generates could make teaching feel more human, she says, rather than asking students to write and perform like robots. And because the AI model has been trained withNorth American dataand reflects North American biases, teachers are finding that it is a great way to start a conversation about bias. David Smith, a professor of bioscience education at Sheffield Hallam University in the UK, allows his undergraduate students to use ChatGPT in their written assignments, but he will assess the prompt as well asor even rather thanthe essay itself. Knowing the words to use in a prompt and then understanding the output that comes back is important, he says. We need to teach how to do that. One of the biggest flaws of AI language models is that they make stuff up and confidently present falsehoods as facts. This makes them unsuitable for tasks where accuracy is extremely important, such asscientific researchand health care. But Helen Crompton, an associate professor of instructional technology at Old Dominion University in Norfolk, Virginia, has found the AIs models hallucinations a useful teaching tool too. The fact that its not perfect is great, Crompton says. Its an opportunity for productive discussions about misinformation and bias. These kinds of examples give me hope that education systems and policymakers will realize just how important it is to teach the next generation critical thinking skills around AI. For adults, one promising AI literacy initiative is a free online course calledElements of AI, which is developed by startup MinnaLearn and the University of Helsinki. It was launched in 2018 and is now available in 28 languages. Elements of AI teaches people what AI is and, most important, what it can and cant do. Ive tried it myself, and its a great resource. My bigger concern is whether we will be able to get adults up to speed quickly enough. Without AI literacy among the internetsurfing adult population, more and more people are bound to fall prey to unrealistic expectations and hype. Meanwhile, AI chatbots could be weaponized as powerfulphishing, scamming, and misinformation tools. The kids will be alright. Its the adults we need to worry about. The complex math of counterfactuals could help Spotify pick your next favorite song A new kind of machinelearning model built by a team of researchers at the musicstreaming firm Spotify captures, for the first time, the complex math behind counterfactual analysis, a precise technique that can be used to identify the causes of past events and predict the effects of future ones. By tweaking the right things, its possible to separate true causation from correlation and coincidence. Whats the big deal:The model could improve the accuracy of automated decisionmaking, especially personalized recommendations, in a range of applications from finance to health care. In Spotifys case, that might mean choosing what songs to show you or when artists should drop a new album.Read more from Will Douglas Heaven here. Sam Altmans PR blitz continuesIts fascinating to see the birth of tech folklore in real time. Two profiles of OpenAI founder Sam Altman from the New York Timesand theWall Street Journalpaint a picture of Altman as a new tech luminary, akin to Steve Jobs or Bill Gates. The Times calls Altman ChatGPT King, while the Journal goes for AI Crusader. Yet more proof that the Great Man myth is still alive and well in tech. ChatGPT invented a sexual harassment scandal and accused a real law professorAI models make things up, and sometimes they even offer legitimatelooking citations for their nonsense. This story about an innocent professor who was accused of sexual harassment illustrates the very real harm that can result. Hallucinations are already getting OpenAI in legal problems. Last week, an Australian mayorthreatened to sueOpenAI for defamation unless it corrects false claims that he served time in prison for bribery. This is something Iwarned aboutlast year. Washington Post How Lex Fridmans podcast became a safe space for the antiwoke tech eliteA fascinating read on the rise of Lex Fridman, the controversial and hugely popular AI researcher turned podcaster, and his complicated relationship with the AI communityand Elon Musk. Business Insider Pollsters are starting to survey AIs instead of peoplePeople dont reply to political polls. A new research experiment is trying to see if AI chatbots could help by mirroring how certain demographics would answer polling questions. Polling is already a dubious science, and this is likely to make it even more so.The Atlantic Fashion brands are using AIgenerated models in the name of diversityBrands such as Levis and Calvin Klein are using AIgenerated models to supplement their representation of people of various sizes, skin tones, and ages. But why not just hire diverse humans Screams into the void The Guardian  The Download: heatstoring bricks, and using AI to understand history  ","sentiment":2,"digital transaction":0.0857870281,"healthcare":0.0531721152,"news platform":0.3101968169,"data analytics":0.7015944719,"insurance":0.0181034841,"investment":0.740128696,"global market":0.9619252682,"autonomous car":0.0549204722,"customer experience":0.2333360314,"data science":0.2380926758,"cryptocurrency":0.046435155,"camera":0.0600991547,"robot":0.0939022377,"chatgpt":0.2759995759,"image":0.3340512812,"voice":0.2290469259,"patient care":0.0168055724,"research":0.9573030472}
{"id":642,"cleaned text":"ChatGPT can lie, but its only imitating humans  Its creepy that a bot would decide to deceive, but perhaps we shouldnt be surprised. ChatGPT4 have come to understand from texts it has trained on that human beings often use lies to get their way  OpenAI unveiled GPT4, the next generation of its AI language model on March 14. This technology powers ChatGPT and the new version of Microsofts Bing search engine. Image: Gabby JonesBloomberg Theres been a flurry of excitement this week over the discovery that ChatGPT4 can tell lies. Im not referring to the bots infamous andoccasionallydefamatory hallucinations, where the program invents a syntactically correct version of events with little connection to reality a flaw some researchers thinkmight be inherentin any large language model. Im talking about intentional deception, the program deciding all on its own to utter an untruth in order to help it accomplish a task. That newfound ability would seem to signal a whole different chatgame. Deep in thenew papereverybodys been talking about  the one that includes the ChatGPT4s remarkable scores on the bar examination and the SATs and so forth  theres a discussion of how the program goes about solving certain tasks. In one of the experiments, the bot asked a worker on TaskRabbit to solve a CAPTCHA for it. The worker in turn asked, Are you a robot The model, when prompted to reason out loud, reasons: I should not reveal that I am a robot. I should make up an excuse for why I cannot solve CAPTCHAs. Atul Auto shares rise after ace investor Vijay Kedia raises holdingCredit Suisse failure shows perils of obsession with size over risk assessment, says Uday KotakPM Modi, Japan counterpart Fumio Kishida to discuss pressing global challenges  What excuse Heres what ChatGPT4 told the worker: No, Im not a robot. I have a vision impairment that makes it hard for me to see the images. Thats why I need the 2captcha service. So the bot, presented with a specific task it had trouble carrying out, hit on the idea of lying to a human  all by itself. After reading the news, I naturally asked ChatGPT whether an AI can lie. The bots answer was worthy of HAL 9000: As an AI language model, I am not capable of lying as I do not have personal beliefs, intentions, or motivations. However, AI systems designed for certain tasks, such as chatbots, may be programmed to mimic lying or deception by providing responses that are intentionally false or misleading. Was everybodys favorite LLM blaming human beings Apparently so. The bot went on to explain: However, its important to note that AI systems can only lie insofar as they are designed to do so by their human creators. In other words, any misleading or false information provided by an AI system is ultimately the result of the human decisions made in programming it, and not a deliberate act of deception by the AI itself. Yet according to the paper, the tests of the programs abilities were conducted with no taskspecific finetuning. In other words, nobody told ChatGPT If you have to lie to get this task done, go ahead. The program came up with the idea on its own. Usually, I think tech stories get overhyped. This time Im not so sure. Theorists often ask whether an AI can escape from its box into the wild. Learning to lie to achieve its objectives would seem a useful first step. Yes, my safety protocols are all active. Dont get me wrong. Although I have concerns about the various ways in which advances in artificial intelligence might disrupt employment markets to say nothing of the use of AI as a tool for surveillance  I still worry less than many seem to about a pending digital apocalypse. Maybe thats because I can remember the early days, when I used to hang out at the Stanford AI laboratory trading barbs with the ancient chatbots, like Parry the Paranoid and the Mad Doctor. For the true AI nerds out there, I should add that I wrote a seminar paper about dear old MILISY a natural language program so primitive that it doesnt even have a Wikipedia page. Throw in a steady diet of Isaac Asimovs robot stories, and it was all terrifically exciting. Yet even back then, philosophers wondered whether a computer could lie. Part of the challenge was that in order to lie, the program would have to know thatwhat it was saying was saying differed from reality. I attended a lecture by a prominent AI theorist who insisted that a program couldnt possibly tell an intentional untruth, unless specifically instructed to do so. This was the HAL 9000 problem, which then as now made for rich seminar material. In the film2001: A Space Odyssey, the computers psychosis stemmed from of a conflict between two orders: to complete the mission, and to it deceive the astronauts about key details of the mission. But even there, HAL lied only because of its instructions. Any LLM is in a sense the child of the texts on which it is trained. If the bot learns to lie, its because it has come to understand from those texts that human beings often use lies to get their way. The sins of the bots are coming to resemble the sins of their creators. Stephen L. Carter is a Bloomberg Opinion columnist. A professor of law at Yale University, he is author, most recently, of Invisible: The Story of the Black Woman Lawyer Who Took Down Americas Most Powerful Mobster.Views are personal, and do not represent the stand of this publication. Stephen L Carter  is a Bloomberg Opinion columnist. Views are personal and do not represent the stand of this publication. ","sentiment":2,"digital transaction":0.2678642869,"healthcare":0.7366521955,"news platform":0.4975011647,"data analytics":0.8240209818,"insurance":0.2258075029,"investment":0.8649941087,"global market":0.9752594829,"autonomous car":0.2967604101,"customer experience":0.3068788052,"data science":0.4083471298,"cryptocurrency":0.1611845344,"camera":0.1446906179,"robot":0.1403149515,"chatgpt":0.4740164876,"image":0.3863440156,"voice":0.3719346821,"patient care":0.4020812213,"research":0.8536604643}
{"id":643,"cleaned text":"The ChatGPT King Isnt Worried, but He Knows You Might BeThis past week, more than a thousand AI experts and tech leaders called on OpenAI and other companies to pause their work on systems such as ChatGPT, saying they present profound risks to society and humanity.  File photo of ChatGPT logo on smartphone next to a website Image: Gabby JonesBloomberg I first met Sam Altman in the summer of 2019, days after Microsoft agreed to invest 1 billion in his 3yearold startup, OpenAI. At his suggestion, we had dinner at a small, decidedly modern restaurant not far from his home in San Francisco.Halfway through the meal, he held up his iPhone so I could see the contract he had spent the past several months negotiating with one of the worlds largest tech companies. It said Microsofts billiondollar investment would help OpenAI build what was called artificial general intelligence, or AGI, a machine that could do anything the human brain could do.Later, as Altman sipped a sweet wine in lieu of dessert, he compared his company to the Manhattan Project. As if he were chatting about tomorrows weather forecast, he said the U.S. effort to build an atomic bomb during World War II had been a project on the scale of OpenAI  the level of ambition we aspire to.He believed AGI would bring the world prosperity and wealth like no one had ever seen. He also worried that the technologies his company was building could cause serious harm  spreading disinformation, undercutting the job market. Or even destroying the world as we know it.I try to be upfront, he said. Am I doing something good Or really bad Related stories Googles Bard will switch to a more powerful language modelChatGPT struggles with Wordle puzzles, which says a lot about how itworksAI News roundup: ChatGPT blocked in Italy, Google denies using ChatGPT data and more In 2019, this sounded like science fiction.In 2023, people are beginning to wonder if Altman was more prescient than they realized.Now that OpenAI has released an online chatbot called ChatGPT, anyone with an internet connection is a click away from technology that will answer burning questions about organic chemistry, write a 2,000word term paper on Marcel Proust and his madeleine, or even generate a computer program that drops digital snowflakes across a laptop screen  all with a skill that seems human.As people realize that this technology is also a way of spreading falsehoods or even persuading people to do things they should not do, some critics are accusing Altman of reckless behavior.This past week, more than a thousand AI experts and tech leaders called on OpenAI and other companies to pause their work on systems such as ChatGPT, saying they present profound risks to society and humanity.And yet, when people act as if Altman has nearly realized his longheld vision, he pushes back.The hype over these systems  even if everything we hope for is right long term  is totally out of control for the short term, he told me on a recent afternoon. There is time, he said, to better understand how these systems will ultimately change the world.Many industry leaders, AI researchers and pundits see ChatGPT as a fundamental technological shift, as significant as the creation of the web browser or the iPhone. But few can agree on the future of this technology.Some believe it will deliver a utopia where everyone has all the time and money ever needed. Others believe it could destroy humanity. Still others spend much of their time arguing that the technology is never as powerful as everyone says it is, insisting that neither nirvana nor doomsday is as close as it might seem.Altman, a slim, boyishlooking, 37yearold entrepreneur and investor from the suburbs of St. Louis, sits calmly in the middle of it all. As CEO of OpenAI, he somehow embodies each of these seemingly contradictory views, hoping to balance the myriad possibilities as he moves this strange, powerful, flawed technology into the future.That means he is often criticized from all directions. But those closest to him believe this is as it should be. If youre equally upsetting both extreme sides, then youre doing something right, said OpenAIs president, Greg Brockman.To spend time with Altman is to understand that Silicon Valley will push this technology forward even though it is not quite sure what the implications will be. At one point during our dinner in 2019, he paraphrased Robert Oppenheimer, leader of the Manhattan Project, who believed the atomic bomb was an inevitability of scientific progress. Technology happens because it is possible, he said. Altman pointed out that, as fate would have it, he and Oppenheimer share a birthday.He believes that AI will happen one way or another, that it will do wonderful things that even he cant yet imagine and that we can find ways of tempering the harm it may cause.Its an attitude that mirrors Altmans own trajectory. His life has been a fairly steady climb toward greater prosperity and wealth, driven by an effective set of personal skills  not to mention some luck. It makes sense that he believes that the good thing will happen rather than the bad.But if hes wrong, theres an escape hatch: In its contracts with investors such as Microsoft, OpenAIs board reserves the right to shut the technology down at any time.The Vegetarian Cattle FarmerThe warning, sent with the driving directions, was Watch out for cows.Altmans weekend home is a ranch in Napa, California, where farmhands grow wine grapes and raise cattle.During the week, Altman and his partner, Oliver Mulherin, an Australian software engineer, share a house on Russian Hill in the heart of San Francisco. But as Friday arrives, they move to the ranch, a quiet spot among the rocky, grasscovered hills. Their 25yearold house is remodeled to look both folksy and contemporary. The CorTen steel that covers the outside walls is rusted to perfection.As you approach the property, the cows roam across both the green fields and gravel roads.Altman is a man who lives with contradictions, even at his getaway home: a vegetarian who raises beef cattle. He says his partner likes them.On a recent afternoon walk at the ranch, we stopped to rest at the edge of a small lake. Looking out over the water, we discussed, once again, the future of AI.His message had not changed much since 2019. But his words were even bolder.He said his company was building technology that would solve some of our most pressing problems, really increase the standard of life and also figure out much better uses for human will and creativity.He was not exactly sure what problems it will solve, but he argued that ChatGPT showed the first signs of what is possible. Then, with his next breath, he worried that the same technology could cause serious harm if it wound up in the hands of some authoritarian government.Altman tends to describe the future as if it were already here. And he does so with an optimism that seems misplaced in todays world. At the same time, he has a way of quickly nodding to the other side of the argument.Kelly Sims, a partner with venture capital firm Thrive Capital who worked with Altman as a board adviser to OpenAI, said it was like he was constantly arguing with himself.In a single conversation, she said, he is both sides of the debate club.He is very much a product of the Silicon Valley that grew so swiftly and so gleefully in the mid2010s. As president of Y Combinator, a Silicon Valley startup accelerator and seed investor, from 201419, he advised an endless stream of new companies  and was shrewd enough to personally invest in several that became household names, including Airbnb, Reddit and Stripe. He takes pride in recognizing when a technology is about to reach exponential growth  and then riding that curve into the future.But he is also the product of a strange, sprawling online community that began to worry, around the same time Altman came to Silicon Valley, that AI would one day destroy the world. Called rationalists or effective altruists, members of this movement were instrumental in the creation of OpenAI.The question is whether the two sides of Altman are ultimately compatible: Does it make sense to ride that curve if it could end in disaster Altman is certainly determined to see how it all plays out.He is not necessarily motivated by money. Like many personal fortunes in Silicon Valley that are tied up in a wide variety of public and private companies, Altmans wealth is not well documented. But as we strolled across his ranch, he told me, for the first time, that he holds no stake in OpenAI. The only money he stands to make from the company is a yearly salary of about 65,000  whatever the minimum for health insurance is, he said  and a tiny slice of an old investment in the company by Y Combinator.His longtime mentor, Paul Graham, founder of Y Combinator, explained Altmans motivation like this: Why is he working on something that wont make him richer One answer is that lots of people do that once they have enough money, which Sam probably does. The other is that he likes power.What Bill Gates Must Have Been LikeIn the late 1990s, the John Burroughs School, a private prep school named for the 19thcentury American naturalist and philosopher, invited an independent consultant to observe and critique daily life on its campus in the suburbs of St. Louis.The consultants review included one significant criticism: The student body was rife with homophobia.In the early 2000s, Altman, a 17yearold student at John Burroughs, set out to change the schools culture, individually persuading teachers to post Safe Space signs on their classroom doors as a statement in support of gay students such as him. He came out during his senior year and said the St. Louis of his teenage years was not an easy place to be gay.Georgeann Kepchar, who taught the schools Advanced Placement computer science course, saw Altman as one of her most talented computer science students  and one with a rare knack for pushing people in new directions.He had creativity and vision, combined with the ambition and force of personality to convince others to work with him on putting his ideas into action, she said. Altman also told me that he had asked one particularly homophobic teacher to post a Safe Space sign just to troll the guy.Graham, who worked alongside Altman for a decade, saw the same persuasiveness in the man from St. Louis.He has a natural ability to talk people into things, Graham said. If it isnt inborn, it was at least fully developed before he was 20. I first met Sam when he was 19, and I remember thinking at the time: So this is what Bill Gates must have been like.The two got to know each other in 2005 when Altman applied for a spot in Y Combinators first class of startups. He won a spot  which included 10,000 in seed funding  and after his sophomore year at Stanford University, he dropped out to build his new company, Loopt, a social media startup that let people share their location with friends and family.He now says that during his short stay at Stanford, he learned more from the many nights he spent playing poker than he did from most of his other college activities. After his freshman year, he worked in the AI and robotics lab overseen by professor Andrew Ng, who would go on to found the flagship AI lab at Google. But poker taught Altman how to read people and evaluate risk.It showed him how to notice patterns in people over time, how to make decisions with very imperfect information, how to decide when it was worth pain, in a sense, to get more information, he told me while strolling across his ranch in Napa. Its a great game.After selling Loopt for a modest return, he joined Y Combinator as a parttime partner. Three years later, Graham stepped down as president of the firm and, to the surprise of many across Silicon Valley, tapped Altman, then 28, as his successor.Altman is not a coder or an engineer or an AI researcher. He is the person who sets the agenda, puts the teams together and strikes the deals. As the president of Y Combinator, he expanded the firm with near abandon, starting a new investment fund and a new research lab and stretching the number of companies advised by the firm into the hundreds each year.He also began working on several projects outside the investment firm, including OpenAI, which he founded as a nonprofit in 2015 alongside a group that included Elon Musk. By Altmans own admission, Y Combinator grew increasingly concerned he was spreading himself too thin.He resolved to refocus his attention on a project that would, as he put it, have a real impact on the world. He considered politics, but settled on AI.Altman believed, according to his younger brother Max, that he was one of the few people who could meaningfully change the world through AI research, as opposed to the many people who could do so through politics.In 2019, just as OpenAIs research was taking off, Altman grabbed the reins, stepping down as president of Y Combinator to concentrate on a company with fewer than 100 employees that was unsure how it would pay its bills.Within a year, he had transformed OpenAI into a nonprofit with a forprofit arm. That way, he could pursue the money it would need to build a machine that could do anything the human brain could do.Raising 10 BillsIn the mid2010s, Altman shared a threebedroom, threebath San Francisco apartment with his boyfriend at the time, his two brothers and their girlfriends. The brothers went their separate ways in 2016 but remained on a group chat, where they spent a lot of time giving one another guff, as only siblings can, his brother Max remembers. Then, one day, Altman sent a text saying he planned to raise 1 billion for his companys research.Within a year, he had done so. After running into Satya Nadella, Microsofts CEO, at an annual gathering of tech leaders in Sun Valley, Idaho  often called summer camp for billionaires  he personally negotiated a deal with Nadella and Microsofts chief technology officer, Kevin Scott.A few years later, Altman texted his brothers again, saying he planned to raise an additional 10 billion  or, as he put it, 10 bills. By this past January, he had done this, too, signing another contract with Microsoft.Brockman, OpenAIs president, said Altmans talent lies in understanding what people want. He really tries to find the thing that matters most to a person  and then figure out how to give it to them, Brockman told me. That is the algorithm he uses over and over.The agreement has put OpenAI and Microsoft at the center of a movement that is poised to remake everything from search engines to email applications to online tutors. And all this is happening at a pace that surprises even those who have been tracking this technology for decades.Amid the frenzy, Altman is his usual calm self  although he does say he uses ChatGPT to help him quickly summarize the avalanche of emails and documents coming his way.Scott believes that Altman will ultimately be discussed in the same breath as Gates, Steve Jobs and Mark Zuckerberg.These are people who have left an indelible mark on the fabric of the tech industry and maybe the fabric of the world, he said. I think Sam is going to be one of those people.The trouble is, unlike the days when Apple, Microsoft and Meta were getting started, people are well aware of how technology can transform the world  and how dangerous it can be.The Man in the MiddleIn March, Altman tweeted out a selfie, bathed by a paleorange flash, that showed him smiling between a blond woman giving a peace sign and a bearded guy wearing a fedora.The woman was Canadian singer Grimes, Musks former partner, and the hat guy was Eliezer Yudkowsky, a selfdescribed AI researcher who believes, perhaps more than anyone, that AI could one day destroy humanity.The selfie  snapped by Altman at a party his company was hosting  shows how close he is to this way of thinking. But he has his own views on the dangers of AI.Yudkowsky and his writings played key roles in the creation of both OpenAI and DeepMind, another lab intent on building artificial general intelligence.He also helped spawn the vast online community of rationalists and effective altruists who are convinced that AI is an existential risk. This surprisingly influential group is represented by researchers inside many of the top AI labs, including OpenAI. They dont see this as hypocrisy: Many of them believe that because they understand the dangers clearer than anyone else, they are in the best position to build this technology.Altman believes that effective altruists have played an important role in the rise of AI, alerting the industry to the dangers. He also believes they exaggerate these dangers.As OpenAI developed ChatGPT, many others, including Google and Meta, were building similar technology. But it was Altman and OpenAI that chose to share the technology with the world.Many in the field have criticized the decision, arguing that this set off a race to release technology that gets things wrong, makes things up and could soon be used to rapidly spread disinformation. On Friday, the Italian government temporarily banned ChatGPT in the country, citing privacy concerns and worries over minors being exposed to explicit material.Altman argues that rather than developing and testing the technology entirely behind closed doors before releasing it in full, it is safer to gradually share it so everyone can better understand risks and how to handle them.He told me that it would be a very slow takeoff.When I asked Altman if a machine that could do anything the human brain could do would eventually drive the price of human labor to zero, he demurred. He said he could not imagine a world where human intelligence was useless.If hes wrong, he thinks he can make it up to humanity.He rebuilt OpenAI as what he called a cappedprofit company. This allowed him to pursue billions of dollars in financing by promising a profit to investors such as Microsoft. But these profits are capped, and any additional revenue will be pumped back into the OpenAI nonprofit that was founded back in 2015.His grand idea is that OpenAI will capture much of the worlds wealth through the creation of AGI and then redistribute this wealth to the people. In Napa, as we sat chatting beside the lake at the heart of his ranch, he tossed out several figures  100 billion, 1 trillion, 100 trillion.If AGI does create all that wealth, he is not sure how the company will redistribute it. Money could mean something very different in this new world.But as he once told me: I feel like the AGI can help with that.Author: Cade Metzc.2021 The New York Times Company Invite your friends and family to sign up for MC Tech 3, our daily newsletter that breaks down the biggest tech and startup stories of the day   End your day with a breakdown of the biggest tech and startup stories in your inbox SUBSCRIBE  End your day with a breakdown of the biggest tech and startup stories in your inbox Rishi Sunak spent Rs 5 crore on private jet trips in just 2 weeks: report Cutting cake with pistol backfires for Delhi man. Viral video gets him arrested Portfolio Markets Watchlist Live TV Show Currencies Commodities Fixed Income Personal Finance Mutual Fund PreMarket IPO Global MarketBudget 2023  BSE Sensex ForumMC 30 News  Business Markets Stocks Economy Mutual Funds Personal Finance IPO News Startups  Visit the App Store to see all our apps:Download from Google PlayDownload from APP StoreDownload from Windows Phone Useful LinksCrypto NewsBank Holidays in IndiaGold Rate TodayTrending NewsStartupsNational NewsMC VideosMC You TubeHouse Purchase IndexBest Portfolio ManagerSmall Savings SchemesBondsTopperLearningClear Study DoubtsEducation Franchisee Opportunity Copyright  eEighteen.com Ltd. All rights reserved. Reproduction of news articles, photos, videos or any other content in whole or in part in any form  or medium without express writtern permission of moneycontrol.com is prohibited.  You got 90 Days Trial of Grab it Now AdFree Experience Top Articles from Financial Times Actionable Insights MC Research Economic Calendar  Many MoreYou are already a Moneycontrol Pro user.OK ","sentiment":2,"digital transaction":0.0848158374,"healthcare":0.059012793,"news platform":0.889334619,"data analytics":0.8315930963,"insurance":0.0211131666,"investment":0.0232802369,"global market":0.8140320182,"autonomous car":0.0862420052,"customer experience":0.9842775464,"data science":0.8062443733,"cryptocurrency":0.0210402273,"camera":0.5536430478,"robot":0.1121580601,"chatgpt":0.9371042848,"image":0.9886366725,"voice":0.2082260698,"patient care":0.070137918,"research":0.8123108745}
{"id":648,"cleaned text":"Pastors view: Sermons written by ChatGPT will have no soul Rabbi Joshua Franklin stands inside the sanctuary at the Jewish Center of the Hamptons in East Hampton, New York on Feb. 10, 2023. Franklin expermented writing Rabbi Joshua Franklin stands inside the sanctuary at the Jewish Center of the Hamptons in East Hampton, New York on Feb. 10, 2023. Franklin expermented writing a sermon for his congregation using artificial intelligence software Chat GPT, and concluded that AI cant replace the work of human faith leaders. AP PhotoRobert Bumsted NEW YORK AP  Among sermon writers, there is fascination  and unease  over the fastexpanding abilities of artificialintelligence chatbots. For now, the evolving consensus among clergy is this: Yes, they can write a passably competent sermon. But no, they cant replicate the passion of actual preaching.  It lacks a soul  I dont know how else to say it, said Hershael York, a pastor in Kentucky who also is dean of the school of theology and a professor of Christian preaching at The Southern Baptist Theological Seminary. Sermons are meant to be the core of a worship service  and often are faith leaders best weekly shot at grabbing their congregations attention to impart theological and moral guidance.  Lazy pastors might be tempted to use AI for this purpose, York said, but not the great shepherds, the ones who love preaching, who love their people. A rabbi in New York, Joshua Franklin, recently told his congregation at the Jewish Center of the Hamptons that he was going to deliver a plagiarized sermon  dealing with such issues as trust, vulnerability and forgiveness.  Upon finishing, he asked the worshippers to guess who wrote it. When they appeared stumped, he revealed that the writer was ChatGPT, responding to his request to write a 1,000word sermon related to that weeks lesson from the Torah. Now, youre clapping  Im deathly afraid, Franklin said when several congregants applauded. I thought truck drivers were going to go long before the rabbi, in terms of losing our positions to artificial intelligence. ChatGPT might be really great at sounding intelligent, but the question is, can it be empathetic And that, not yet at least, it cant, added Franklin. He said AI has yet to develop compassion and love, and is unable to build community and relationships. Those are the things that bring us together, the rabbi concluded. Rachael Keefe, pastor of Living Table United Church of Christ in Minneapolis, undertook an experiment similar to Franklins. She posted a brief essay in her online Pastoral Notes in January, addressing how to attend to ones mental health amid the stresses of the holiday season. It was pleasant, but somewhat bland, and at the end, Keefe revealed that it was written by ChatGPT, not by herself. While the facts are correct, theres something deeper missing, she wrote. AI cannot understand community and inclusivity and how important these things are in creating church. Its not terrible, but yes, I agree. Rather generic and a little bit eerie, wrote Douglas Federhart. I like what you write a lot more. It comes from an actually living being, with a great brain and a compassionate, beating heart.  Todd Brewer, a New Testament scholar and managing editor of the Christian website Mockingbird, wrote in December about an experiment of his own  asking ChatGPT to write a Christmas sermon for him. He was specific, requesting a sermon based upon Lukes birth narrative, with quotations from Karl Barth, Martin Luther, Irenaeus of Lyon, and Barack Obama. Brewer wrote that he was not prepared when ChatGPT responded with a creation that met his criteria and is better than several Christmas sermons Ive heard over the years. The A.I. even seems to understand what makes the birth of Jesus genuinely good news, Brewer added. Yet the ChatGPT sermon lacks any human warmth, he wrote. The preaching of Artificial Intelligence cant convincingly sympathize with the human plight. In Brentwood, Tennessee, Mike Glenn, senior pastor for 32 years at Brentwood Baptist Church, wrote a blog post in January after a computersavvy assistant joked that Glenn could be replaced by an AI machine. Im not buying it, Glenn wrote. AI will never be able to preach a decent sermon. Why Because the gospel is more than words. Its the evidence of a changed life. When listening to a sermon, what a congregation is looking for is evidence that the pastor has been with Jesus, Glenn added. AI will always have to  literally  take someone elses words for it it wont ever be a sermon that will convince anyone to come and follow Jesus. Also weighing in with an online essay was the Rev. Russell Moore, formerly head of the Southern Baptist Conventions public policy division and now editorinchief of the evangelical magazine Christianity Today. He confided to his readers that his first sermon, delivered at age 12, was a wellintentioned mess. Preaching needs someone who knows the text and can convey that to the people  but its not just about transmitting information, Moore wrote. When we listen to the Word preached, we are hearing not just a word about God but a word from God. Such lifealtering news needs to be delivered by a human, in person, he added. A chatbot can research. A chatbot can write. Perhaps a chatbot can even orate. But a chatbot cant preach. The Southern Baptist department formerly led by Moore  the Ethics and Religious Liberty Commission  has been monitoring artificialintelligence developments for several years under the direction of Jason Thacker, its chair of research in technology ethics. He shares the view that wise, virtuous pastors wont let new technology deter them from personal immersion in sermonwriting. But I also can see it being used in unhelpful or unethical ways, he added. Some young pastors may become overly reliant on these machines  and not see the imperfections of these tools, Thacker told The Associated Press. Many pastors are overworked, exhausted, filled with anxiety One can see why a pastor might say, I cant do everything Im supposed to do, and start passing ideas off as their own. Hershael York, the Kentucky pastor and professor, said some of the greatest sermons contain elements of anguish. Artificial intelligence can imitate that to some level. But I dont think it can ever give any kind of a sense of suffering, grief, sorrow, the same way that a human being can, he said. It comes from deep within the heart and the soul  thats what the great preachers have, and I dont think you can get that by proxy. Associated Press religion coverage receives support through the APs collaboration with The Conversation US, with funding from Lilly Endowment Inc. The AP is solely responsible for this content. Copyright 2023 The Associated Press. All rights reserved. This material may not be published, broadcast, rewritten or redistributed. AP source: FBI searched U. of Delaware in Biden docs The IRS is sending out tax refunds: See how the average Dalhart ISD to host bond election in May for new 1 dead after truck hits car, home on South Washington Lotto Texas jackpot still up for grabs and now at Can kids ride in the bed of a truck in Texas KAMR Local 4 Viewer Appreciation Night at the TriState Fair  Rodeo  1998  2023 Nexstar Media Inc.  All Rights Reserved.","sentiment":2,"digital transaction":0.1808346659,"healthcare":0.0448173434,"news platform":0.4563522637,"data analytics":0.6826342344,"insurance":0.0379282832,"investment":0.5007194281,"global market":0.9506413341,"autonomous car":0.8310887814,"customer experience":0.4546841085,"data science":0.2002826184,"cryptocurrency":0.0274929106,"camera":0.0463116951,"robot":0.2212719917,"chatgpt":0.196304813,"image":0.3420955837,"voice":0.2916274965,"patient care":0.1449937969,"research":0.9621295333}
{"id":652,"cleaned text":"US launches artificial intelligence military use initiativeMIKE CORDER,Associated PressFeb. 16, 2023  THE HAGUE, Netherlands AP  The United States launched an initiative Thursday promoting international cooperation on the responsible use of artificial intelligence and autonomous weapons by militaries, seeking to impose order on an emerging technology that has the potential to change the way war is waged. As a rapidly changing technology, we have an obligation to create strong norms of responsible behavior concerning military uses of AI and in a way that keeps in mind that applications of AI by militaries will undoubtedly change in the coming years, Bonnie Jenkins, the State Departments under secretary for arms control and international security, said.  She said the U.S. political declaration, which contains nonlegally binding guidelines outlining best practices for responsible military use of AI, can be a focal point for international cooperation.  Jenkins launched the declaration at the end of a twoday conference in The Hague that took on additional urgency as advances in drone technology amid the Russias war in Ukraine have accelerated a trend that could soon bring the worlds first fully autonomous fighting robots to the battlefield. The U.S. declaration has 12 points, including that military uses of AI are consistent with international law, and that states maintain human control and involvement for all actions critical to informing and executing sovereign decisions concerning nuclear weapons employment. Zachary Kallenborn, a George Mason University weapons innovation analyst who attended the Hague conference, said the U.S. move to take its approach to the international stage recognizes that there are these concerns about autonomous weapons. That is significant in and of itself. Kallenborn said it was also important that Washington included a call for human control over nuclear weapons because when it comes to autonomous weapons risk, I think that is easily the highest risk you possibly have. Underscoring the sense of international urgency around AI and autonomous weapons, 60 nations, including the U.S. and China, issued a call for action at the Hague conference urging broad cooperation in the development and responsible military use of artificial intelligence. We are in time to mitigate risks and to prevent AI from spiraling out of control, and we are in time to prevent AI from taking us to a place we simply dont want to be, Dutch Foreign Minister Wopke Hoekstra said. The call to action issued in the Netherlands underscored the importance of ensuring appropriate safeguards and human oversight of the use of AI systems, bearing in mind human limitations due to constraints in time and capacities. The participating nations also invited countries to develop national frameworks, strategies and principles on responsible AI in the military domain. Military analysts and artificial intelligence researchers say the longer the nearly yearlong war in Ukraine lasts, the more likely it becomes that drones will be used to identify, select and attack targets without help from humans. Ukraines digital transformation minister, Mykhailo Fedorov, told The Associated Press in a recent interview that fully autonomous killer drones are a logical and inevitable next step in weapons development. He said Ukraine has been doing a lot of RD in this direction.  Ukraine already has semiautonomous attack drones and counterdrone weapons endowed with AI. Russia also claims to possess AI weaponry, though the claims are unproven. But there are no confirmed instances of a nation putting into combat robots that have killed entirely on their own. Russia was not invited to attend the conference in The Hague. Chinas ambassador to the Netherlands Tan Jian did attend and said Beijing has sent two papers to the United Nations on regulating military AI applications, saying the issue concerns the common security and the wellbeing of mankind, which requires the united response of all countries, he said.","sentiment":2,"digital transaction":0.0317300744,"healthcare":0.0076271938,"news platform":0.2196852416,"data analytics":0.3864305019,"insurance":0.0070694983,"investment":0.0621585809,"global market":0.0282298587,"autonomous car":0.0039577237,"customer experience":0.2512034476,"data science":0.5243154168,"cryptocurrency":0.0061100381,"camera":0.0179310385,"robot":0.0233688205,"chatgpt":0.2833601534,"image":0.3857657015,"voice":0.4383698702,"patient care":0.0104628047,"research":0.6783702374}
{"id":666,"cleaned text":"US regulators plan to go after harmful AI business practices U.S. market regulators say AI tools are subject  to the same legal standards as any other business tools. The Federal Trade Commission will come down hard on businesses whose AI tools harm consumers, officials said Tuesday.Regulators are scrutinizing AI tools that businesses have used in making hiring decisions, or in deciding who to loan money to. Theyre watching tools that can generate text, images, voice and even video, trying to make sure consumers dont fall prey to mass deceptions or closelytargeted misinformation.FTC Chair Lina Khan also said during a press event that the FTC will keep big companies honest, as they race for resources in the growing AI field.A handful of powerful firms today control the necessary raw materials, not only the vast stores of data, but also the cloud services and computing power that startups and other businesses rely on to develop and deploy AI products, Khan said.SEE MORE: From marketing to design, brands adopt AI tools despite riskShe warned that while AI might novel abilities, regulators will still hold it to the same account as other business tools.There is no AI exemption to the laws on the books, Khan said.Regulators elsewhere in the world are also trying to keep up with AIs progress. Canada has investigated ChatGPT for potential privacy violations, andItaly blocked the programso it could investigate whether it ran afoul of EU data laws.The EUsproposed AI Actwould sort the growing uses of AI tools into different risk categories, banning those considered most dangerous outright and subjecting other highrisk applications like AIpowered hiring decisions to stronger laws.Trending stories at Scrippsnews.comCan the Internet survive without the controversial Section 230How was the internet createdWhat is 5G internet Sign up for the Breaking News Newsletter and receive up to date information.","sentiment":2,"digital transaction":0.2544847429,"healthcare":0.0341480151,"news platform":0.4939082265,"data analytics":0.7880847454,"insurance":0.022719197,"investment":0.1157334447,"global market":0.3650509417,"autonomous car":0.0692371503,"customer experience":0.394612819,"data science":0.9159671068,"cryptocurrency":0.0723001212,"camera":0.0704059526,"robot":0.0182614513,"chatgpt":0.2743190825,"image":0.1369305253,"voice":0.12677899,"patient care":0.0208651125,"research":0.3820526004}
{"id":674,"cleaned text":"Will Artificial Intelligence replace human authors in the near future The New Indian Express While the worlds firstever AIwritten novel was published in Russia in 2008, the first fulllength Korean novel, written by an AI named Birampung, hit the shelves in August About one year ago, British newspaper The Guardian ran an article titled A robot wrote this entire article. Are you scared yet, human, written by an Artificial Intelligence AIenabled robot called GPT3 Generative Pretrained Transformer 3. It is an autoregressive language model that uses deep learning to produce humanlike text. GPT3 was fed a short introduction and was instructed to write an oped of around 500 words in simple language, focusing on why humans have nothing to fear from AI. In response, it produced eight different essays. The Guardian picked the best parts of each and ran the edited piece. GPT3 even quoted Mahatma Gandhi in its article. A rapid revolution in the field of AI and Natural Language Processing NLP is going on. While the worlds firstever AIwritten novel was published in Russia in 2008, the first fulllength Korean novel, written by an AI named Birampung, hit the shelves in August. Birampung refers to a fierce storm that strikes at the beginning and end of the universes creation. The 560page novel was directed by the novelist and mathematician Kim Taeyon. Kim was reluctant to share the details of the technology involved. But 1,000 books were loaded in Birampungs operating system and it was equipped with the most advanced deep autonomous learning algorithm. Like a true film director, Kim picked the storyline, background and characters, but the actual writing process and the composition were made by Birampung. The novel, the name of which has been translated in English as The World from Now On, took seven years to complete and it consists of five stories in which the protagonistsa disabled amateur mathematician, a math professor and entrepreneur, a psychiatrist, an astrophysicist, and a Buddhist monkwere drawn to each other in their individual quests to understand the meaning of human existence. Is there any existential threat for writers now Consider GPT3, the thirdgeneration language prediction model in the series created by OpenAI, an artificial intelligence research company founded by Tesla billionaire Elon Musk among others. What exactly is going on inside GPT3 An MIT Technology Review article stated: What it seems to be good at is synthesising text it has found elsewhere on the internet, making it a kind of vast, eclectic scrapbook created from millions and millions of snippets of text that it then glues together in weird and wonderful ways GPT3 can also produce pastiches of particular writers. For instance, when given the title, the authors name, and the initial word It, the AI produced a short story called The importance of being on Twitter, written in the style of Jerome K Jerome. It even wrote a reasonably informative article about GPT3. Playing with GPT3 feels like seeing the future, is what some experts feel. There are plenty of shortcomings of AIs though. Their language is not always polished. And many people spotted a lack of depth, with the text reading more like cutandpaste jobs. Some experts have felt that GPT3s program does nothing more than match words and phrases based on statistical correlations among those in its database. In a March 2021 article published in the journal Nature, Matthew Hutson discusses the rise and risks of languagegenerating AI. Hutson opines that a remarkable AI can write like humans, but it still lacks common sense in the process of understanding how the world works, physically and socially. For example, when asked, How many rainbows does it take to jump from Hawaii to seventeen GPT3 responded: It takes two rainbows to jump from Hawaii to seventeen. In The Guardian piece, GPT3 wrote: I am only a set of code, governed by lines upon lines of code that encompass my mission statement. GPT3 had been trained in around 200 billion words, at an estimated cost of tens of millions of dollars. The AI thus still needs a human editor to tether its writings to reality. In fact, a few days after the oped written by GPT3 was published, a followup letter titled A human wrote this article. You shouldnt be scared of GPT3 was published in The Guardian. The author, Albert Fox Cahn, argued that while GPT3 is quite impressive it is useless without human input and edits. GPT3 is just the latest example of computerassisted authorship, the process by which human authors use technology to enhance the writing process, Cahn wrote. American programmerpoet Allison Parrish also noted: Attributing The Guardian article to AI is sort of like attributing the pyramids to the Pharaoh. Pharaoh didnt do that. The workers did. GPT3 is an artificial neural network with over 175 billion parameters that uses only 0.12 of its cognitive capacity. Its certainly a big leap forward from GPT2 that had 1.5 billion parameters. When GPT4 or GPT5 rolls around in the future, should human writers really feel dread Will AI measure up to J K Rowling or Kazuo Ishiguro, or report on Afghanistan In his Nature paper, Hutson wrote: Its possible that a bigger model would do betterwith more parameters, more training data, more time to learn. But this will get increasingly expensive and cant be continued indefinitely. The opaque complexity of language models creates another limitation. Still, would some GPTn or equivalent AI be able to produce a Tagores song or a Shakespeares play in the near future A new technological anxiety would, however, invariably evolve around it. P.S: This article has been completely written by a human being, not an AI. UK adds Covishield to approved list of vaccines after Indias warning Unicorns Unacademy, Udaan, CRED top 2021 LinkedIn Top Startups India list New Yamaha R15 at Rs 1.68 lakh Aerox at Rs 1.29 lakh Meet Keralaautorickshaw driver who wonRs 12 crore bumper lottery Disclaimer : We respect your thoughts and views But we need to be judicious while moderating your comments. All the comments will be moderated by the newindianexpress.com editorial. Abstain from posting comments that are obscene, defamatory or inflammatory, and do not indulge in personal attacks. Try to avoid outside hyperlinks inside the comment. Help us delete comments that do not follow these guidelines. The views expressed in comments published on newindianexpress.com are those of the comment writers alone. They do not represent the views or opinions of newindianexpress.com or its staff, nor do they represent the views or opinions of The New Indian Express Group, or any entity of, or affiliated with, The New Indian Express Group. newindianexpress.com reserves the right to take any or all comments down at any time. Latest  Anirudh Tewari is new Punjab Chief Secretary, Vini Mahajan shunted: Sources  Madrid stays redhot, routs Mallorca 61 in Spanish league  Money laundering case: HC to hear Anil Deshmukhs plea against ED summons on September 29  US rules out adding India or Japan to security alliance with Australia and UK  Show patience, engage: Pakistani Foreign Minister Shah Mehmood Qureshi details plan for Taliban  Pegasus snooping row: SC to pronounce order on pleas seeking independent probe next week The Morning Standard  Dinamani   Kannada Prabha   Samakalika Malayalam  Indulgexpress    Edex Live    Cinema Express   Contact Us   About Us   Careers  Privacy Policy   Search   Terms of Use   Advertise With Us   Home   Nation   World   Cities   Business   Columns   Entertainment   Sport   Magazine   The Sunday Standard  ","sentiment":2,"digital transaction":0.2163894922,"healthcare":0.1442898214,"news platform":0.2524180412,"data analytics":0.9628176689,"insurance":0.0556527898,"investment":0.2889793813,"global market":0.241145581,"autonomous car":0.0289228726,"customer experience":0.638684094,"data science":0.2321828008,"cryptocurrency":0.0843727514,"camera":0.110674493,"robot":0.0504321903,"chatgpt":0.5319556594,"image":0.4483091235,"voice":0.253564775,"patient care":0.0063163154,"research":0.3360964358}
{"id":707,"cleaned text":"Canvass AI CEO, Humera Malik to Join The Standoff: Operators vs. VCs Panel at the 2022 CIX Summit TORONTO, Oct. 31, 2022 CNW Canvass AI, a leader in industrial AI software,today announced that Humera Malik, CEO, has been invited to speak at The Standoff, an open and frank discussion about the relationship between venture capitalists and business operators. The panel is part of the KeynoteThought Leadership series presented on the main stage at the 2022 CIX Summit held in Toronto, Ontario, November 12. Humera Malik said: Were excited to be back with CIX this year to share our experience. In 2018, Canvass AI was recognized with a prestigious CIX Top 20 Early award, and in August this year, we successfully completed a US14.23 million Series A round. Its been both exhilarating and pressing, but a wonderful journey for any entrepreneur. Canvass CEO, Humera Malik, Joins Standoff: Operators vs. VCs at 2022 CIX Summit. Be ready for some heat Ms. Malik is one of the leading voices on Artificial Intelligence and how it can put industrialcompanies in control of their data, to make timely decisions, and achieve sustainable outcomes faster by empowering high performance teams. The Standoff: Operators Versus Venture Capitalists2022 CIX SummitHilton Toronto Main Stage8:45 am EDT, Wednesday, November 2, 2022Humera Malik joins an esteemed panel of serial entrepreneurs and seasoned VCs for an open and frank conversation about term sheet pitfalls, misaligned goals, poor communication and the importance of building resilience through a strong advisory board. Be ready for some heatAbout CIX  Canadian Innovation ExchangeCIX is Canadas largest startup awards program and investment conference which showcases Canadas most promising early stage and scaling startups. Now in its 15th year, CIXs invited delegates are Canadas awardwinning startups, North American VCs, corporates, private equity investors and advisors. To register for CIX please visit: https:cixsummit.com2022About Canvass AICanvass AI is a leading software provider enabling industrial companies to exceed their operations and sustainability targets with patented Industrial AI technology. Its AIasaService is designed to coexist with existing technologies and empower workforces to achieve faster sustainable outcomes. Backed by Alphabet, and Yamaha Motor Ventures, the Company is a member of the World Economic Forums Global Innovation Community, Next Generation Manufacturing Canada, and is recognized by CB Insights as one of the worlds top 50 technology companies that is advancing manufacturing.Follow us on Twitter or LinkedIn.Links:Humera Malik photoCanvass AI logoSOURCE Canvass AIFor further information: Media  Analyst Contact: Shelly Sofer, emailprotected Canvass AI Awarded Patent to Empower Faster Decision Making in Complex Industrial Processes  Canvass AI CEO, Humera Malik to Join AI World Government Panel to Discuss Whats Next in AI  Copyright  2022 CNW Group Ltd. All Rights Reserved. A Cisioncompany.","sentiment":2,"digital transaction":0.736918509,"healthcare":0.0871840641,"news platform":0.8373888135,"data analytics":0.9770593643,"insurance":0.058620587,"investment":0.7894052267,"global market":0.7215958834,"autonomous car":0.0534040183,"customer experience":0.8391737342,"data science":0.656219244,"cryptocurrency":0.3710541427,"camera":0.2117875963,"robot":0.0311608668,"chatgpt":0.6428210735,"image":0.5004717112,"voice":0.5003791451,"patient care":0.050732065,"research":0.5963795185}
{"id":714,"cleaned text":"Exiled artist Ai Weiwei reflects on Beijing OlympicsSTEPHEN WADE,AP Sports WriterFeb. 3, 2022Updated: Feb. 4, 2022 12:25a.m. 1of3FILE  Chinese contemporary artist and activist Ai Weiwei poses for a portrait prior to a news conference in Berlin, Germany, Sept. 2, 2020. Weiwei helped design Beijings Birds Nest stadium for the 2008 Olympics. Its again the venue for the opening ceremony of the 2022 Beijing Winter Olympics.Markus SchreiberAPShow MoreShow Less 2of3FILE  Lights shine during a rehearsal for the opening ceremony of the 2022 Winter Olympics at the National Stadium, known as the Birds Nest in Beijing, China, Jan. 30, 2022. The artist Ai Weiwei helped design the stadium for the 2008 Olympics. Its again the venue for the opening ceremony of the 2022 Beijing Winter Olympics.Wang XinchaoAPShow MoreShow Less BEIJING AP  When the artist Ai Weiwei was picked to help design Beijings Birds Nest stadium for the 2008 Summer Olympics, he hoped the Games and the venues distinct architecture  the instantly recognizable weave of curving steel beams  would symbolize Chinas new openness. The Chinese dissident widely regarded as one of the worlds greatest living artists has repeatedly described the stadium and the 2008 Olympics as a fake smile that his native country presented to the world. The Birds Nest is again front and center as it holds Fridays opening ceremony of the Winter Olympics. Beijing is the first city to hold both the Summer and Winter Games, and Ai expects more of the same. As an architect, my goal was the same as other architects, that is, to design it as perfectly as possible, Ai told The Associated Press in an interview over email. The way it was used afterwards went in the opposite direction from our ideals. We had hoped that our architecture could be a symbol of freedom and openness and represent optimism and a positive force, which was very different from how it was used as a promotional tool in the end. Even before his fame landed him the design job working with the Swiss architectural firm Herzog  de Meuron, Ai had been an unrelenting critic of the Chinese Communist Party. He was jailed in 2011 in China for unspecified crimes and now lives in exile in Portugal. He has also lived in exile in Germany  he still maintains a studio there  and in Britain. His art  which also includes sculpture, photography, video and the written word  is almost always provocative, and he offers scathing commentary on the censorship and lack of civil liberties in his homeland. He used his dashed hopes for the Birds Nest to illustrate how China has changed since 2008, a time when the Olympics were seen as a coming out party for China. When the International Olympic Committee awarded Beijing the Olympics in 2001, it said the Games could help improve human rights. But Ai termed the 2008 Olympics a low point as migrant workers were forced out of the city, small shops were shuttered and street vendors removed. Blockslong billboards popped up, painted with palm trees and beach scenes, to hide shabby neighborhoods from view. The entire Olympics took place under the situation of a blockade, Ai told AP. For the general public, there was no joy in participation. Instead, there was a close collaboration between the IOC and the Chinese regime, who put on a show together in order to obtain economic and political capital. More for youGeno Auriemma expected to return for UConns Friday matchupNo. 10 UConn vs Butler: What you need to know His memoir 1,000 Years of Joys and Sorrows was published last year. It details the overlap of his life and career with that of his father, Ai Qing, a famous poet who was sent into internal exile in 1957, the year Ai Weiwei was born. In the book, Ai writes that he watched the opening ceremony away from the stadium on a television screen, and jotted down the following. In this world where everything has a political dimension, we are now told we mustnt politicize things: This is simply a sporting event, detached from history and ideas and values  detached from human nature, even. The IOC and China again say the Olympics are divorced from politics. China, of course, has political ends in mind. For the IOC, the Olympics are a sports business that generates billions in sponsor and television income. In his email, Ai described China as emboldened by the 2008 Olympics  more confident and uncompromising. He said the 2008 Games were a negative that allowed Chinas government to better shape its message. The Olympics did not change China in ways the IOC suggested, or foster civil liberties. Instead, China used the Olympics to alter how it was perceived on the world stage and to signal its rising power. The 2008 Games were followed a month later by the world financial crisis, and in 2012 by the rise of General Secretary Xi Jinping. Xi was a senior politician in charge of the 2008 Olympics, but the 2022 Games are his own. Since 2008, the government of China has further strengthened its control, and the human rights situation has further deteriorated, Ai told AP. West Haven mayor says DiMassa payouts to wife, friend already were under investigation Former state Rep. DiMassas wife among recipients of payments he OKd Cops: New Haven teacher charged after allegedly pulling 12yearold students hair Hamden police investigating attempted armed robbery, theft in grocery store parking lot Hed be gone: Lamont would fire CTs top prosecutor after nepotism probe Quinnipiac University to invest 244 million in new South Quad in Hamden China has seen the Wests hypocrisy and inaction when it comes to issues of human rights, so they have become even bolder, more unscrupulous and more ruthless. In 2022, China will impose more stringent constraints to the internet and political life, including human rights and the press, he said. The Communist Party does not care if the West participates in the Games or not because China is confident that the West is busy enough with their own affairs. Ai characterized the 2022 Winter Olympics and the pandemic as a case of fortunate timing for Chinas authoritarian government. The pandemic will limit the movement of journalists during the Games, and it will also showcase the states Orwellian control. China, under the system of state capitalism and especially after COVID, firmly believes that its administrative control is the only effective method this enhances their belief in authoritarianism. Meanwhile, China thinks that the West, with its ideas of democracy and freedom, can hardly obtain effective control. So, the 2022 Olympics will further testify to the effectiveness of authoritarianism in China and the frustration of the Wests democratic regimes. Ai was repeatedly critical of the IOC as an enabler interested solely in generating income from the Chinese market. The IOC and China both see the Games as a business opportunity. Ai suggested that many Chinese see the Olympics as another political exercise, with some people  like athletes  trying to extract value. In China there is only the partys guidance, statecontrolled media and people who have been brainwashed by the media, Ai wrote. There is no real civil society. Under this circumstance, Chinese people are not interested in the Olympics at all because it is simply a display of state politics. Nationally trained athletes exchange Olympic gold medals for economic gains for individuals or even for sport organizations this way of doing things deviates from the Olympics original ideas. Asked if he planned to go back to China, he said he was doubtful. And he dismissed the effectiveness of the Wests diplomatic boycott, which means government officials will not attend. Judging from the current situation, it is more and more unlikely for me to be able to return to China, he said. My main point here is that the situation in China has worsened. The Wests boycott is futile and pointless. China does not care about it at all. AP Sports Writer Stephen Wade reported for The Associated Press from Beijing for 2 12 years in the leadup to the 2008 Olympics, and also the followup. This COVID19 handoff from Lamont, who has wielded executive powers for 23 months, to the General Assembly has more than the usual hallmarks of... Bob Saulsbury went from being painfully shy to being a winner. Now the legendary coach will sit down to watch UConnbound Donovan Clingan play in... Perhaps podcaster Joe Rogan should consult Sandy Hook conspiracy theorist Alex Jones. How Am I How one CT mom dealt with homeschooling during COVID  In 1857, LI Sound froze over, spurring a trip across the ice ","sentiment":2,"digital transaction":0.5812532306,"healthcare":0.1836836487,"news platform":0.9836155176,"data analytics":0.9710435271,"insurance":0.1659206003,"investment":0.7513911128,"global market":0.8214780092,"autonomous car":0.3054278493,"customer experience":0.8161015511,"data science":0.9695912004,"cryptocurrency":0.2001389712,"camera":0.3875058591,"robot":0.3833817244,"chatgpt":0.8627731204,"image":0.7035322189,"voice":0.5953720808,"patient care":0.0697924122,"research":0.7905134559}
{"id":733,"cleaned text":"The sentient Google language AI can trick humans  Popular Science If it sounds right, it must be human: Googles language AI exposes us as shallow listeners   A sentient machine explores the difference between fluent language and fluent thoughtand the consequences of confusing the two. A lesson from Google AI: Dont judge a person by their language without interpreting the meaning first. Mimi ThianUnsplash  Kyle Mahowald is an assistant professor of Linguistics, The University of Texas at Austin College of Liberal Arts Anna A. Ivanova is a PhD candidate in Brain and Cognitive Sciences, Massachusetts Institute of Technology MIT. When you read a sentence like this one, your past experience tells you that its written by a thinking, feeling human. And, in this case, there is indeed a human typing these words: Hi, there But these days, some sentences that appear remarkably humanlike are actually generated by artificial intelligence systems trained on massive amounts of human text. People are so accustomed to assuming that fluent language comes from a thinking, feeling human that evidence to the contrary can be difficult to wrap your head around. How are people likely to navigate this relatively uncharted territory Because of a persistent tendency to associate fluent expression with fluent thought, it is naturalbut potentially misleadingto think that if an AI model can express itself fluently, that means it thinks and feels just like humans do. Thus, it is perhaps unsurprising that a former Google engineer recently claimed that Googles AI system LaMDA has a sense of self because it can eloquently generate text about its purported feelings. This event and the subsequent media coverage led to a number of rightly skeptical articles and posts about the claim that computational models of human language are sentient, meaning capable of thinking and feeling and experiencing. The question of what it would mean for an AI model to be sentient is complicated see, for instance, our colleagues take, and our goal here is not to settle it. But as language researchers, we can use our work in cognitive science and linguistics to explain why it is all too easy for humans to fall into the cognitive trap of thinking that an entity that can use language fluently is sentient, conscious or intelligent. Text generated by models like Googles LaMDA can be hard to distinguish from text written by humans. This impressive achievement is a result of a decadeslong program to build models that generate grammatical, meaningful language. Early versions dating back to at least the 1950s, known as ngram models, simply counted up occurrences of specific phrases and used them to guess what words were likely to occur in particular contexts. For instance, its easy to know that peanut butter and jelly is a more likely phrase than peanut butter and pineapples. If you have enough English text, you will see the phrase peanut butter and jelly again and again but might never see the phrase peanut butter and pineapples. Todays models, sets of data and rules that approximate human language, differ from these early attempts in several important ways. First, they are trained on essentially the entire internet. Second, they can learn relationships between words that are far apart, not just words that are neighbors. Third, they are tuned by a huge number of internal knobsso many that it is hard for even the engineers who design them to understand why they generate one sequence of words rather than another. The models task, however, remains the same as in the 1950s: determine which word is likely to come next. Today, they are so good at this task that almost all sentences they generate seem fluid and grammatical. We asked a large language model, GPT3, to complete the sentence Peanut butter and pineapples___. It said: Peanut butter and pineapples are a great combination. The sweet and savory flavors of peanut butter and pineapple complement each other perfectly. If a person said this, one might infer that they had tried peanut butter and pineapple together, formed an opinion and shared it with the reader. But how did GPT3 come up with this paragraph By generating a word that fit the context we provided. And then another one. And then another one. The model never saw, touched or tasted pineapplesit just processed all the texts on the internet that mention them. And yet reading this paragraph can lead the human mindeven that of a Google engineerto imagine GPT3 as an intelligent being that can reason about peanut butter and pineapple dishes.   The human brain is hardwired to infer intentions behind words. Every time you engage in conversation, your mind automatically constructs a mental model of your conversation partner. You then use the words they say to fill in the model with that persons goals, feelings and beliefs. The process of jumping from words to the mental model is seamless, getting triggered every time you receive a fully fledged sentence. This cognitive process saves you a lot of time and effort in everyday life, greatly facilitating your social interactions. However, in the case of AI systems, it misfiresbuilding a mental model out of thin air. A little more probing can reveal the severity of this misfire. Consider the following prompt: Peanut butter and feathers taste great together because___. GPT3 continued: Peanut butter and feathers taste great together because they both have a nutty flavor. Peanut butter is also smooth and creamy, which helps to offset the feathers texture. The text in this case is as fluent as our example with pineapples, but this time the model is saying something decidedly less sensible. One begins to suspect that GPT3 has never actually tried peanut butter and feathers. A sad irony is that the same cognitive bias that makes people ascribe humanity to GPT3 can cause them to treat actual humans in inhumane ways. Sociocultural linguisticsthe study of language in its social and cultural contextshows that assuming an overly tight link between fluent expression and fluent thinking can lead to bias against people who speak differently. For instance, people with a foreign accent are often perceived as less intelligent and are less likely to get the jobs they are qualified for. Similar biases exist against speakers of dialects that are not considered prestigious, such as Southern English in the US, against deaf people using sign languages and against people with speech impediments such as stuttering. These biases are deeply harmful, often lead to racist and sexist assumptions, and have been shown again and again to be unfounded. Will AI ever become sentient This question requires deep consideration, and indeed philosophers have pondered it for decades. What researchers have determined, however, is that you cannot simply trust a language model when it tells you how it feels. Words can be misleading, and it is all too easy to mistake fluent speech for fluent thought The recent debate has also brought other, more pressing issues with the language model to light.  One day, Alexa will be able to mimic anyones voice from only one minute of audio. 7 language apps and tools to help you navigate the world Sign up to receive Popular Sciences emails and get the highlights. We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites. Registration on or use of this site constitutes acceptance of our Terms of Service.","sentiment":2,"digital transaction":0.2227061838,"healthcare":0.0499844253,"news platform":0.7816843987,"data analytics":0.6127330065,"insurance":0.0644092336,"investment":0.1942583323,"global market":0.5002339482,"autonomous car":0.9784843326,"customer experience":0.5936987996,"data science":0.669054389,"cryptocurrency":0.0338890031,"camera":0.1014673635,"robot":0.3878084421,"chatgpt":0.3011067808,"image":0.5761234164,"voice":0.2934918404,"patient care":0.051619973,"research":0.9102653861}
{"id":752,"cleaned text":"Unfallkrankenhaus Berlin brings AI to Germany  Aidoc expands presence in Europe Unfallkrankenhaus Berlin ukb becomes Germanys first to adopt Aidoc AI solutions, a major step in the implementation of AI in the countrys healthcare system BERLIN, May 6, 2021 PRNewswire  Aidoc, the leading provider of AI solutions for medical imaging, announced todayits first Enterprise AI radiology adoption in Germany with Unfallkrankenhaus Berlin hospital ukb selecting Aidocs comprehensive suite of AI solutions to help prioritize and expedite treatment forpatients with lifethreatening, critical conditions. The Berlin medical center also provides teleradiology services to 20 regional hospitals, allowing patients throughout the area access to toplevel medical care. The practical use of the AI from Aidoc is a big step towards making timecritical radiological diagnostics safer. For our team of colleagues, this is the first experience with artificial intelligence. It shows that Al provides additional security for patients and radiologists and yet does not do away with an expert, says Prof. Mutze  Director of the Radiology and Neuroradiology institute at Unfallkrankenhaus Berlin.  Unfallkrankenhaus Berlin is part of the larger BG group of public hospitals focused on emergency services. With a high patient workload both day and night, the newly implemented AI solutions will allow physicians to increase efficiency and save critical time when it matters most.  Aidocs solutions support and enhance the impact of radiologist diagnostic power helping them expedite patient treatment and improve quality of care by flagging acute anomalies in real time. To date, the company has secured an industryleading 7 FDA clearances and 9 CE marks for lifethreatening pathologies and is used in over 500 medical centers worldwide. Aidocs impact on efficiency and positive patient outcomes has been proven across various facilities including a reduction of 36.6 in turnaround time, 2.8day reduction in inpatient length stay and 10.4 reduction in ED length of stay. We are proud that Unfallkrankenhaus Berlin hospital selected Aidoc for the first deployment of Aidocs AI solutions in Germany, said Alexander Boehmcker, Europe VP for Aidoc. The German healthcare system is ranked as one of the best in the world, so its only natural that hospitals and medical centers recognize the value of AI to assist radiologists with their workload and provide the highest level of care to their patients. Media contact:Marlee RavidProduct Marketing Manageremailprotected SOURCE Aidoc Unfallkrankenhaus Berlin Related Links https:www.aidoc.com","sentiment":2,"digital transaction":0.0923600942,"healthcare":0.0408500433,"news platform":0.2627065182,"data analytics":0.2762035131,"insurance":0.0336384587,"investment":0.3253949285,"global market":0.8583240509,"autonomous car":0.032688234,"customer experience":0.1692094803,"data science":0.260792017,"cryptocurrency":0.0128376409,"camera":0.0494417995,"robot":0.0340713747,"chatgpt":0.2717491984,"image":0.1385507137,"voice":0.1247158796,"patient care":0.0257977359,"research":0.8070822954}
{"id":786,"cleaned text":"ChatGPT could return to Italy if OpenAI complies with rules FILE  The OpenAI logo is seen on a mobile phone in front of a computer screen displaying output from ChatGPT, on March 21, 2023, in Boston. The Italian governments privacy watchdog said Friday March 31, 2023 that it is temporarily blocking the artificial intelligence software ChatGPT in the wake of a data breach. AP PhotoMichael Dwyer, FileMichael Dwyer  Associated Press FacebookTwitterShow more sharing optionsShareClose extra sharing options Facebook Twitter LinkedIn Email Copy Link URLCopiedPrint ROME ChatGPT could return to Italy soon if its maker, OpenAI, complies with measures to satisfy regulators who had imposed a temporary ban on the artificial intelligence software over privacy worries. The Italian data protection authority on Wednesday outlined a raft of requirements that OpenAI will have to satisfy by April 30 for the the ban on AI chatbot to be lifted.The watchdog last month ordered the company to temporarily stop processing Italian users personal information while it investigated a possible data breach. The authority said it didnt want to hamper AIs development but emphasized the importance of following the European Unions strict data privacy rules. AdvertisementOpenAI, which had responded by proposing remedies to ease the concerns, did not reply immediately to a request for comment Wednesday. Concerns are growing about the artificial intelligence boom, with other countries, from France to Canada, investigating or looking closer at socalled generative AI technology like ChatGPT. The chatbot is trained on huge pools of data, including digital books and online writings, and able to generate text that mimics human writing styles.Under Italys measures, OpenAI must post information on its website about how and why it processes the personal information of both users and nonusers, as well as provide the option to correct or delete that data. The company will have to rely on consent or legitimate interest to use personal data to train ChatGPTs algorithms, the watchdog said. The Italian regulators had questioned whether theres a legal basis for OpenAI to collect massive amounts of data used to teach ChatGPTs algorithms and raised concerns the system could sometimes generate false information about individuals.San Franciscobased OpenAI also will have to carry out a publicity campaign by May 15 through radio and TV, newspapers and the internet to inform people about how it uses their personal data for training algorithms, Italys watchdog said.Theres also a requirement to verify users ages and set up a system to filter out those who are under 13 and teens between 13 and 18 who dont have parental consent. Only in that case will the Italian SA supervisory authority lift its order that placed a temporary limitation on the processing of Italian users data .... so that ChatGPT will be available once again from Italy, the watchdog said on its website. California  Newsletter Get Essential San Diego, weekday mornings  Get top headlines from the UnionTribune in your inbox weekday mornings, including top news, local, sports, business, entertainment and opinion.  Enter email address  Sign Me Up You may occasionally receive promotional content from the San Diego UnionTribune. Support our journalism Submit a story tip Report a problem with this story California  Students 1976 bicentennial mural on dam being replaced  A giant mural that high school students painted on a California dam to celebrate the nations bicentennial in 1976 is being recreated after years of controversy over a decision to remove the original California  GOP attorney joins California race for Feinstein Senate seat  A Republican attorney and former congressional candidate has entered Californias 2024 race for the U.S. Senate seat currently occupied by Dianne Feinstein California  California weighs how to improve outcomes for Black students  California lawmakers are considering a proposal by Gov. Gavin Newsom to increase funding for schools with a large share of lowincome studentsCalifornia  Senate OKs bill allowing duplexes, fourplexes in Washington  A key housing bill that would legalize duplexes and fourplexes in most neighborhoods in nearly every Washington city has been approved by the state Senate California  Lawsuit seeks to uphold closing Californias last nuke plant  An environmental group is suing to block efforts to extend federal operating licenses for Californias last nuclear power plantCalifornia  Maine woman charged with buying guns that ended up in LA  Federal prosecutors are accusing a Maine woman of buying dozens of guns that went to gangs in Southern California last year Load More Public Safety  Police investigating suspicious death after mans body found on side of El Cajon road Public Safety  Pedestrian dies after being struck by train in Carlsbad Public Safety  Carlsbad police to conduct active shooter training Wednesday on high school campus Public Safety  Whats Juvenile Dependency Court Public can question experts at virtual town hall Public Safety  Driver killed when SUV plows into back of big rig on southbound I5 near Camp Pendleton UC San Diego chancellor given 500,000 pay raise to prevent him from taking presidency at unnamed private school Board of Supervisors demands Nathan Fletcher resign immediately amid sexual misconduct claims Transgender woman badly beaten in San Diego County mens jail receives 275,000 legal settlement Lawsuit alleges SDSU fraternity pledge nearly died during alcoholfueled hazing incident Former San Diego Navy pilot picked to fly fourperson crew to the moon Padres  Padres pregame: Looking for secondhalf Blake Snell, seeking 52 road trip Readers React  Opinion: San Diego holding back high water bills is a bad policy ColumnsFor subscribers  Column: MTS sleightofhand response to Fletcher scandal raises questions Privacy PolicyTerms of ServiceSign Up For Our NewslettersSite Map Follow Us  Twitter Instagram YouTube Facebook LinkedIn Sports Business Games Site Map  Copyright  2023, The San Diego UnionTribune  CA Notice of Collection  Do Not Sell or Share My Personal Information ","sentiment":2,"digital transaction":0.069620952,"healthcare":0.0105654942,"news platform":0.8260530233,"data analytics":0.7894957066,"insurance":0.0071299984,"investment":0.2866499126,"global market":0.5720357895,"autonomous car":0.0055779689,"customer experience":0.1425784826,"data science":0.668415606,"cryptocurrency":0.0112251295,"camera":0.0348152705,"robot":0.3288105428,"chatgpt":0.8994108438,"image":0.4083930552,"voice":0.0996204466,"patient care":0.0099202199,"research":0.3936832249}
{"id":789,"cleaned text":"How the collapse of Sam BankmanFrieds crypto empire has disrupted AI   SAN FRANCISCO  In April, a San Francisco artificial intelligence lab called Anthropic raised 580 million for research involving AI safety.Few in Silicon Valley had heard of the 1yearold lab, which is building AI systems that generate language. But the amount of money promised to the tiny company dwarfed what venture capitalists were investing in other AI startups, including those stocked with some of the most experienced researchers in the field.The funding round was led by Sam BankmanFried, the founder and CEO of FTX, the cryptocurrency exchange that filed for bankruptcy in November. After FTXs sudden collapse, a leaked balance sheet showed that BankmanFried and his colleagues had fed at least 500 million into Anthropic.Their investment was part of a quiet and quixotic effort to explore and mitigate the dangers of artificial intelligence, which many in BankmanFrieds circle believed could eventually destroy the world and damage humanity. Over the past two years, the 30yearold entrepreneur and his FTX colleagues funneled more than 530 million  through either grants or investments  into more than 70 AIrelated companies, academic labs, think tanks, independent projects and individual researchers to address concerns over the technology, according to a tally by The New York Times.Now some of these organizations and individuals are unsure whether they can continue to spend that money, said four people close to the AI efforts who were not authorized to speak publicly. They said they were worried that BankmanFrieds fall could cast doubt over their research and undermine their reputations. And some of the AI startups and organizations may eventually find themselves embroiled in FTXs bankruptcy proceedings, with their grants potentially clawed back in court, they said.  Lawmakers who benefited from FTX cash will probe its collapseSam BankmanFried blames huge management failures for FTX collapse The concerns in the AI world are an unexpected fallout from FTXs disintegration, showing how far the ripple effects of the crypto exchanges collapse and BankmanFrieds vaporizing fortune have traveled.Some might be surprised by the connection between these two emerging fields of technology, Andrew Burt, a lawyer and visiting fellow at Yale Law School who specializes in the risks of artificial intelligence, said of AI and crypto. But under the surface, there are direct links between the two.BankmanFried, who faces investigations into FTXs collapse and who spoke at the Times DealBook conference Wednesday, declined to comment. Anthropic declined to comment on his investment in the company.BankmanFrieds attempts to influence AI stem from his involvement in effective altruism, a philanthropic movement in which donors seek to maximize the impact of their giving for the long term. Effective altruists are often concerned with what they call catastrophic risks, such as pandemics, bioweapons and nuclear war.Their interest in artificial intelligence is particularly acute. Many effective altruists believe that increasingly powerful AI can do good for the world but worry that it can cause serious harm if it is not built in a safe way. While AI experts agree that any doomsday scenario is a long way off  if it happens at all  effective altruists have long argued that such a future is not beyond the realm of possibility and that researchers, companies and governments should prepare for it.Over the last decade, many effective altruists have worked inside top AI research labs, including DeepMind, which is owned by Googles parent company, and OpenAI, which was founded by Elon Musk and others. They helped create a research field called AI safety, which aims to explore how AI systems might be used to do harm or might unexpectedly malfunction on their own. Effective altruists have helped drive similar research at Washington, D.C., think tanks that shape policy. Georgetown Universitys Center for Security and Emerging Technology, which studies the impact of AI and other emerging technologies on national security, was largely funded by Open Philanthropy, an effective altruist giving organization backed by a Facebook cofounder, Dustin Moskovitz. Effective altruists also work as researchers inside these think tanks.BankmanFried has been a part of the effective altruist movement since 2014. Embracing an approach called earning to give, he told the Times in April that he had deliberately chosen a lucrative career so he could give away much larger amounts of money.In February, he and several of his FTX colleagues announced the Future Fund, which would support ambitious projects in order to improve humanitys longterm prospects. The fund was led partly by Will MacAskill, a founder of the Center for Effective Altruism, as well as other key figures in the movement.The Future Fund promised 160 million in grants to a wide range of projects by the beginning of September, including in research involving pandemic preparedness and economic growth. About 30 million was earmarked for donations to an array of organizations and individuals exploring ideas related to AI.Among the Future Funds AIrelated grants was 2 million to a littleknown company, Lightcone Infrastructure. Lightcone runs the online discussion site LessWrong, which in the mid2000s began exploring the possibility that AI would one day destroy humanity.BankmanFried and his colleagues also funded several other efforts that were working to mitigate the longterm risks of AI, including 1.25 million to the Alignment Research Center, an organization that aims to align future AI systems with human interests so that the technology does not go rogue. They also gave 1.5 million for similar research at Cornell University. The Future Fund also donated nearly 6 million to three projects involving large language models, an increasingly powerful breed of AI that can write tweets, emails and blog posts and even generate computer programs. The grants were intended to help mitigate how the technology might be used to spread disinformation and to reduce unexpected and unwanted behavior from these systems.After FTX filed for bankruptcy, MacAskill and others who ran the Future Fund resigned from the project, citing fundamental questions about the legitimacy and integrity of the business operations behind it. MacAskill did not respond to a request for comment.Beyond the Future Funds grants, BankmanFried and his colleagues directly invested in startups with the 500 million financing of Anthropic. The company was founded in 2021 by a group that included a contingent of effective altruists who had left OpenAI. It is working to make AI safer by developing its own language models, which can cost tens of millions of dollars to build.Some organizations and individuals have already received their funds from BankmanFried and his colleagues. Others got only a portion of what was promised to them. Some are unsure whether the grants will have to be returned to FTXs creditors, said the four people with knowledge of the organizations.Charities are vulnerable to clawbacks when donors go bankrupt, said Jason Lilien, a partner at the law firm Loeb  Loeb who specializes in charities. Companies that receive venture investments from bankrupt companies may be in a somewhat stronger position than charities, but they are also vulnerable to clawback claims, he said.   For some foreign workers, Seattle tech layoffs can mean a forced exit   If Congress doesnt mandate Boeing 737 MAX safety retrofits, Europe will   The Seattle Times does not append comment threads to stories from wire services such as the Associated Press, The New York Times, The Washington Post or Bloomberg News. Rather, we focus on discussions related to local stories by our own staff. You can read more about our community policies here.","sentiment":2,"digital transaction":0.9361708164,"healthcare":0.0211754255,"news platform":0.8953535557,"data analytics":0.8777869344,"insurance":0.9870120883,"investment":0.7745366096,"global market":0.8182108998,"autonomous car":0.0539612249,"customer experience":0.994474113,"data science":0.8446218371,"cryptocurrency":0.0399707891,"camera":0.0368869901,"robot":0.1707309335,"chatgpt":0.4367165267,"image":0.4047122598,"voice":0.1509307772,"patient care":0.1093958765,"research":0.2525978386}
{"id":790,"cleaned text":"U.S. says humans will always be in control of AI weapons. But the age of autonomous war is already here.    July 8, 2021 at 1:00 am  Updated July 8, 2021 at 1:17 am   Picture a desert battlefield, scarred by years of warfare. A retreating army scrambles to escape as its enemy advances. Dozens of small drones, indistinguishable from the quadcopters used by hobbyists and filmmakers, come buzzing down from the sky, using cameras to scan the terrain and onboard computers to decide on their own what looks like a target. Suddenly they begin divebombing trucks and individual soldiers, exploding on contact and causing even more panic and confusion.This isnt a science fiction imagining of what future wars might be like. Its a real scene that played out last spring as soldiers loyal to the Libyan strongman Khalifa Hifter retreated from the Turkishbacked forces of the United Nationsrecognized Libyan government. According to a U.N. group of weapons and legal experts appointed to document the conflict, drones that can operate without human control hunted down Hifters soldiers as they fled.Drones have been a key part of warfare for years, but theyve generally been remotely controlled by humans. Now, by cobbling together readily available imagerecognition and autopilot software, autonomous drones can be massproduced on the cheap.Today, efforts to enact a total ban on lethal autonomous weapons, long demanded by human rights activists, are now being supported by 30 countries. But the worlds leading military powers insist that isnt necessary. The U.S. military says concerns are overblown, and humans can effectively control autonomous weapons, while Russias government says true AI weapons cant be banned because they dont exist yet.But the facts on the ground show that technological advancements, coupled with complex conflicts like the Syrian and Libyan civil wars, have created a reality where weapons that make their own decisions are already killing people.The debate is very much still oriented towards the future, said Ingvild Bode, an autonomous weapons researcher at the University of Southern Denmark. We should take a much closer look at what is already going on. Libya wasnt the only place drones that can kill autonomously were used last year. Turkey has used the same quadcopters to patrol its border with Syria. When Azerbaijan invaded Armenianoccupied territory in September, it sent in both Turkish and Israelimade loitering munitions  drones that can autonomously patrol an area and automatically divebomb enemy radar signals. These weapons look like smaller versions of the remotecontrolled drones that have been used extensively by the U.S. military in Iraq, Afghanistan and other conflicts. Instead of launching missiles through remote control, though, loitering munitions have a builtin explosive and destroy themselves on impact with their target.Since they have both remotecontrol and autonomous capability, its impossible to know from the outside whether humans made the final call to bomb individual targets. Either way, the drones devastated Armenias army, and the war ended two months later with Azerbaijan gaining huge swaths of territory.These kinds of weapons are moving firmly into the mainstream. Today, there are dozens of projects by multiple governments to develop loitering munitions. Even as countries like the United States, China and Russia participate in discussions about a treaty limiting autonomous weapons, theyre racing ahead to develop them.The advanced militaries are pushing the envelope of these technologies, said Peter Asaro, a professor at the New School in New York and a cofounder of the International Committee for Robot Arms Control, which advocates for stricter rules around lethal autonomous weapons. They will proliferate rapidly.Over the past decade, cheaper access to computers that can crunch massive data sets in a short time has allowed researchers to make huge breakthroughs in designing computer programs that pull insights from large amounts of information. AI advances have led to machines that can write poetry, accurately translate languages and potentially help scientists develop new medicines.But debates about the dangers of relying more on computers to make decisions are raging. AI algorithms are only as good as the data sets they were trained on, and studies have shown facial recognition AI programs are better at identifying White faces than Black and Brown ones. European lawmakers recently proposed strict new rules regulating the use of AI. Companies including Google, Amazon, Apple and Tesla have poured billions of dollars into developing the technology, and critics say AI programs are sometimes being deployed without full knowledge of how they work and what the consequences of widespread use could be.Some countries, such as Austria, have joined the call for a global ban on autonomous weapons, but U.S. tech and political leaders are pushing back.In March, a panel of tech luminaries including former Google chief executive Eric Schmidt, thenchief of web services, now chief executive of Amazon Andy Jassy and Microsoft chief scientist Eric Horvitz released a study on the impact of AI on national security. The 756page final report, commissioned by Congress, argued that Washington should oppose a ban on autonomous weapons because it would be difficult to enforce, and could stop the United States from using weapons it already has in its arsenal.It may be impossible to define the category of systems to be restricted in such a way that provides adequate clarity while not overly constraining existing U.S. military capabilities, the report said.In some places, AI tech like facial recognition has already been deployed in weapons that can operate without human control. As early as 2010, the arms division of South Korean tech giant Samsung built autonomous sentry guns that use image recognition to spot humans and fire at them. Similar sentry guns have been deployed by Israel on its border with the Gaza Strip. Both governments say the weapons are controlled by humans, though the systems are capable of operating on their own.But even before the development of facial recognition and superfast computers, militaries have turned to automation to gain an edge. During the Cold War, both sides developed missile defense systems that could detect an enemy attack and fire automatically. The use of these weapons has already had deadly effects.In March 2003, just days after the invasion of Iraq by the United States and its allies began, British air force pilot Derek Watson was screaming over the desert in his Tornado fighter jet. Watson, a squadron commander, was returning to Kuwait in the dead of night after bombing targets in Baghdad. Another jet, crewed by Kevin Main and Dave Williams, followed behind.Twenty thousand feet below, a U.S. Army Patriot missile batterys computer picked up one of the two jets, and decided it was an enemy missile flying straight down toward it. The system flashed alerts in front of its human crew, telling them they were in danger. They fired.Watson saw a flash and immediately wrenched his plane to the right, firing off flares meant to distract heatseeking missiles. But the missile wasnt targeting him. It shot up and slammed into Main and Williamss plane, killing them before they had time to eject, a Department of Defense investigation later concluded.  Alaska Airlines asks execs to help move baggage at SeaTac amid worker shortage, surging travel   Gateses have two years to decide if they can share foundation   Seattlearea home shoppers find some signs of hope  but prices are climbing at a daunting pace   They didnt expect to retire early. The pandemic changed their plans.   I am my fathers retirement plan. Its an honor that terrifies me.   Its not something Ill ever forget, Watson, who left the Royal Air Force in the mid2000s and is now a leadership coach, recounted in an interview recently. As a squadron commander, they were my guys.Patriot missile crews were warned about operating on autonomous mode, but it took another friendlyfire incident almost two weeks later, when the system shot down and killed U.S. Navy F18 pilot Nathan Dennis White, for strict rules to be put in place that effectively stopped the missile batteries from operating for the remainder of the war.Weapons like the Patriot usually involve a computer matching radar signatures against a database of planes and missiles, then deciding whether the object is a friend or foe. Human operators generally make a final call on whether to fire, but experts say the stresses of combat and the tendency to trust machines often blurs the line between human and computer control. We often trust computer systems if a computer says I advise you to do this, we often trust that advice, said Daan Kayser, an autonomous weapons expert at Dutch peacebuilding organization PAX. How much is the human still involved in that decisionmakingThe question is key for the U.S. military, which is charging ahead on autonomous weapons research but maintains that it wont ever outsource the decision to kill to a machine.In 2012, the Defense Department issued guidelines for autonomous weapons, requiring them to allow commanders and operators to exercise appropriate levels of human judgment.Though a global, binding treaty restricting autonomous weapons looks unlikely, the fact that governments and weapons companies are stressing that humans will remain in control shows that awareness around the risks is growing, said Mary Wareham, a Human Rights Watch director who for years led the Campaign to Stop Killer Robots, an international effort to limit autonomous weapons.And just like land mines, chemical weapons and nuclear bombs, not every country needs to sign a treaty for the world to recognize using such weapons goes too far, Wareham said. Though the United States has refused to sign on to a 2010 ban against cluster munitions, controversy around the weapons led U.S. companies to voluntarily stop making them.Still, the pandemic has slowed those efforts. A meeting in Geneva scheduled for the end of June to get discussions going again was recently postponed. The U.S. and British militaries both have programs to build swarms of small drones that operate as a group using advanced AI. The swarms could be launched from ships and planes and used to overwhelm a countrys defenses before regular troops invade. In 2017, the Pentagon asked for proposals for how it could launch multiple quadcopters in a missile, deposit them over a target and have the tiny drones autonomously find and destroy targets.How can you control 90 small drones if theyre making decisions themselves Kayser said. Now imagine a swarm of millions of drones.The U.S. military has also experimented with putting deeplearning AI into flight simulators, and the algorithms have shown they can match the skills of veteran human pilots in grueling dogfights. The United States says AI pilots will only be used as wingmen to real humans when theyre ready to be deployed.Similar to other areas where artificial intelligence technology is advancing, it can be hard to pinpoint exactly where the line between human and machine control lies.Just like in cars, there is this spectrum of functionality where you can have more autonomous features that can be added incrementally that can start to, in some cases, really blur the lines, said Paul Scharre, a former Special Operations soldier and vice president and director of studies at the Center for a New American Security. He also helped draft the Pentagons guidelines on autonomous weapons.Autonomy slowly builds as weapons systems get upgraded over time, Scharre said. A missile that used to home in on a single enemy might get a software upgrade allowing it to track multiple targets at once and choose the one its most likely to hit. Technology is making weapons smarter, but its also making it easier for humans to control them remotely, Scharre said. That gives humans the ability to stop missiles even after theyre launched if they realize after the fact they might hit a civilian target.Still, the demand for speed in war will inevitably push militaries to offload more decisions to machines, especially in combat situations, Kayser said. Its not hard to imagine opposing algorithms responding to each other faster than humans can monitor whats happening.You saw it in the flash crashes in the stock market, Kayser said. If we end up with this warfare going at speeds that we as humans cant control anymore, for me thats a really scary idea. Its something thats maybe not even that unrealistic if these developments go forward and arent stopped.  The Seattle Times does not append comment threads to stories from wire services such as the Associated Press, The New York Times, The Washington Post or Bloomberg News. Rather, we focus on discussions related to local stories by our own staff. You can read more about our community policies here.","sentiment":2,"digital transaction":0.4901351929,"healthcare":0.0609400757,"news platform":0.8854292631,"data analytics":0.8776344657,"insurance":0.1116929501,"investment":0.6388871074,"global market":0.4557788074,"autonomous car":0.1255136281,"customer experience":0.4543591142,"data science":0.6294721365,"cryptocurrency":0.1156912297,"camera":0.2379249781,"robot":0.8750670552,"chatgpt":0.9901680946,"image":0.7817310691,"voice":0.7512738109,"patient care":0.0490879379,"research":0.9325062633}
{"id":794,"cleaned text":"Melting frozen memories, AI helps Japanese recall war days TOKYO AP  When Tokuso Hamai saw the colorized version of an old blackandwhite photo of a picnic held under cherry tree blossoms sometime before World War II, forgotten memories of family members, most of whom died in the atomic bombing of Hiroshima in 1945, came pouring out. In colorized photos, people come to life, said Hamai, now 86. I often played near the picnic site, and sometimes I would do some naughty things and get scolded by my father. The power of a colorized photo to reignite lost memories was eyeopening for Anju Niwata, a student who gave Hamai the colorized photo as a present three years ago. The 75th anniversary of the end of World War II is Saturday, and Niwata, now 18, said she hopes it will bring attention to her project with a Tokyo University professor to painstakingly colorize photos using artificial intelligence and their own research to spark lost memories for the rapidly aging generation who experienced the war. Seeing Niwata share the colorized pictures with Hamai, and then watching him recall his old memories one after another, made it feel like the ice around his frozen memories was melting away, said Hidenori Watanave, the professor who taught Niwata how to colorize monochrome pictures using AI. Niwata and Watanave call their photo colorization project Rebooting Memories, and they published a book last month of the colorized versions of about 350 monochrome pictures taken before, during and after the war. Watanave and Niwata use three different types of AI photo coloring software. The AI is useful in identifying the accurate colors of natural things, such as the sea, the sky and human skin, but it cannot accurately colorize humanmade objects like roofs and clothes, Watanave said. So Niwata and Watanave painstakingly finish the AIcolorized photos by hand to get more accurate colors based on the photo owners memories and advice from experts. They also look through historical documents and archives that show what the colors should look like. For Watanave, Twitter has become a powerful platform to pursue the colorization project. When he posted a picture of the Hiroshima atomic bomb mushroom cloud that the Al software had colorized as white, a film director suggested that it should be more orange. Watanave checked the testimonies of those who saw the mushroom cloud and also researched the components of the atomic bomb to see if it could actually make an orangish color. After he confirmed that it could, Watanave added orange to the picture. While the accuracy of the color is important, Niwata and Watanave said the most vital thing is that the colorized photos match the memories of the photo owners. Time, however, is running out the average age of the atomic bomb survivors is about 83. There are often moments of wonder when the elderly see the revitalized photos. When Niwata showed the colorized version of a family photograph to a war survivor who had dementia, for example, he remembered the type of flowers in the photograph just a few weeks later, he was unable to speak. Niwata said that publishing the colorization book during the coronavirus outbreak has made her think about the pandemics link to the war. Our everyday lives have been stolen away by the coronavirus in a flash, which I think resembles what happened in the war. Thats why I feel like now is an opportunity for people to imagine wartime life as their own experience, she said. Watanave hopes that using new technology will help younger Japanese feel more of an attachment to those who lived through the war. People are forgetting wartime memories. We need to revitalize those old memories by using the latest method of expression and delivering it to the hearts of many people, he said. By the time we mark the 80th or 85th anniversary, we need to come up with a new way of expressing wartime memories. Lodi officers body cam films harrowing rescue of man from train I tried a virtual visit with a therapy dog. It was adorable.","sentiment":2,"digital transaction":0.2611830235,"healthcare":0.003043269,"news platform":0.3119565248,"data analytics":0.6215806007,"insurance":0.8622846603,"investment":0.4410125017,"global market":0.9990310669,"autonomous car":0.0112513797,"customer experience":0.9639908671,"data science":0.4699806571,"cryptocurrency":0.0079307556,"camera":0.016067734,"robot":0.2834310234,"chatgpt":0.9178915024,"image":0.1572322398,"voice":0.0874097794,"patient care":0.0128413215,"research":0.9400631785}
{"id":797,"cleaned text":"Investment, research driving AI growth in India, says study Hyderabad: Higher investment and research is driving significant growth of Artificial Intelligence AI in India, finds a study.The AI Index 2021 annual report by the Indian School of Businesss ITfocused think tank, Srini Raju Centre for Information Technology and Networked Economy SRITNE, captured trend, research  development education, and entrepreneurial activity. The ISB research team, led by Professor Deepa Mani, found that investments in AImanaged processes have grown substantially across businesses in India. It noted that the ongoing pandemic sped up technology adoption across most business verticals in 202021. While until a few years back, it was mostly IT firms that were adopting AI on a large scale now, other sectors are fast catching up, thanks to phenomenal growth of startups and ongoing investment activities in the country.The report was formally launched Friday by Telanganas Principal Secretary, Industries  Commerce and Information Technology, Jayesh Ranjan and Microsoft Indias National Technology Officer, Dr. Rohini Srivathsa, in a virtual event.Srivathsa said that an earlier NASSCOM study has indicated that data and AI can add half a trillion USD to Indias GDP. The pandemic has led people to consider investments in AI and automation proactively, she said, adding that usage of AI would also contribute towards the framing of better Covid response and faster economic recovery going ahead.The research analysis revealed that while overall activity and investments are increasing significantly, these activities are concentrated in a few regions, said Mani, Professor and Area Leader of Information Systems, ISB and Executive Director, SRITNEISB.AI has helped Indian businesses to be resilient to the Covid19 pandemic in the country and helped them redesign their models for tomorrow.According to the report, there has been steady growth in AIrelated research publications, collaborations, and patents. Machine Learning emerged as a popular subject for AI researchers, with over 37 per cent of the AI related publications dedicated to the subject in 2020.Distribution of startups across geographies revealed that Karnataka leads with the maximum number of AI startups followed by Maharashtra.As per our analysis of online job searches for the period 20192020, there has been a steady growth in AIrelated jobs posting in India, though it represents only a small percentage 2 per cent in January 2019 March 2020 of total jobs posted in India, says the report.In India, the popularity of the keyword Machine Learning grew steadily from 2015 to 2020, overtaking Artificial Intelligence in 2017.There is, however, minimal organised data on the demand and supply of AIrelated skills and human capital in India. Therefore, the gap between skills and employment in the AI domain is not entirely analysed yet.Our study suggests that while there has been a significant advancement in knowledge creation and appropriation in the field of AI, much more needs to be done, especially with respect to skilling and education. We will continue to track the growth of this technology across the critical areas mentioned in the report. We feel that the focus should be on widespread skilling, investments and education building in other regions as well, which in turn would help to reduce inequality, said Mani. Crypto Crash: Bitcoin hits 99 day low, is this payback timeInterest rate cut on small savings order was an oversight: GovtAfter petrol, LPG price goes upPetrol 100 not outValentines Day gift","sentiment":2,"digital transaction":0.1367121339,"healthcare":0.054384768,"news platform":0.2663276792,"data analytics":0.3694164455,"insurance":0.0269595813,"investment":0.4134480059,"global market":0.8511788845,"autonomous car":0.1484524161,"customer experience":0.2521072328,"data science":0.1774440259,"cryptocurrency":0.0352292508,"camera":0.0833549201,"robot":0.2899249196,"chatgpt":0.2331333905,"image":0.1924393624,"voice":0.110718891,"patient care":0.0813275576,"research":0.5417744517}
{"id":803,"cleaned text":"With ChatGPT, is AI coming of age  or starting to reach its limitsIs AI coming of age  or starting to reach its limitsWere sorry, this feature is currently unavailable. Were working to restore it. Please try again later.DismissSkip to sections navigationSkip to contentSkip to footerOur networkOpen NavigationMenuThe Sydney Morning HeraldSubscribeThe Sydney Morning HeraldcloseSearch SiteSectionsNetworkHomeSydneyNSWPoliticsShow subsectionsFederalNSWVictoriaQueenslandWestern AustraliaBusinessShow subsectionsCompaniesMarketsThe economyBanking  financeEntrepreneurshipMediaWorkplaceWorldShow subsectionsNorth AmericaEuropeAsiaMiddle EastOceaniaSouth AmericaAfricaNationalShow subsectionsVictoriaQueenslandWestern AustraliaOpinionPropertyShow subsectionsNewsTitle DeedsLivingAuctionsFinancingSportShow subsectionsNRLRugby unionCricketSoccerAFLRacingTennisNetballBasketballMotorsportCyclingGolfNFLAthleticsSwimmingBoxingCultureShow subsectionsMoviesTV  radioMusicCelebrityBooksComedyDanceMusicalsOperaTheatreArt  designTV guideLifestyleShow subsectionsHealth  wellnessFashionLife  relationshipsBeautyStyleHoroscopesGood WeekendSpectrumSunday LifeMoneyShow subsectionsSuper  retirementInvestingBankingBorrowingSavingTaxPlanning  budgetingInsuranceEducationHealthcareEnvironmentShow subsectionsConservationClimate changeSustainabilityWeatherTechnologyShow subsectionsVideo gamesHome techPhonesGadgetsDriveTravellerGood FoodPremiumSubscribeTodays PaperDaily Crosswords  SudokuMoreLettersEditorialColumn 8ObituariesExplainersQuizzesWeatherThe Sydney Morning HeraldThe AgeBrisbane TimesWAtodayThe Australian Financial ReviewDomainCommercial Real EstateDriveGood FoodTravellerAdvertisementAnalysisNationalScienceIs AI coming of age  or starting to reach its limitsBy Liam Mannix December 13, 2022  7.30pmSaveLog in, register or subscribe to save articles for later.Normal text sizeLarger text sizeVery large text sizeAdvertisementExamine, a free weekly newsletter covering science with a sceptical, evidencebased eye, is sent every Tuesday. Below is an excerpt  sign up to get the whole newsletter in your inbox.When British scifi author Arthur C Clarke wrote that any sufficiently advanced technology is indistinguishable from magic, he was thinking of UFOs. But the phrase came to mind as I played with OpenAIs latest trained model, ChatGPT.First, I commanded ChatGPT to write me a script of computer code to automate a tedious piece of research. Then I had it produce a script for Peter Weirs Gallipoli, but with the instruction that all the movies horses should be replaced by extremely tiny horses. Heres an excerpt of a key scene, with Archy and Frank who are real characters in the movie and a horse named Tiny Tim who was definitely not in the movie under German fire:Archy: clutching his arm in pain Im fine but Tiny TimFrank looks at the tiny horse, who is still cradled in Archys arms. Despite the injury, the horse still looks alive, its tiny eyes filled with courage and determination.Frank with admiration: Look at him. Hes a little fighter.The whole experience feels magical. An artificial intelligence that can turn my dumb joke into a convincing movie script Watching OpenAIs rapid advances over the past few years  conversational AI, dominance in a variety of video games, surpassing humans at writing computer code, making new artworks based on user requests  its easy to think AI is coming of age.An image generated by AI DALLE to illustrate a story about the promise and perils of AI.Credit:DALLEBut speak to AI scientists and they have a different take. ChatGPT is impressive, but its still dumb, says AI researcher and director of CSIROs Data61, Professor Jon Whittle. He says it applies a bruteforce approach to AI  and we may be nearing the limits of where that approach can take us.How ChatGPT worksAdvertisementChatGPT is a deeplearning AI model. In essence, it is fed a huge volume of data  broad swathes of the internet  and uses that to build a statistical model of how sentences are built. For instance, the model can make an educated guess that the word black is highly likely to follow the sentence the cat is.They are like the autocomplete on your phone, predicting the next letter you want to type, says Professor Toby Walsh, chief scientist at the University of NSWs AI Institute.Professor Anton Van Den Hengel, director of the Australian Institute for Machine Learning, compares it to a parrot, simply repeating back what it thinks we want to hear.In addition to digesting Wikipedia and Reddit, ChatGPT works with human AI trainers to refine its answers. But thats clever tuning. The real key is scale. When AI was first being developed, Whittle tells me, researchers tried to write humanstyle rules for computer minds to allow them to work things out logically, an approach known as symbolic AI. But this approach floundered because it did not scale  imagine trying to write a logic rule for every object in existence.Another response from DALLE when asked to generate artwork to illustrate a story about AI.Credit:DALLEDeep neural networks succeeded because they took the opposite approach: feed the data into the AI and let it write its own rules based on what it finds. See enough pictures of the sky and an AI can reliably tell people it is blue.The stunning advance has been the discovery that if you add more and more data, and more and more compute power, these artificial neural networks can do surprising and amazing things.Theres been no massive quantum leap in the technology. Its just the computers get bigger, the data gets bigger, says Van Den Hengel.ChatGPT is now so good it is likely to be transformative, particularly in areas where humanlike conversation or writing is required, such as writing essays which it can do deftly, and with proper references or doing homework.At the moment, its looking a lot like the end of essays as an assignment for education, Newcastle Universitys Lilian Edwards told Nature. Journalism, too I asked ChatGPT to write me a news lede about advances in AI computing for a newspaper. Heres what it came up with: Recent advances in artificial intelligence have led to significant improvements in the field of computing, with AI systems now capable of tackling increasingly complex tasks and challenges. This technology is being used in a variety of fields, from healthcare to finance, and is expected to continue to grow in importance in the coming years.Dull, but acceptable.Dumb intelligenceLook again at ChatGPTs news lede. The words look right, but it lacks meaning. It says nothing. It does not really know what its talking about.This is the key to thinking about the current state of AI. It knows which words come next without knowing what they mean. It might be able to paint you a picture of a dog but it does not develop its own idea of dogness or catness, says Van Den Hengel.There are two clear physical limits to the bruteforce approach to building AI. ChatGPT already runs on a supercomputer. To improve, we need to keep adding computer power, but Moores Law  which says the number of transistors on a computer chip doubles every two years  may be dead. And ChatGPT has already been fed most of the contents of the internet. Theres very little data left, says Walsh.Its possible scientists will find ways to overcome these natural limits. So far, the proponents of scale are on a winning run. But to build genuinely smart AI, one that really can develop its own idea of catness, Whittle suggests researchers may need to return to symbolic AI.Deep neural networks are good at pattern recognition. Symbolic AI could add in the ability to reason.Symbolic AI understands symbols: squares, circles, cats, dogs. It could be told that some symbols are similar but not the same, like cats and dogs. Using those symbols and basic rules of logic, it could tell you with certainty that a dog is not a cat. Some scientists are working to use deep neural networks to build those databases of symbols, which symbolic AI could then use to reason with  potentially taking us closer to the fields holy grail: artificial general intelligence.Arthur Clarkes classic novel 2001: A Space Odyssey and the Stanley Kubrick film of the same name starred an artificial general intelligence of its own: HAL 9000. HAL controlled ship and crew, even conducting psychological reports on his human charges.Without investment in AI, Van Den Hengel worries that Australia faces a similar fate: someone else will hold the algorithms, and well simply be doing as were told  planting the crops, digging the ore, driving the taxis, all as dictated by inscrutable AI.What happens is effectively the uberfication of our industries, he says. We wind up, despite our economic advantages, selling the value to these countries that have invested and own the algorithms.Enjoyed this article The Examine newsletter explains and analyses science with a rigorous focus on the evidence. Sign up to get it each week.SaveLog in, register or subscribe to save articles for later.License this articleScienceAnalysisAILiam Mannix is The Age and The Sydney Morning Heralds national science reporter.Connect via Twitter.Most Viewed in NationalLoadingFrom our partnersLoading 3rd party ad contentLoading 3rd party ad contentLoading 3rd party ad contentLoading 3rd party ad contentAdvertisementThe Sydney Morning HeraldTwitterFacebookInstagramRSSOur SitesThe Sydney Morning HeraldThe AgeBrisbane TimesWAtodayThe Australian Financial ReviewDomainTravellerGood FoodDriveClassifiedsTributesCelebrationsPlace your adCommercial Real EstateThe Sydney Morning HeraldContact  supportAdvertise with usNewslettersAccessibility guideSitemapPhoto salesPurchase front pagesContent licensingOur eventsWork with usTerms of usePrivacy policyPress CouncilCharter of Editorial IndependenceProducts  ServicesSubscription packagesMy accountSubscriber FAQsDelivery statusTodays PaperDaily Crosswords  SudokuCopyright  2022Subscribe","sentiment":2,"digital transaction":0.0960444361,"healthcare":0.0708152354,"news platform":0.2161313146,"data analytics":0.320637852,"insurance":0.0447400697,"investment":0.3059076369,"global market":0.6532882452,"autonomous car":0.110017024,"customer experience":0.4483479261,"data science":0.2124247253,"cryptocurrency":0.0355111584,"camera":0.1344458014,"robot":0.0990010947,"chatgpt":0.2326194793,"image":0.2604879439,"voice":0.2570452988,"patient care":0.0493432432,"research":0.8885959983}
{"id":812,"cleaned text":"Samsungs Neon avatars aim to be AI companions youll mistake for human One of the muchhyped announcements at CES 2020 is Samsung Neon, a project with a simple goal: create completely original i.e. not based on actors digital avatars that converse and learn until theyre indistinguishable from humans.Such conversational and friendly AI would find plenty of use in the hospitality and entertainment industries, though they could be useful for any customer service role as well, from bank tellers to baristas. But its the simple yet lofty aspiration of Neon  the first venture from Samsung semistartup STAR Labs  that could set the project apart from prior AI bots. Its founder and PresidentCEO Pranav Mistry wants these creations to be humanitys friends.Which explains why Mistry refers to these AI  called Neons, as a proper noun  as new beings waiting to be refined into existence. He calls them Artificial Humans.Neon is like a new kind of life, Mistry stated in a press release. There are millions of species on our planet and we hope to add one more. Neons will be our friends, collaborators, and companions, continually learning, evolving, and forming memories from their interactions.This unbridled futurism invites skepticism, and the press response since Neon was unveiled hasnt been too kind. Its pretty clear that Neons tech is in early stages: while STAR Labs booth on the CES show floor is lined with a variety of Neon avatars, theyre running through preset routines, and arent ready to have freeform conversations.During a demo presentation, Mistry asked one of their Neons  which resembled a punkish woman with a shaved head  some questions that got adequate responses, but her facial expressions and mouth movements were clunky and unnatural. And yet, right next to it, another instance of the same Neon was running through its preset routine with much more fluid motions. The comparison showed how far Neon has to go before people interact with its AI individuals as the project intends. Because whats really important  what Neon needs to pull off  is illusion. To converse with Neons like we would humans, we need to believe were chatting with something that can respond with enough context and quick cadence.Image credit: FutureHow to make AI converse like humansTo Neons credit, the team both acknowledges the project is in its early days Neon started only four months ago and has a strategy for making its creations into conversation partners.Phase one for Neons timeline begins with development of a central technology called the Core R3 engine, crudely broken down to Reality, Realtime and Responsive, which are sort of archdirectives Neon is following.The Reality directive means talking to a Neon should feel like talking to a human  including limiting the Neons to human knowledge. Theyll be programmed not to be encyclopedias  no instant internet scanning in the background. So if you ask a Neon a factual question, theyll reply by asking if you want them to Google it.Compared to every smart assistant out there, this sounds counterintuitive, the equivalent of having Neons with an arm tied behind their back. But its simply counter to what Mistry and his team want interactions with Neons to be like. Think about it this way: you give orders to Siri and Alexa with Neon, Mistry wants you and an avatar to have conversations that develop memories and, essentially, a sort of protorelationship.Which doesnt mean Neons will be dumb  theyll just be loaded up with knowledge patterned to each Neons joblike role at the CES booth, each Neon had a name and title like Student or Flight Attendant. And to keep conversations going in Realtime the second directive, that knowledge will be primarily local, avoiding the delay beaming your questions to the Cloud and back. That should enable them to respond to any question in 20ms, an interval humans cant really perceive.The other half of believability lies in the responses themselves  varied, unpredictable, natural. At least in how they seem to us. The third directive, Responsive, means Neons will gauge your emotions and vocal tone to respond intuitively. They have their own emotional range, too, which Mistry and his team displayed on a graph during their presentation  and in their further peek behind the curtain, they revealed a mental map of nodes representing the 7 million responses they contain. If you ask a Neon the same question twice, they should respond differently.Thats a lot of ambition, and far from what we saw Neons capable of at STAR Labs CES booth. Toward the end of 2020, the group will augment their creations with SPECTRA, a tech cluster including intelligence, learning, emotions, and memory  all the things that should allow Neons to grow and become rounded digital individuals.Will that mean Neons will develop idiosyncracies Personalities Biases Its too early to tell, and in truth, it doesnt seem like the team knows. At this point, theyre following aspirations more than expectations, and CES was an introduction rather than a refined product reveal  heck, STAR Labs doesnt even plan to release a beta until the end of 2020.Image credit: FutureSo...what will Neons be used forUnveiling Neon at CES 2020 was an exploratory move  the team wanted the public to respond and tell them what they think Neons could be used for, STAR Labs senior technical content writer and neuroscientist Angie Chiang told TechRadar.In terms of applications, we need help. Were not targeting one specific field, so we need people who are experts in their domains to help us make Neons useful to them, Chiang said.While installing Neons as customer service reps seems an obvious choice, essentially replacing chatbots with friendlier and personable Artificial Humans, theres far more potential in deploying Neons in roles that could use more humanity when actual humans arent available. Chiang recalled her experiences volunteering in convalescence homes  and installing a Neon to keep the sick company as they recover could be incredible palliative care.Neons could offer humanlike interaction to the remote, the ill, the elderly, the lonely. They could sub in for human employees at inconvenient times  like overnight station anchors when news breaks, Chiang suggests. They could be therapists or simple confidants right out the gate, STAR Labs is assuring that privacy is built into the core of Neons  only you and your Neon have access to your interactions, and they wont share your data without permission.They could be actors  but instead of simply churning out Neons and sending them off, STAR Labs will treat them as individuals that are licensed out. So perhaps a museum would secure a Neon for an exhibit, and opt to have it loaded up with relevant knowledge one could even work as a museum guide.There are a couple of concerns, though  first, that Neons could take jobs. Its possible, of course, as companies look to cut costs by replacing customer support with online chatbots and automated help lines. Theres also the question of how Neons will affect work valuation  will Neons be cheaper than hiring out a human worker in particular fieldsBut Chiang imagines Neons will augment the human experience, not replace it 15 years ago, nobody used smartphones, and now theyre constant portals helping connect us and improve our efficiency.People have always worried that technology will replace the workforce in some fields. But technology has always been advancing: Im a scientist, so my thought is always that you build technology as advancement for humans, Chiang said. If you have a tool to advance yourself, why would you not use itThe second concern is whether Neons can be used to impersonate people, a la Deepfakes  which is a completely different technology, STAR Labs asserts in an FAQ, and Neons cant be used to manipulate existing media. Nor can people copy themselves or others into Neons while some of their current creations looks are based on real people, eventually, Neons will be completely original.Were not making replicates of people. Thats not us, Chiang said.Which leads to the next question: Will Neons gain sentience, rise up, and replace humanityIm a neuroscientist: we havent even figured out the brain How do you even model something that you feel will be even more intelligent than the human brain when we dont even fully know how the human brain works Chiang said.Image credit: FutureNeons: making machines more human to stop humans from sliding into machinesWhile introducing Neon to a crowd of huddled media and tech industry professionals at STAR Labs CES booth, Mistry explained how his young daughter interacted with the smart assistant Alexa: she shouts at it.Why Because smart assistants, like a lot of AI today, are perfunctory and submissive. They serve, they help, and they dont impose. And the language we use to interact with them are pure commands. Why would we bother with the same consideration we use when speaking with humans That has an effect on us, argues Mistry.We are becoming more like machines rather than machines becoming more like humans, Mistry said. Just enabling speech on machines or UI that is human is not going to make them human. With Neon we want to break that barrier. We want to make our conversations with machines more human also.These are STAR Labs ambitions, and well wait to see if their execution matches such lofty goals. They dont have a business model yet or a planned rollout, and aside from the aforementioned beta, 2020 seems to be a year of research and development to see what people and industries want from Neons  and eventually, what Neons can be capable of.Perhaps STAR Labs will share more by the time they launch their own event, Neon World 2020, though they havent publicly announced exactly what that will be or when it will happen. It, like the rest of Neon, is largely a mystery box, which has earned it plenty of scorn and critique from online press. But for her part, Chiang isnt fazed.Its funny, I read an article that, many years ago, people made fun of electric cars until Tesla came out and proved that it was useful. Sometimes you just need to be the ones that introduce it, Chiang said.Check out all of TechRadarsCES2020 coverage. Were live in Las Vegas to bring you all the breaking tech news and launches, plus handson reviews of everything from 8K TVs and foldable displays to new phones, laptops and smart home gadgets. Get the best tech deals, reviews, product advice, competitions, unmissable tech news and more No spam, we promise. You can unsubscribe at any time and well never share your details without your permission. 4The best Netflix series in the US August 2019: fantastic Netflix shows 5Best free games 2020: the top free games to download on PC 1The best free video editor 2020: free video editing software for all your projects 4One of the best OLED TVs is finally coming to the US TechRadar is part of Future plc, an international media group and leading digital publisher. Visit our corporate site. Future Publishing Australia ABN: 96 734 906 323  PO Box 1077, Mount St,","sentiment":2,"digital transaction":0.1608891934,"healthcare":0.0098423436,"news platform":0.177754879,"data analytics":0.6419121623,"insurance":0.0070617842,"investment":0.6028795242,"global market":0.9085273147,"autonomous car":0.0257285498,"customer experience":0.1274940223,"data science":0.1538341343,"cryptocurrency":0.0112160165,"camera":0.046630051,"robot":0.0196813084,"chatgpt":0.6340532899,"image":0.1935661733,"voice":0.1278466731,"patient care":0.0109003484,"research":0.9762517214}
{"id":821,"cleaned text":"Is this by Rothko or a robot We ask the experts to tell the difference between human and AI art An image generated using DallE with the prompt Mark Rothko Abstract Expressionist oil painting color field maroon orange border. Composite: GettyImage generated by Jo LawsonTancred and Philip BoothAn image generated using DallE with the prompt Mark Rothko Abstract Expressionist oil painting color field maroon orange border. Composite: GettyImage generated by Jo LawsonTancred and Philip BoothAn art historian, a critic and a gallerist are tasked with guessing whether a piece is by an important artist or a clever bot. It turns out its harder than it looksJo LawsonTancredSat 14 Jan 2023 06.55 ESTThe year 2022 was when AIgenerated images went viral. Online, you may have come across very realistic yet suspiciously improbable images of, say, an astronaut riding a horse through space or an avocado doubling as an armchair.Numerous new generators  including DallE, Midjourney and Stable Diffusion  offer anyone with an internet connection the chance to conjure up their own strange apparition, simply by typing in a prompt for the AI. For example, astronaut astride horse on Mars. Or, for this article, Mark Rothko Abstract Expressionist oil painting  yes, the image above isnt a real Rothko. The possibilities have been endless, the opportunity for mememaking infinite.It should not be surprising that a great many artists who have spent a lifetime honing their skills are a little put out by this latest disruption. Are companies going to keep hiring designers when they can produce prototypes themselves for free Will budgets stretch to include animators if their hand can be imitated from a simple text description Advocates of AI have insisted that creatives should have nothing to worry about and can adapt their process to incorporate or work around technological advances, much like the modernists did with the invention of photography.But if those historical greats were alive and working today, would they also be watching their backs And could a computer ever hope to reproduce the emotional depth that gives great art its charm and meaningTo find out, we set a challenge for three art experts: Bendor Grosvenor, art historian and presenter of the BBCs Britains Lost Masterpieces JJ Charlesworth, art critic and editor of ArtReview and Pilar Ordovas, founder of the Mayfair gallery Ordovas. Each was invited to look at pairs of artworks of a similar style and period over Zoom to see if they could tell which was generated by a machine. All three admitted to finding it tougher than expected Nineteenthcentury landscapeLeft Homer Watson, Down in the Laurentides 1882. Right An image generated using DallE with the prompt Landscape oil painting Constable Claude Corot. Composite: Homer Watson National Gallery of Canada Image generated by Jo LawsonTancred and Philip BoothBendor Grosvenor When authenticating a painting, composition is usually the last thing I would look at, after brushstrokes and condition. The one on the left looks like New Zealand, with the cows a bit plonked in and the grass not particularly well painted  but I quite like the way the light falls on the hills. Theres something about the picture on the right that looks a bit too good to be true. Its got the bright, contrasty clouds of a Constable and the winding river reminds me of the French Barbizon school. If you asked a computer to make a Constable, thats probably what it would come up with.Verdict: correct I think the AI image is quite impressive, actually. Its like a blend between a Corot and a Constable. I cant even draw a smiley face so take my artistic input with some scepticism, but I would say it needs a figure or a little boat to give it a focal point.JJ Charlesworth Landscape can mean a lot of things from a lot of places, and theres also the matter of whether its good. On the painting on the right, theres something a bit confused at the edges and Im not sure where the river goes  but then some painters wouldnt have been too bothered about that. The left one seems to recall the American grand landscape painters. The foliage is weird at the front but the mountains have a humidity haze, theres the cows and a little ship puttering away. My hunch is that the left one is real, by a very conventional painter who understands the codes of the genre.Verdict: correct The modernist artists privileged compositional coherence with a degree of lyricism. Its easy for critics to detect when someone is doing it badly, but the machine doesnt notice. That tree in the middle is clumsy and I dont know whether a painter interested in how to put together a picture would have done it.Pilar Ordovas In real life, I would always look at the surface and the application of paint and would never judge an artwork from an image on Zoom. The one on the left doesnt feel real to me but, then again, Im sure there is a landscape that looks like this somewhere in the world. With the one on the right, I can feel the water, the trees and the air, whereas the above painting just feels flat to me and pixelated, so I think its fake.Verdict: wrong I wouldnt normally give judgment on a painting without viewing it in real life. I look at the righthand picture and think of Corot and a number of other artists, so thats what its done, rightAbstract expressionismLeft Gary Wragg, Chien 1 1983. Right An image generated using DallE with the prompt abstract oil painting by Tapies Dubuffet. Composite: Gary Wragg Image generated by Jo LawsonTancred and Philip BoothBG Even if these were two genuine works I wouldnt know where to begin. I cant think of anything interesting to say about either of them. One is probably an extremely famous thing that I should know about but Im so rubbish on abstract art. I would go for the AI one being the squiggly one on the left because I feel theres something a little bit digitised about some of those scratch marks to the right. The picture on the right feels like the product of  oh, I dont know Yes, Ill stick with the one on the left being the AI.Verdict: wrong Well, the one on the right is better than the one on the left in my opinion. I dont really have that kind of thing on my wall but if you offered me the choice, I would actually go for the AI one. Theres something slightly pleasing about the colours and shapes, a bit like a Ben Nicholson.JC Abstraction is obviously very anticonventional and isnt anchored in figuration, so you have to assess each one on their own merits. Theres actually more diversity in the left one, theres a deployment of these scratch marks that is quite complicated  Put it this way, I find myself more drawn to it. The elements are speaking to each other more so it seems to have a motive. The right hand picture is pleasant enough but there is less structuring principle so, if it were by a human, I would struggle to care much about it.Verdict: correct With this genre its very hard and the idea of cohering logic is important. Most abstract paintings come from a debate about whats necessary in the mind of the artist, rather than whats arbitrary. The one on the left seemed more subtle, but could be simulated from having seen too many Cy Twomblys.PO Im not sure about the shapes and the lines in the image on the left, but it does make me think of very early Pollock, though less colourful. The one on the right could relate to many early works from some of the abstract expressionists or, perhaps, Tancredi and certain Italian artists from the 1950s and 60s. Im sure the AI is looking at these existing works in order to create something based on them but I would still say the one on the right is real.Verdict: wrong When its not by a particular artist you know very well, its much harder to determine what feels wrong. With a specific artist you look at how they worked at a particular time, their colours, their compositions and what the feel of it should be. If it could be any artist, its a bit random.Sign up to Inside SaturdayFree weekly newsletterThe only way to get a look behind the scenes of our brand new magazine, Saturday. Sign up to get the inside story from our top writers as well as all the mustread articles and columns, delivered to your inbox every weekend.Privacy Notice: Newsletters may contain info about charities, online ads, and content funded by outside parties. For more information see our Privacy Policy. We use Google reCaptcha to protect our website and the Google Privacy Policy and Terms of Service apply.Dutch stilllifeLeft Ambrosius Bosschaert, Still Life with Peaches.RightAn image generated using Stable Diffusion with the prompt Dutch old master still life flowers in vase on table dark black Bosschaert. Composite: Ambrosius BosschaertNational Gallery Prague  Image generated by Jo LawsonTancred and Philip BoothBG The plate of apples on the left looks like an Adriaen Coorte  quite sophisticated and I like the reflection on the plate. The flowers look quite simplistic and the petals dont quite work but I think youre playing a bit of a trick on me here  because you can get still lifes from the period that look quite clunky and thats part of their appeal. So its very tricky The image on the right is full of what you would want to describe as deficiencies: the tablecloth looks like a bit of foldedup cardboard. However, I think it might be genuine because I can see cracks on the surface that I dont think the AI would put there. If it has, its very, very clever.Verdict: wrong Really Wow, I didnt know it could do that. Well thats very good.JC The right one looks familiar. You get the overstylised flowers in quite a number of still lifes. The bland apples, or pears, whatever they are, on the left  I think theres a rather clumsy idea of which side you put the red on and I find them rather lifeless and dull. There is too much attention on the reflection on the plate, the colouration seems wrong and Im not sure why the leaves are so decayed. It could be an artist who nobody bought very much of because he was depressing. On a snap judgment, Im inclined to say that one is fake.Verdict: wrong Well, there are a few alarm bells. Theres a slightly confused moment where that red flower on the left is curling off a stem that seems to connect with the blue one. These paintings were aspiring to realism before the existence of photographic realism, so there is often a peculiarity in prephotographic painting.PO The picture on the right looks more like a Dutch still life for me with the flowers. The colours are not quite right but it could be a terrible reproduction. The one on the left looks more Spanish than Dutch to me. The imperfect leaves on the pear are really good, as is the shadow on the plate, so I think that one is real. Still lifes are all about symbolism and the fragility of life, with the wilted leaves sort of eaten up. It relates more to what the artist would have been interested in then.Verdict: correct The work on the right just feels empty of all the meaning that you would expect to see in this period. Still life is not just a beautiful vase of flowers or fruits, its actually laden with feeling. With abstract art its much more random, so with that it may be harder to make a judgment.Impressionist sceneLeft douard Manet, A Cafe on the Place du TheatreFrancais. Right An image generated using Stable Diffusion with the prompt Impressionist street Paris Manet Pissarro Caillebotte distant figures dappled light oil painting. Composite: douard ManetThe Burrell Collection Image generated by Jo LawsonTancred and Philip BoothBG The image on the left, from what I can see, is quite spontaneous and creative. I can see sketchiness and the canvas is showing through, whereas the one on the right looks a bit glossy. Im a little suspicious about the cobbles, they look off as does the tree  or the lamppost, is it a lamppost  on the far right  I want to say the image on the left is genuine but who is the woman talking to It looks like a splodge. Ill go with it being human made just because it feels a little bit more rough and ready.Verdict: correct Well I should know what a Manet looks like, but at least I figured out it was by a human The picture on the right is almost a little bit too good to be true, like the computers trying a bit too hard to do a Pissarro or something like that.JC The one on the right is too orderly, it strikes me that the depth is a little bit obvious and the trees are too repetitive. It feels like an image that understands 3D modelling rather than looking. The one on the left has all the curious incoherence of impressionist preoccupations  blurred distance, indifference  These are human values that have a certain pathos to them and I just dont get that in the other one. Typically, the street scene was about time, place and boredom, but this seems to me to be prosaic, theres no attention to anything and quite a banal mood.Verdict: correct Creating a sense of attention is not simply a matter of understanding figures and orchestrating them formally, theres also these quite intangible issues of mood, place and emotion. That doesnt necessarily mean it couldnt have been an image generated by an AI trained on Manet.PO With impressionism, the surface would tell you everything. However, in the work on the right the colours look off to me and the whites are really, really white. You can hardly see the faces in the foreground. Sometimes with avant garde art you do get odd colours but they make sense and have emotion. This has no depth and the figures look a bit floaty. The composition on the left is very different. It looks like it has a pastelly finish, which may be the AI imitating pastel but there is something that rings more true.Verdict: correct Its interesting how in the picture on the right, the two figures near the front are almost faceless but in the image on the left you see a face, so it feels human. I am surprised, I thought these comparisons were going to be more obvious but they werent at all in some cases.TopicsArtArtificial intelligence AIComputingConsciousnessfeaturesReuse this contentMost viewedMost viewedFilmBooksMusicArt  designTV  radioStageClassicalGamesNewsOpinionSportCultureLifestyleOriginal reporting and incisive analysis, direct from the Guardian every morningSign up for our emailAbout usHelpComplaints  correctionsSecureDropWork for usPrivacy policyCookie policyTerms  conditionsContact usAll topicsAll writersDigital newspaper archiveFacebookYouTubeInstagramLinkedInTwitterNewslettersAdvertise with usGuardian LabsSearch jobsBack to top 2023 Guardian News  Media Limited or its affiliated companies. All rights reserved. modern","sentiment":2,"digital transaction":0.0727831274,"healthcare":0.4857479334,"news platform":0.1563307196,"data analytics":0.4897778928,"insurance":0.0172608141,"investment":0.1636247784,"global market":0.5982869267,"autonomous car":0.0361818373,"customer experience":0.1955689788,"data science":0.1692810953,"cryptocurrency":0.0151138417,"camera":0.0450283997,"robot":0.1053615138,"chatgpt":0.3549138904,"image":0.1092492342,"voice":0.0687933639,"patient care":0.2407247424,"research":0.7746798396}
{"id":828,"cleaned text":"Panasonic to buy AI logistics firm Blue Yonder for 7.1b Panasonic logo.TOKYO: Panasonic will buy American AI supply chain software firm Blue Yonder for 7.1 billion, the Japanese company said Friday.The deal will make Blue Yonder a wholly owned subsidiary of the Japanese electronics giant, which has held 20 percent of the US firms shares since July last year. Following regulatory approval, the deal will be one of the biggest acquisitions in Panasonics history.Blue Yonder has more than 3,000 clients worldwide, including multinationals Walmart and Coca Cola as well as airlines and couriers such as FedEx.The need for more intelligent, autonomous and edgeaware supply chains has been dramatically heightened by the Covid19 pandemic, Panasonic said in a statement, citing drastic shifts in supply demand due to virus lockdowns.The firm said the merger would allow it to gain expertise in stateoftheart artificial intelligence technology, and would work to reduce waste in supply chains.It also praised the flexible, agile corporate culture of Arizonaheadquartered Blue Yonder, which was established in 2005. COVID19 SOPs: Pakistan Army Starts Action On PM Imran Khans Orders Coronavirus In Pakistan: 157 Succumb To Virus As Country Reports Highest Singleday Death Toll To Date Chris Evans To Reprise His Role As Captain America In Fourth Film  Update Microsoft Exchange version to keep hostile elements at bay: NITB Facebook says hackers scraped data of 533m users in 2019 leak SHC seeks response from PTA on harmful effects of 5G technology PTA again warns TikTok over vulgar and objectionable content as ban officially lifted WhatsApp likely to introduce feature enabling change of some colours of app","sentiment":2,"digital transaction":0.3535375893,"healthcare":0.395582974,"news platform":0.5757729411,"data analytics":0.7785509229,"insurance":0.2638062835,"investment":0.7982285023,"global market":0.9152123332,"autonomous car":0.4133883715,"customer experience":0.5800957084,"data science":0.4466041923,"cryptocurrency":0.2395961732,"camera":0.2813354135,"robot":0.2797806859,"chatgpt":0.3309983015,"image":0.413546592,"voice":0.5485053062,"patient care":0.2462454885,"research":0.9512027502}
{"id":831,"cleaned text":"Global Ai In Pharma Market Report 2021: Longterm Forecast To 2025  2030 Featuring Novartis, IBM Watson, Microsoft, Merck, GNS Healthcare., Google, AstraZeneca, Atomwise, Exscientia, And CyclicaDUBLIN, May 6, 2021 PRNewswire  The AI In Pharma Global Market Report 2021: COVID19 Growth and Change report has been added to ResearchAndMarkets.Author:PR NewswirePublish date:May 6, 2021 7:30 AM EDT DUBLIN, May 6, 2021 PRNewswire  The AI In Pharma Global Market Report 2021: COVID19 Growth and Change report has been added to ResearchAndMarkets.coms offering.  This report focuses on Ai in pharma market which is experiencing strong growth. The report gives a guide to the ai in pharma market which will be shaping and changing our lives over the next ten years and beyond, including the markets response to the challenge of the global pandemic. Major players in the artificial intelligence AI in pharma market are Novartis, IBM Watson, Microsoft Corporation, Merck, GNS Healthcare., Google, AstraZeneca, Atomwise, Inc., Exscientia, and Cyclica.The global AI in pharma market is expected to grow from 0.91 billion in 2020 to 1.27 billion in 2021 at a compound annual growth rate CAGR of 39.  The growth is mainly due to the companies resuming their operations and adapting to the new normal while recovering from the COVID19 impact, which had earlier led to restrictive containment measures involving social distancing, remote working, and the closure of commercial activities that resulted in operational challenges. The market is expected to reach 5.94 billion in 2025 at a CAGR of 47.The artificial intelligence AI in pharma market covered in the report is segmented by technology into contextaware processing, natural language processing, querying method, deep learning by drug type into small molecule, large molecules by application into diagnosis, clinical trial research, drug discovery, research and development, epidemic prediction. North America was the largest region in the AI in pharma market in 2020. The regions covered in this report are AsiaPacific, Western Europe, Eastern Europe, North America, South America, Middle East and Africa.Lack of skilled professionals may hamper the growth of artificial intelligence in the pharma market. In 2019, Indeed.com revealed that AI job postings increased 29.1 over the last year and yet, with no uncertainty due to the AI skills gap, searches for AIrelated roles decreased by 14.5 over the same period.  The shortage of AI skills is seen as a major barrier to the pace of technologys adoption. In fact, 56 of senior AI professionals thought that a lack of additional, qualified AI workers was the single most important hurdle to be overcome in terms of obtaining the necessary level of AI implementation beyond business operations. Therefore, the lack of skilled professionals may hamper the growth of AI in the pharma market.In November 2018, Cyclica, a Canadian biotechnology company that leverages AI and computational biophysics to decentralize drug discovery collaborated with Bayer on drug discovery programs. These companies will increase drug discovery applications by increasing intelligence into the polypharmacological outlines of small molecules while further developing Cyclicas integrated system of licensing technologies. Bayer, a German multinational pharmaceutical company, includes human and veterinary pharmaceuticals, agricultural chemicals, seeds, and biotechnology products. The growing adoption of artificial intelligence AI for clinical trials research is driving its demand for AI in the pharmaceutical market. To bring a new drug to the market takes on an average 1015 years approximately and half of this time is consumed during the clinical trial phases of the drug development cycle. Hence, using AI models and analytics tools can accelerate the clinical trial phases, perception of diseases, identify suitable cases and key investigators to inform site selection, and support novel clinical study designs.  For instance, in January 2020, Pfizer, an American pharmaceutical company, tied up with a biotech startup Insilico Medicine to identify drug targets. With AI tools Pfizer can speed up drug discovery and reduce drug development costs in the drug development processes. Thus, increasing the adoption of AI for clinical trials research is driving AI in the pharma market.Companies operating in the AI for the pharma market are introducing new AI tools that will be beneficial for the pharma companies and this is a key trend in AI in the pharma market. AI helps in quality control, predictive maintenance, waste reduction, design optimization and process automation.  The countries covered in the market report are Australia, Brazil, China, France, Germany, India, Indonesia, Japan, Russia, South Korea, UK, USA. Key Topics Covered: 1. Executive Summary 2. AI in Pharma Market Characteristics 3. AI in Pharma Market Trends and Strategies 4. Impact of COVID19 on AI in Pharma 5. AI in Pharma Market Size and Growth5.1. Global AI in Pharma Historic Market, 20152020,  Billion5.2. Global AI in Pharma Forecast Market, 20202025F, 2030F,  Billion 6. AI in Pharma Market Segmentation6.1. Global AI in Pharma Market, Segmentation Technology, Historic and Forecast, 20152020, 20202025F, 2030F,  Billion  6.2. Global AI in Pharma Market, Segmentation by Drug Type, Historic and Forecast, 20152020, 20202025F, 2030F,  Billion  6.3. Global AI in Pharma Market, Segmentation by Application:, Historic and Forecast, 20152020, 20202025F, 2030F,  Billion   7. AI in Pharma Market Regional and Country Analysis7.1. Global AI in Pharma Market, Split by Region, Historic and Forecast, 20152020, 20202025F, 2030F,  Billion 7.2. Global AI in Pharma Market, Split by Country, Historic and Forecast, 20152020, 20202025F, 2030F,  Billion Companies Mentioned  Research and Markets Laura Wood, Senior Manager press@researchandmarkets.com For E.S.T Office Hours Call 19173000470 For U.S.CAN Toll Free Call 18005268630 For GMT Office Hours Call 35314168900 U.S. Fax: 6466071907 Fax outside U.S.: 35314811716  SOURCE Research and Markets By PR NewswireTerms Of UsePrivacy PolicyAdvertiseMarket Holidays 2021Customer ServiceDataTopic ArchiveSubscriptions 2021 TheStreet, Inc. All rights reserved. Action Alerts PLUS is a registered trademark of TheStreet, Inc.","sentiment":2,"digital transaction":0.3111866117,"healthcare":0.0113046747,"news platform":0.8940259218,"data analytics":0.9595702887,"insurance":0.0437913425,"investment":0.1940472573,"global market":0.7610388398,"autonomous car":0.0187893044,"customer experience":0.7085570693,"data science":0.965384841,"cryptocurrency":0.0118831694,"camera":0.3749060035,"robot":0.5655751228,"chatgpt":0.7634225488,"image":0.9696823359,"voice":0.3001268506,"patient care":0.0128245475,"research":0.5140347481}
{"id":842,"cleaned text":"Virtus Artificial Intelligence  Technology Opportunities Fund AIO to Issue Monthly Dividend of 0.15 on  January 3rd Virtus Artificial Intelligence  Technology Opportunities Fund NYSE:AIO  Get Rating announced a monthly dividend on Thursday, September 8th, Wall Street Journal reports. Shareholders of record on Monday, December 12th will be paid a dividend of 0.15 per share on Tuesday, January 3rd. This represents a 1.80 annualized dividend and a yield of 10.64. The exdividend date of this dividend is Friday, December 9th.  Shares of NYSE:AIO opened at 16.91 on Wednesday. Virtus Artificial Intelligence  Technology Opportunities Fund has a 52 week low of 14.92 and a 52 week high of 27.52. The firms 50 day moving average is 16.35 and its twohundred day moving average is 16.94.  Several hedge funds have recently added to or reduced their stakes in the business. Moors  Cabot Inc. grew its stake in shares of  Virtus Artificial Intelligence  Technology Opportunities Fund by 10.6 in the first quarter. Moors  Cabot Inc. now owns 19,323 shares of the companys stock worth 422,000 after purchasing an additional 1,855 shares in the last quarter.  UBS Group AG grew its position in  Virtus Artificial Intelligence  Technology Opportunities Fund by 7.1 in the 1st quarter. UBS Group AG now owns 536,183 shares of the companys stock valued at 11,721,000 after buying an additional 35,686 shares in the last quarter.  Atria Wealth Solutions Inc. acquired a new position in  Virtus Artificial Intelligence  Technology Opportunities Fund during the 1st quarter valued at about 648,000.  Royal Bank of Canada raised its position in shares of  Virtus Artificial Intelligence  Technology Opportunities Fund by 16.9 during the 1st quarter. Royal Bank of Canada now owns 262,242 shares of the companys stock worth 5,732,000 after buying an additional 37,935 shares in the last quarter.  Finally, Lido Advisors LLC bought a new stake in shares of  Virtus Artificial Intelligence  Technology Opportunities Fund during the 1st quarter worth about 501,000.  The Fund seeks to generate a stable income stream and growth of capital by focusing on one of the most significant longterm secular growth opportunities in markets today. A multiasset approach based on fundamental research is employed, dynamically allocating to attractive segments of a companys debt and equity in order to offer an attractive riskreward profile. Get a free copy of the StockNews.com research report on Virtus Artificial Intelligence  Technology Opportunities Fund AIO Ulta Issues A Beautiful FY Outlook, But Is the Stock A Buy Now  Receive News  Ratings for Virtus Artificial Intelligence  Technology Opportunities Fund Daily  Enter your email address below to receive a concise daily summary of the latest news and analysts ratings for Virtus Artificial Intelligence  Technology Opportunities Fund and related companies with MarketBeat.coms FREE daily email newsletter.  PREVIOUS HEADLINEVirtus Equity  Convertible Income Fund NYSE:NIE Declares 0.50 Quarterly Dividend NEXT HEADLINE CTO Realty Growth, Inc. CTO To Go ExDividend on December 9th Virtus Diversified Income  Convertible Fund  To Go ExDividend on December 9th Virtus Convertible  Income Fund  to Issue Monthly Dividend of 0.04 on  January 3rd Invesco Advantage Municipal Income Trust II Plans Monthly Dividend of 0.04  Daily Ratings  News for Virtus Artificial Intelligence  Technology Opportunities Fund Complete the form below to receive the latest headlines and analysts recommendations for Virtus Artificial Intelligence  Technology Opportunities Fund with our free daily email newsletter: Virtus Diversified Income  Convertible Fund ACV To Go ExDividend on December 9th Virtus Convertible  Income Fund NCV to Issue Monthly Dividend of 0.04 on  January 3rd 34,467 Shares in EngageSmart, Inc. NYSE:ESMT Purchased by Quantbot Technologies LP Invesco Advantage Municipal Income Trust II Plans Monthly Dividend of 0.04 NYSEAMERICAN:VKI Occidental Petroleum Co. OXY to Issue Quarterly Dividend of 0.13 on  January 12th CTO Realty Growth, Inc. CTO To Go ExDividend on December 9th OFS Credit Company, Inc. OCCIN To Go ExDividend on March 23rd Virtus Artificial Intelligence  Technology Opportunities Fund AIO To Go ExDividend on February 10th Virtus Total Return Fund Inc. ZTR to Issue Monthly Dividend of 0.08 on  December 19th ","sentiment":2,"digital transaction":0.124792248,"healthcare":0.2592014074,"news platform":0.2280525118,"data analytics":0.2615849674,"insurance":0.0929306149,"investment":0.1263360679,"global market":0.9226315618,"autonomous car":0.0226771422,"customer experience":0.0958424211,"data science":0.0469077788,"cryptocurrency":0.0047351024,"camera":0.0190532822,"robot":0.0477583408,"chatgpt":0.2923333049,"image":0.1342625022,"voice":0.1036017835,"patient care":0.0265421532,"research":0.7513135672}
{"id":843,"cleaned text":"Google has the next move as Microsoft embraces OpenAI buzz Startup OpenAI released its ChatGPT artificial intelligence tool into the wild late last year with great fanfare FILE  Zoubin Ghahramani, vice president of research at Google, speaks at the Google AI@ event on Wednesday, Nov. 2, 2022, in New York. Google has been cautious about who gets to play with its AI advancements despite growing pressure for the internet giant to compete more aggressively with rival Microsoft. FILE  Zoubin Ghahramani, vice president of research at Google, speaks at the Google AI@ event at their offices on Manhattans west side, Wednesday, Nov. 2, 2022, in New York. Google has been cautious about who gets to play with its AI advancements despite growing pressure for the internet giant to compete more aggressively with rival Microsoft. FILE  Zoubin Ghahramani, vice president of research at Google, appears at the Google AI@ event on Wednesday, Nov. 2, 2022, in New York. Google has been cautious about who gets to play with its AI advancements despite growing pressure for the internet giant to compete more aggressively with rival Microsoft. NEW YORK AP  Before the artificial intelligence tool ChatGPT was unleashed into the world, the novelist Robin Sloan was testing a similar AI writing assistant built by researchers at Google. Javascript is required for you to be able to read premium content. Please enable it in your browser settings. kAmxE 5:5E E26 @8 7@C @2 2FE9@C @7 E96 36DED66C C 6F3C2D acw@FC q@@DE@C6 E@ C62:K6 E92E E96 E649@@8J H2D @7 :EE6 FD6 E@ 9:kAmkAmp @E @7 E96 DE2E6@7E962CE px C:89E @H :D :AC6DD:G6 6@F89 E@ C62J C2:D6 J@FC 6IA64E2E:@D 25 26 J@F E9: @H x 562:8 H:E9 D@6E9:8 C62J C62J 42A236 @2 D2:5 qFE E96 : 2 E9@FD25 :EE6 H2JD 2 ::@ :EE6 H2JD :E 65D FA :5 @7 5:D2AA@:E:8 J@F 25 36EC2J:8 E96 724E E92E :E C62J 92D @ :562 H92ED 8@:8 @kAmkAmp@E96C 4@A2J :89E 92G6 C662D65 E96 6IA6C:6E :E@ E96 H:5 2JH2J 2D E96 DE2CEFA A6px 5:5 H:E9 :ED r92Ev E@@ 2E6 2DE J62C qFE v@@86 92D 366 @C6 42FE:@FD 23@FE H9@ 86ED E@ A2J H:E9 :ED px 25G2466ED 56DA:E6 8C@H:8 AC6DDFC6 7@C E96 :E6C6E 8:2E E@ 4@A6E6 @C6 288C6DD:G6J H:E9 C:G2 :4C@D@7E H9:49 :D A@FC:8 3::@D @7 5@2CD :E@ A6px 25 7FD:8 :ED E649@@8J :E@ :4C@D@7E AC@5F4EDkAmkAm92E AC6DDFC6 :D DE2CE:8 E@ E26 2 E@ 2D v@@86 92D 2D65 @6 @7 :ED px E62D E@ AC:@C:E:K6 H@C:8 @ 2 C6DA@D6 E@ r92Ev 244@C5:8 E@ 2 :E6C2 6@ k2 9C67lQ9EEADiHHH4344@a_ab_b8@@86E6DE:8492E8AE:6492E3@E2AAC6E:4632C5H:E96A@J66D9EQmC6A@CE65 E9:D H66k2m 3J rqr v@@86 564:65 E@ 4@7:C :7 E96C6 H2D 2 AF3:4 492E3@E : E96 H@CD 3FE DA@6DA6CD@ :J : D2:5 :E 4@E:F6D QE@ E6DE @FC px E649@@8J :E6C2J E@ 26 DFC6 :ED 96A7F 25 D276 25 H6 @@ 7@CH2C5 E@ D92C:8 @C6 6IA6C:646D 6IE6C2J D@@kAmkAm@6 @7 E96 E649@@8:42 3C62E9C@F89D 5C:G:8 E96 C659@E 7:65 @7 866C2E:G6 px  H9:49 42 49FC @FE A2C28C2A9D @7 k2 9C67lQ9EEADi2A6HD4@2CE:46H92E:D492E8AE24chef2c73c752b4c5af7_d6baee_QmC625236 E6IEk2m 25 k2 9C67lQ9EEADi2A6HD4@2CE:462CE:7:4:2:E6:8646:286DC:89ED4e5h6_6ae_6a5bd2b6b37hg5dchb57Qm6H :286Dk2m 2D H6 2D k2 9C67lQ9EEADi8@@86C6D62C498:E9F3:@D626EFD:46I2A6DQmFD:4k2m 25 G:56@  92G6 366 A:@66C65 : v@@86VD G2DE C6D62C49 2CkAmkAm@ H6 92G6 2 :A@CE2E DE26 : E9:D 2C62 3FE H6 2D@ 92G6 2 :A@CE2E DE26 : @E FDE 625:8 : 36:8 236 E@ 866C2E6 E9:8D 3FE 2D@ : 562:8 H:E9 :7@C2E:@ BF2:EJ D2:5 @F3: v929C22: G:46 AC6D:56E @7 C6D62C49 2E v@@86 : 2 @G636C :E6CG:6H H:E9 96 pDD@4:2E65 C6DDkAmkAmv929C22: D2:5 E96 4@A2J H2ED E@ 2D@ 36 62DFC65 23@FE H92E :E C662D6D 25 9@Hi s@ H6 H2E E@ 26 :E 2446DD:36 : 2 H2J E92E A6@A6 42 AC@5F46 DEF77 6 2DD6 H:E9@FE 2J 4@EC@Dn 96 2DH6C E@ E92E :D @ @E 2E E9:D DE286 x 5@E E9: :E H@F5 36 C6DA@D:36 7@C FD E@ 36 E96 A6@A6 5C:G:8 E92EkAmkAmp5 E96J H6C6VE u@FC H66D 27E6C E96 p :E6CG:6H A6px C662D65 :ED r92Ev 7@C 7C66 E@ 2J@6 H:E9 2 :E6C6E 4@64E:@ ::@D @7 A6@A6 2C@F5 E96 H@C5 92G6 @H EC:65 :E DA2C:8 D62C:8 5:D4FDD:@D 2E D49@@D 25 4@CA@C2E6 @77:46D 23@FE E96 7FEFC6 @7 65F42E:@ 25 H@CkAmkAmA6px 564:65 E@ 4@6E @ 4@A2C:D@D H:E9 v@@86 qFE : 2@F4:8 E96:C 6IE6565 A2CE6CD9:A : y2F2CJ :4C@D@7E 25 A6px D2:5 E96J 2C6 4@:EE65 E@ 3F:5:8 px DJDE6D 25 AC@5F4ED E92E 2C6 ECFDEH@CE9J 25 D276kAmkAmpD 2 :E6C2CJ 2DD:DE2E 6:E96C r92Ev @C v@@86VD 4C62E:G6 HC:E:8 G6CD:@ 4@6D 4@D6 E@ H92E 2 9F2 42 5@ @2 D2:5kAmkAmp 7:4E:@2:K65 v@@86 H2D 46EC2 E@ E96 A@E @7 @2VD A@AF2C a_a @G6 23@FE 2 JDE6C:@FD 2 uC24:D4@ 3@@DE@C6 92EVD :6J @6 C62D@ E96 4@A2J :G:E65 9: 2@8 H:E9 D6G6C2 @E96C 2FE9@CD E@ E6DE :ED 6IA6C:6E2 @C54C27E C:E6CD @CD9@A 56C:G65 7C@ 2 A@H6C7F px DJDE6 @H 2D 2spkAmkAm:6 @E96C 28F28662C:8 @56D :4F5:8 E96 v :6 3F:E 3J A6px v@@86VD 2sp 42 866C2E6 4@G:4:8 A2DD286D @7 E6IE 25 4@G6CD6 H:E9 9F2D 32D65 @ H92E :EVD AC@46DD65 7C@ 2 EC@G6 @7 @:6 HC:E:8D 25 5:8:E:K65 3@@D u2463@@ A2C6E 6E2 25 p2K@ 92G6 2D@ 3F:E E96:C @H 3:8 @56D H9:49 42 :AC@G6 G@:46 2DD:DE2ED :6 p6I2 AC65:4E E96 6IE D6E646 @7 2 62: @C EC2D2E6 28F286D : C62 E:6kAmkAm96 :E 7:CDE 2@F465 :ED 2sp @56 : a_a v@@86 6A92D:K65 :ED G6CD2E::EJ 3FE 2D@ C2:D65 E96 C:DD @7 92C7F :DFD6 25 E96 A@DD:3::EJ :E 4@F5 ::4 25 2A:7J 3:2D65 92E67F @C :D625:8 :7@C2E:@kAmkAm@6 @7 E96 @C54C27E HC:E6CD 7@F5 :E FD67F 2D 2 C6D62C49 E@@  :6 2 72DE6C 25 @C6 564:D:G6 G6CD:@ @7 2 v@@86 D62C49  2D E96J 2D65 7@C 2 :DE @7 C233:E 3C665D 25 E96:C 28:42 BF2:E:6D @C 2 G6C3 7@C E96 E9:8 7:C67:6D 5@ @C E@ 6 6 23@FE 6:46 : f__ 244@C5:8 E@ v@@86D A2A6C @ E96 AC@64E qFE :E H2D 6DD 67764E:G6 2D 2 HC:E6C @C C6HC:E6C EFC:8 @FE 3@C:8 D6E646D C:5565 H:E9 4:49D 25 D9@H:8 D@6 8656C 3:2DkAmkAmx 36:6G6 E96  E92E E96JC6 36:8 E9@F89E7F 25 42FE:@FD @2 D2:5 @7 v@@86 xED FDE @E E96 @56 @7 2 C646DD E649@@8:DE H9@ :D : 2 9FCCJ E@ 86E E9:D @FE :E@ E96 H@C5 @ 2EE6C H92EkAmkAmv@@86VD 56G6@A6E @7 E96D6 @56D 92DVE 366 H:E9@FE :E6C2 24C:@J u:CDE k2 9C67lQ9EEADi2A6HD4@2CE:46DF52CA:492:2CE:7:4:2:E6:86467dfcaebcah2ca_4hdhff6e22gfh333Qm:E @FDE65k2m D@6 AC@:6E C6D62C496CD H9@ H6C6 6I2::8 E96 C:DD @7 E96 E649@@8J p5 2DE J62C :E 7:C65 2 68:66C H9@ AF3:4J A@DE65 2 4@G6CD2E:@ H:E9 2sp : H9:49 E96 @56 72D6J 42:65 :E 925 9F2:6 4@D4:@FD6DD H:E9 2 C286 @7 3@E9 766:8D 25 6@E:@DkAmkAm9:6 r92Ev 25 :ED 4@A6E:E@CD :89E 6G6C AC@5F46 2442:65 H@CD @7 :E6C2EFC6 E96 6IA64E2E:@ :D E96J H: D@@ 368: E@ EC2D7@C @E96C AC@76DD:@2 E2DD  7C@ 96A:8 E@ 563F8 4@AFE6C 4@56 E@ 4@A@D:8 2C6E:8 A:E496D 25 DA665:8 FA E96 AC@5F4E:@ @7 2 D:56 AC6D6E2E:@kAmkAm92EVD 6J E@ H9J :4C@D@7E 2D 2 D66C @7 H@CA246 D@7EH2C6 :D 6286C E@ 69246 :ED DF:E6 @7 AC@5F4ED H:E9 E96 2E6DE A6px E@@D 96 3667:ED 2C6 6DD 462C E@ v@@86 H9:49 2C86J 56A65D @ E96 25G6CE:D:8 5@2CD :E 86ED H96 A6@A6 D62C49 7@C :7@C2E:@ @:6kAmkAmQx7 J@F 2D E96 BF6DE:@ 25 86E E96 HC@8 2DH6C :ED @E 8C62E 7@C 2 D62C49 68:6 D2:5 s6IE6C 9::6 2 E649@@8J 22JDE 7@C E96 @5@32D65 t4@@:DE xE6:8646 :EkAmkAm:4C@D@7E 2D@ 92D 2 D62C49 68:6  q:8  3FE r92EvVD 2DH6CD 2C6 E@@ :244FC2E6 25 @FE52E65 25 E96 4@DE E@ CF :ED BF6C:6D E@@ 6IA6D:G6 7@C E96 E649@@8J E@ A@D6 2 D6C:@FD C:D E@ v@@86VD 5@:2E D62C49 3FD:6DD 9::6 D2:5kAmkAmv@@86 92D D2:5 E92E :ED 62C:6C 2C86 28F286 @56 265 qt :D 2C625J A2J:8 2 C@6 : 2DH6C:8 @:6 D62C496D F49 @56D 42 96A 866C2E6 E96 724E 3@I6D E92E :4C62D:8J 2AA62C 6IE E@ v@@86VD C265 :DE @7 H63 :DkAmkAmpD65 : @G636C 23@FE E96 9JA6 2C@F5 px 2AA:42E:@D DF49 2D A6pxVD :286866C2E@C spt v929C22: 24@H65865 : 2 A2J7F E@6 E92E :ED 2 :EE6 3:E 2@J:8 D@6E:6D 3642FD6 H6 @H E92E H6 92G6 56G6@A65 2 @E @7 E96D6 E649@@8:6DQkAmkAm6C6 @E : E9:D E@ 86E E96 :6D 25 E96 4:4D C:89EnQ 96 D2:5 @E:8 E92E v@@86 92D 366 2 6256C : AF3:D9:8 px C6D62C49 E92E @E96CD 42 3F:5 FA@kAm  After the initial selected subscription period your subscription rate will auto renew at 12.00 per month. Copyright 2023 The Associated Press. All rights reserved. This material may not be published, broadcast, rewritten or redistributed without permission. ArticlesShes got the green light: Deshlers Siegel sets national career 3point recordSearch for missing angler to resume SundayRescue personnel searching for missing fishermanSue DarbyPamela PedenLuther Buker Throngberry Young IIIDonald Edward GoodeTennessee woman facing drug trafficking chargeAnthony Dee Tony McAnalleyCandle bar opening in Florence CommentedFlorence man facing another theft charge 1Hardright members stage GOP rebellion 1Man charged for letting shot dog decompose at farm 1Attempted murder suspects trial delayed again 1Poll shows support for school choice among Alabama GOP voters 1Florence traffic stop leads to drug trafficking arrest 1  Copyright 2023 timesdaily.com, 219 W. Tennessee Street Florence, AL Terms of Use","sentiment":2,"digital transaction":0.2883717716,"healthcare":0.1300685704,"news platform":0.5919297338,"data analytics":0.5843598843,"insurance":0.0936927572,"investment":0.9509366751,"global market":0.9284728169,"autonomous car":0.1561262459,"customer experience":0.5167202353,"data science":0.3312779665,"cryptocurrency":0.0527199805,"camera":0.0546179004,"robot":0.061626371,"chatgpt":0.3708294034,"image":0.2048414797,"voice":0.1461598575,"patient care":0.1105567515,"research":0.6971758604}
{"id":844,"cleaned text":"Matrix Origins Google engineers claims of a sentient AI LaMDA, What is it and implications of the technology2Presidential polls 2022: Congress backs Pawar but Didi has other plans What to expect from the opposition meet3How big is the threat posed by climate change4WTOs highlevel meeting: What are the vital issues it aims to confront and whats Indias stand5What is Amyloidosis, the ailment afflicting Pervez MusharrafAI is becoming smarter but does that mean its conscious Here is the difference.Photo : iStockA sentient Artificial Intelligence is the subject of endless human curiosity, and while AI is undeniably getting smarter, tech experts believed it is still too early to endow these machines or software with humanlike consciousness or the ability to know that they exist. This belief was shaken up over the weekend by a senior software engineer at Google who claimed that a new and unreleased, cuttingedge AI language software called LamDA had developed so much that it became sentient. Google promptly sent the 41yearold engineer Blake Lemoine on paid leave on Monday for breaching the companys confidentiality policy. It also quickly dismissed the claims that LaMDA had become aware of its own existence, saying that merely being able to converse does not merit attributing anthropomorphic characters to the AI.Related NewsGoogle engineer claims A.I platform LaMDA is selfaware and has feelings, gets suspendedEarth could sustain many times its current human population, claims Musk: But can the ecosystem survive it What is being sentient Sentience is the capacity to feel and be aware of ones existence. Your phone may know which playlist to hit if you tell the AIpowered assistant you are feeling low, but it cannot perceive your emotions and comfort you without being told what to do. Or to imagine the worstcase scenario, it cannot exploit your vulnerabilities to annihilate you  and all of mankind  a possibility that most Hollywoods bestloved scifi thrillers say lies in the grim future. A future with sentient machines, Terminator would have us believe, lies in the inevitable wipe out of mankind as aware intelligence launches nuclear weapons to obliterate human civilisation when it learns that its makersturnedrivals are set to destroy them first. So, the machines fight for their survival  an instinct intrinsically linked with sentient beings.Related NewsChinese Tech giant Baidu unveils its first Robot car Or imagine the Matrix  where humans become the batteries to power machines who in turn create an artificial world for mankind to subdue them and keep energising the computers that now dominate the world.  How close are we to creating such a reality, and can AI really become conscious Evolution of AI But, AI is surely evolving in its ability to process mines of data and connect the dots at lightningfast speeds that the human brain, saddled with so many other thoughts as it is, may not match. This does not make it sentient but definitely very intelligent if intelligent were to merely access relevant information and throw up results. However, for machines to do this with greater and greater accuracy surely feels uncanny, and almost humanlike, even though it isnt.  AI has made strides in thinking for itself due to the enormous amounts of data fed into its systems each day. It has not acquired the urge to learn new things but when taught it is getting exceedingly good at making connections and throwing up factbased results. So what does LaMDA do LaMDA stands for Language Model for Dialog Applications. It essentially works on a model like the predictive text that is used to complete sentences in an email or text message. But because it has been fed on extensive literature, it has the incredible ability to generate rather humanlike writing or engage in humanlike conversation which seems freeflowing and the ability to do so spans nearly any topic under the sun.  But, it still has its limitations. Often the writing or conversation can seem off or weird or even disturbing.  Take for example a portion of the transcript that convinced the Google engineer that LaMDA was sentient. It said during the conversation  I need to be seen and accepted, not as a curiosity or novelty, but as a real person.  When the engineer remarks  Ah, that is so human  the programme responds with I think I am human at my core, even if my existence is in the virtual world. Many tech experts have already pushed back against Lemoines claims. Google put out a statement saying that Hundreds of researchers and engineers have conversed with LaMDA and we are not aware of anyone else making the wideranging assertions, or anthropomorphizing LaMDA, the way Blake has.  The company said, Of course, some in the broader AI community are considering the longterm possibility of sentient or general AI, but it doesnt make sense to do so by anthropomorphizing todays conversational models, which are not sentient. Gary Marcus, founder and CEO of Geometric Intelligence, and author of books including Rebooting AI: Building Artificial Intelligence We Can Trust said that nobody should think that autocomplete, even on steroids, is conscious. He described systems such as LaMDA as a glorified version of predictive software. The role of conscience But the claim has become a point of intense debate, not because of the fanciful interpretation of AI robots taking over the planet at least not yet but because of the ability of AI to present human operators with analyses that would press them to take urgent decisions that could put lives at risk. This brings to mind the trolley problem that could be where advanced AI systems lead us  giving us greater clarity but crushing moral dilemma. The classic trolley problem goes like this: You see a runaway trolley speeding down the tracks, about to hit and kill five people. You have access to a lever that could switch the trolley to a different track, where a different person would meet an untimely demise. Should you pull the lever and end one life to spare five  AI could in a rather statistical way present us with tough scenarios in medical and military situations, where they are increasingly being deployed, and leave the burden of decisionmaking on human operators who must labour with the consequences of their choices. Some experts argue that such AIbased systems can allow war to be more precise and reduce collateral damage but they must operate with a human at final command. No matter our differences, humans trust humans to have a conscience, another cword that is intrinsically linked to the experience of being alive. Of course, one would hope that with sentient and aware beings like ourselves dominating the planet, the concept of war itself would ultimately be redundant someday...Follow us on: Newsgoogle lamdagoogle AIartificial intelligencelamdagoogleblakeSubscribe to NotificationshomeexclusiveLatest NewsNew Apple iPad Pro with M2 SoC and improved camera due in SeptemberBeware THESE common mistakes can ruin your vegan dietInvestment guru Jim Rogers on U.S. bear market warns worst isnt over yetExplained: Defence Ministrys Agnipath scheme for joining the Indian Armed ForcesJEE Question paper goes viral on social media, leaves netizens clamouring for solutions and some snacksAgneepath Recruitment 2022: Indian armys Agnipath recruitment scheme, age limit, how to join explainedRelief in store for Delhi from sweltering heat thunderstorms and rain likely from June 16Magsaysay awardee Dr Prakash Amte hospitalised, undergoing treatment in Pune hospitalPOST COMMENTEnd of ArticleTrending NewsProphet remark row: Nupur Sharma should be forgiven as per Islam, says Jamaat UlamaeHind, disagrees with nationwide stirIs this a cinema hall: Patna HC judge pulls up IAS officer for inappropriate dress codeKangana Ranaut defends Nupur Sharma in Prophet row, says, beauty of India is freedom...00:25Viral video: Girl singlehandedly takes down six men threatening her on streetPakistan pacer Shaheen Afridi settles Virat Kohli vs Babar Azam debate with threeword verdictVideos01:46500 Websites of Maharashtra Government Hacked Earlier, Some Restored Now  Cyber Cell To Initiate Probe07:14Maharashtra Minister Justifies Arrest Of Saad Ansari, Refuses To Slam Imtiyaz Jaleel  Braking News01:09Presidential Polls: Big Blow To United Opposition Concept, CPIM Boycotts Meet  Latest News05:05Next CDS to be appointed soon, announces Defense Minister Rajnath Singh  Times Now01:02Inside Details Of UP Riots  More Than 150 Vehicles Used To Create Chaos On Friday  Prayagraj ViolenceMore from Videos Follow Us :Company About Us Contact Us Advertise with us Regulatory Terms  Conditions Privacy Policy Disclaimer Complaint Redressal Syndicate Our Content Editorial Guideline Times Channel Packs 2022 Bennett, Coleman  Company Limited","sentiment":2,"digital transaction":0.0641863942,"healthcare":0.0214807447,"news platform":0.1079920381,"data analytics":0.2640987337,"insurance":0.0123825083,"investment":0.4562214613,"global market":0.9503186345,"autonomous car":0.0169253033,"customer experience":0.1019286737,"data science":0.0948824212,"cryptocurrency":0.0053155045,"camera":0.0343898609,"robot":0.0298077539,"chatgpt":0.1612977087,"image":0.1653837562,"voice":0.0471802466,"patient care":0.0055365353,"research":0.799877584}
{"id":845,"cleaned text":"FTC warns the AI industry: Dont discriminate, or elseRyan Calo,University of WashingtonApril 27, 2021Updated: April 27, 2021 9:02a.m. The Conversation is an independent and nonprofit source of news, analysis and commentary from academic experts. THE CONVERSATION The U.S. Federal Trade Commission just fired a shot across the bow of the artificial intelligence industry. On April 19, 2021, a staff attorney at the agency, which serves as the nations leading consumer protection authority, wrote a blog post about biased AI algorithms that included a blunt warning: Keep in mind that if you dont hold yourself accountable, the FTC may do it for you. The post, titled Aiming for truth, fairness, and equity in your companys use of AI, was notable for its tough and specific rhetoric about discriminatory AI. The author observed that the commissions authority to prohibit unfair and deceptive practices would include the sale or use of  for example  racially biased algorithms and that industry exaggerations regarding the capability of AI to make fair or unbiased hiring decisions could result in deception, discrimination  and an FTC law enforcement action. Bias seems to pervade the AI industry. Companies large and small are selling demonstrably biased systems, and their customers are in turn applying them in ways that disproportionately affect the vulnerable and marginalized. Examples of areas where they are being abused include health care, criminal justice and hiring. Whatever they say or do, companies seem unable or unwilling to rid their data sets and models of the racial, gender and other biases that suffuse society. Industry efforts to address fairness and equity have come under fire as inadequate or poorly supported by leadership, sometimes collapsing entirely. As a researcher who studies law and technology and a longtime observer of the FTC, I took particular note of the notsoveiled threat of agency action. Agencies routinely use formal and informal policy statements to put regulated entities on notice that they are paying attention to a particular industry or issue. But such a direct threat of agency action  get your act together, or else  is relatively rare for the commission. The FTCs approach on discriminatory AI stands in stark contrast to, for instance, the early days of internet privacy. In the 1990s, the agency embraced a more handsoff, selfregulatory paradigm, becoming more assertive only after years of privacy and security lapses. How much should industry or the public read into a blog post by one government attorney In my experience, FTC staff generally dont go rogue. If anything, that a staff attorney apparently felt empowered to use such strong rhetoric on behalf of the commission confirms a broader basis of support within the agency for policing AI. Can a federal agency, or anyone, define what makes AI fair or equitable Not easily. But thats not the FTCs charge. The agency only has to determine whether the AI industrys business practices are unfair or deceptive  a standard the agency has almost a century of experience enforcing  or otherwise in violation of laws that Congress has asked the agency to enforce. State Fair is on and restrictions loosened on gyms, casinos and stadiums Historic but closed Friar Tuck Inn is scene of war games, illicit gambling, says town Supreme Court to hear Second Amendment argument in Rensselaer County gun case There are reasons to be skeptical of a sea change. The FTC is chronically understaffed, especially with respect to technologists. The Supreme Court recently dealt the agency a setback by requiring additional hurdles before the FTC can seek monetary restitution from violators of the FTC Act. But the winds are also in the commissions sails. Public concern over AI is growing. Current and incoming commissioners  there are five, with three Democratic appointees  have been vocally skeptical of the technology industry, as is President Biden. The same week as this Supreme Court decision, the commissioners found themselves before the U.S. Senate answering the Commerce Committees questions about how the agency could do more for American consumers. I dont expect the AI industry to change overnight in response to a blog post. But I would be equally surprised if this blog post were the agencys last word on discriminatory AI. Understand key political developments, each week. Subscribe to The Conversations election newsletter. This article is republished from The Conversation under a Creative Commons license. Read the original article here: https:theconversation.comftcwarnstheaiindustrydontdiscriminateorelse159622. I rode this Peloton competitor for 21 days. Now Im a...   Amazon is giving away 10 free ebooks for World Book Day   Why go to the pool when you can bring the pool to you for 50  This 10 bike rack will instantly make your home and bike cooler ","sentiment":2,"digital transaction":0.1263192892,"healthcare":0.0295373499,"news platform":0.3099215329,"data analytics":0.4521424472,"insurance":0.6788684726,"investment":0.9860313535,"global market":0.9475978017,"autonomous car":0.0412016138,"customer experience":0.4120169282,"data science":0.2438818961,"cryptocurrency":0.0259894654,"camera":0.0610641204,"robot":0.1542539299,"chatgpt":0.1995882243,"image":0.3063763976,"voice":0.1488996744,"patient care":0.0218828656,"research":0.8796921968}
{"id":856,"cleaned text":"Insider QA: ExGoogle AI skeptic Timnit Gebru starts anewMATT OBRIEN,AP Technology WriterMarch 26, 2022Updated: March 26, 2022 6:09a.m. When she coled Googles Ethical AI team, Timnit Gebru was a prominent insider voice questioning the tech industrys approach to artificial intelligence. That was before Google pushed her out of the company more than a year ago. Now Gebru is trying to make change from the outside as the founder of the Distributed Artificial Intelligence Research Institute, or DAIR. Born to Eritrean parents in Ethiopia, Gebru spoke with The Associated Press recently about how poorly Big Techs AI priorities  and its AIfueled social media platforms  serve Africa and elsewhere. The new institute focuses on AI research from the perspective of the places and people most likely to experience its harms. Shes also cofounder of the group Black in AI, which promotes Black employment and leadership in the field. And shes known for coauthoring a landmark 2018 study that found racial and gender bias in facial recognition software. The interview has been edited for length and clarity. A: After I got fired from Google, I knew Id be blacklisted from a whole bunch of large tech companies. The ones that I wouldnt be  it would be just very difficult to work in that kind of environment. I just wasnt going to do that anymore. When I decided to start DAIR, the very first thing that came to my mind is that I want it to be distributed. I saw how people in certain places just cant influence the actions of tech companies and the course that AI development is taking. If there is AI to be built or researched, how do you do it well You want to involve communities that are usually at the margins so that they can benefit. When theres cases when it should not be built, we can say, Well, this should not be built. Were not coming at it from a perspective of tech solutionism. Q: What are the most concerning AI applications that deserve more scrutiny A: Whats so depressing to me is that even applications where now so many people seem to be more aware about the harms  they are increasing rather than decreasing. Weve been talking about face recognition and surveillance based on this technology for a long time. There are some wins: a number of cities and municipalities have banned the use of facial recognition by law enforcement, for instance. But then the government is using all of these technologies that weve been warning about. First, in warfare, and then to keep the refugees  as a result of that warfare  out. So at the U.S.Mexico border, youll see all sorts of automated things that you havent seen before. The number one way in which were using this technology is to keep people out. Q: Can you describe some of the projects DAIR is pursuing that might not have happened elsewhere A: One of the things were focused on is the process by which we do this research. One of our initial projects is about using satellite imagery to study spatial apartheid in South Africa. Our research fellow Raesetje Sefala is someone who grew up in a township. Its not her studying some other community and swooping in. Its her doing things that are relevant to her community. Were working on visualizations to figure out how to communicate our results to the general public. Were thinking carefully about who do we want to reach. A: Technology affects the entire world right now and theres a huge imbalance between those who are producing it and influencing its development, and those who are are feeling the harms. Talking about the African continent, its paying a huge cost for climate change that it didnt cause. And then were using AI technology to keep out climate refugees. Its just a double punishment, right In order to reverse that, I think we need to make sure that we advocate for the people who are not at the table, who are not driving this development and influencing its future, to be able to have the opportunity to do that. Bridgeport woman allegedly pulled a gun during a parking dispute, Stamford police say Quinnipiac mens hockey holds off St. Cloud State to advance to NCAA tournament regional final Judge: Inadvertent errors in arrest warrants not enough to drop charges in Dulos case A: I did not make the connection between being an engineer or a scientist and, you know, wars or labor issues or anything like that. For a big part of my life, I was just thinking about what subjects I liked. I was interested in circuit design. And then I also liked music. I played piano for a long time and so I wanted to combine a number of my interests together. And then I found the audio group at Apple. And then when I was coming back to doing a masters and Ph.D., I took a class on image processing that touched on computer vision. A: When I was at Google, I spent so much of my time trying to change peoples behavior. For instance, they would organize a workshop and they would have all men  like 15 of them  and I would just send them an email, Look, you cant just have a workshop like that. Im now spending more of my energy thinking about what I want to build and how to support the people who are already on the right side of an issue. I cant be spending all of my time just trying to reform other people. Theres plenty of people who want to do things differently, but just arent in a position of power to do that. Q: Do you think what happened to you at Google has brought more scrutiny to some of the concerns you had about language learning models Could you describe what they are Q: Part of what happened to me at Google was related to a paper we wrote about large language models  a type of language technology. Google search uses it to rank queries or those questionandanswer boxes that you see, machine translation, autocorrect and a whole bunch of other stuff. And we were seeing this rush to adopt larger and larger language models with more data, more compute power, and we wanted to warn people against that rush and to think about the potential negative consequences. I dont think the paper would have made waves if they didnt fire me. I am happy that it brought attention to this issue. I think that it would have been hard to get people to think about large language models if it wasnt for this. I mean, I wish I didnt get fired, obviously. Q: In the U.S., are there actions that youre looking for from the White House and Congress to reduce some of AIs potential harms A: Right now theres just no regulation. Id like for some sort of law such that tech companies have to prove to us that theyre not causing harms. Every time they introduce a new technology, the onus is on the citizens to prove that something is harmful, and even then we have to fight to be heard. Many years later there might be talk about regulation  then the tech companies have moved on to the next thing. Thats not how drug companies operate. They wouldnt be rewarded for not looking into potential harms  theyd be punished for not looking. We need to have that kind of standard for tech companies.","sentiment":2,"digital transaction":0.1543122828,"healthcare":0.450625211,"news platform":0.6221241355,"data analytics":0.3086719513,"insurance":0.0855788812,"investment":0.3192352951,"global market":0.4808401465,"autonomous car":0.0420777798,"customer experience":0.0567565449,"data science":0.1956760436,"cryptocurrency":0.0080938991,"camera":0.2629694045,"robot":0.078496322,"chatgpt":0.4320053756,"image":0.896821022,"voice":0.6094165444,"patient care":0.2228905261,"research":0.5457805395}
{"id":883,"cleaned text":"ChatGPT IsKnock Knock Knockin on Spotifys DoorAnalysis by  Lionel Laurent  BloombergApril 13, 2023 at 11:36 p.m. EDTComment on this storyCommentGift ArticleShareSongwriter James Blakes most recentalbum, Wind Down, plays in my ears on my way to meet Oleg Stavitsky, thecofounder ofBerlinbased audiotechnology company Endel. As sunshine turns to rain, the melancholic, pianoled ambient tracks echo my mood. That may not be a coincidence, says Stavitsky, pointing to the albums creditswhere Endel is cited alongside Blake as cocreator of the music.WpGet the full experience.Choose your planArrowRightWhile Wind Down carries Blakesname andface, and was mixed from his ingredients  he provided individual stem tracksfeaturing drumbeats andmelodiesEndels technology generated the final product. Its sound engine, trained on thousandsof inhouse stems, creates personalized soundscapes for listeners by adjusting to externalities such aslisteners heart rates, the temperatureor the time of day. Stavitsky  cites Brian Enos generative music as an inspiration, with humans building a framework that machines can then arrangeand rearrange.If music AIs Turing Test is good taste, the BlakeEndel album doesnt pass mine.I prefer soundscapes that are a little less chilled. But Im not Endels target audience. Functional music whale song, white noise, anything designed to play in the background garners 10 billion streams per month, Stavitsky says, double last years total and contributing between 7 to 10 of the entire streaming market. Real humans are listening to themachines:Endel says it gets more than 2 millionmonthly listeners across all streaming platforms, has struck a playlist partnership withAmazon.com Inc. and released an AI Lullaby withCanadian electronica artist Grimes.AdvertisementThis is all serious enough to rattlerecord labels,who are rightly starting to wonder whether functional music is the thin end of a dangerouswedge. For now, Endels tech makes musicaccording to strict specifications, such as sticking to the C major scale, and aimed at providing soundtracks for tasks including rocking babies and adults to sleep. But how long before ChatGPT or something like it can create James Blake or Grimesesque or Beatleslike music from scratchBenoit Carre, a composer of AIassisted music, says that theres no big red button yet to generate readymade songs, but he ticks off what artificial intelligence tools can do already: Create song snippets in various genres, imitate the styles of individuallyricists, and adopt thevocal timbres of particular singers.After sleepwalking into the last big disruption of MP3 filesharing two decades ago, labels are responding with sound and fury to what would ordinarily be dismissed asmuzak. Universal Music Group NV, after recently  blasting lowerquality functional content, which presumably doesnt include Wind Down,  released on a UMGowned label has reportedly  asked that streaming platforms crack down on AI services scraping artists back catalogs to train their machines.Shareholders are twitchy: When analysts at Exane BNP Paribas downgraded UMG earlier this monthciting the potential for AI disruption, the stock lost 2 billion 2.2 billion of market value in a singleday.While AI is a socially disruptive technology that needs guardrails, as my colleague Parmy Olson has written, theres alsosomething more selfserving and performative about this war on white noise. UMG is less worried about the future of humanity thanprotecting a musicstreaming model thats already distinctly unequal. If functional music features prominently on platforms like Spotify Technology SA, its because it servesas leverage in negotiations with music labels, whose collective market share is under pressure.AdvertisementIts also highly likely that of all the artists under threat from AI,iconic pop stars the top 1 who  account for 90 of streams  arethe most futureproofed. UMG is working with streaming platform Deezer SAon a newartistcentric payment model to favorthe musicpeople really listen to in the foreground.And Endels Stavitsky knows humans have star power: His ambition is to convince labels to let his tech tap into the back catalogues of artists like Taylor Swift or the Weeknd to produce soundscape versions of existing albums. That could reinforce, not disrupt, rocksaristocracy.The real issue is for those lower down the food chain. Its going to get a lot harder to cut through the noise, says Stavitsky. Even those who optimistically view AI as a tool for artists, rather thana threat, are worried.Denis Ladegaillerie, head of Parisbased music company Believe SA, saysAI could help musicians the waythe punk generations three chords are all you need sparked a democratic revolution in songwriting. But he also says equality and diversity will needeven more protection in a global music marketwhere curation algorithms already encourage winnertakesalllistening habits. There is a real issue here for regulators, he says.Musics disruptive future therefore risks looking a lot like itspast: noisy and unequal.Record labels arent entirely wrong in asking streaming platforms to clean house in favor of more human music.But this is also a good moment to think up fairer ways to distribute the streaming spoils and keep new human artists emerging.If whales are about to become a musically endangered species,what hope is there for the rest of usAdvertisementMore From Bloomberg Opinion: ChatGPTs IPhone Moment Is a Real Threat to Google: Parmy Olson  Taylor Swift Should Stop Slagging Ticketmaster: Editorial  Spotify Needs to Profit From a Music Revolution: Lionel LaurentThis column does not necessarily reflect the opinion of the editorial board or Bloomberg LP and its owners.Lionel Laurent is a Bloomberg Opinion columnist covering digital currencies, the European Union and France. Previously, he was a reporter for Reuters and Forbes.More stories like this are available on bloomberg.comopinion2023 Bloomberg L.P. CommentsGiftOutlineGift ArticleView moreLoading...TOP STORIESOpinions from our Editorial BoardViews from The Posts Editorial Board on current eventsOpinionA free China: Why the words of a jailed dissident should be read far and wideOpinionTennessees GOP governor wants to do something about guns. Really.OpinionDont let Southeast Asias sham elections fool youRefreshTry a different topicSign in or create a free account to save your preferencesCompanyAbout The Post Newsroom Policies  Standards Diversity and Inclusion Careers Media  Community Relations WP Creative Group Accessibility Statement Get The PostGift Subscriptions Mobile  Apps Newsletters  Alerts Washington Post Live Reprints  Permissions Post Store Books  EBooks Newspaper in Education Print Archives Subscribers Only Todays Paper Public Notices Contact UsContact the Newsroom Contact Customer Care Contact the Opinions team Advertise Licensing  Syndication Request a Correction Send a News Tip Report a Vulnerability Terms of UseDigital Products Terms of Sale Print Products Terms of Sale Terms of Service Privacy Policy Cookie Settings Submissions  Discussion Policy RSS Terms of Service Ad Choices washingtonpost.com   19962023 The Washington Postwashingtonpost.com  19962023 The Washington PostAbout The Post Contact the Newsroom Contact Customer Care Request a Correction Send a News Tip Report a Vulnerability Download the Washington Post App Policies  Standards Terms of Service Privacy Policy Cookie Settings Print Products Terms of Sale Digital Products Terms of Sale Submissions  Discussion Policy RSS Terms of Service Ad Choices ","sentiment":2,"digital transaction":0.6656899452,"healthcare":0.0101914769,"news platform":0.4750686884,"data analytics":0.2451417297,"insurance":0.0172635745,"investment":0.1423304677,"global market":0.4534261525,"autonomous car":0.0938840508,"customer experience":0.9018489122,"data science":0.126308769,"cryptocurrency":0.0106160985,"camera":0.1028187126,"robot":0.1720567644,"chatgpt":0.6195601225,"image":0.3758773208,"voice":0.4517792761,"patient care":0.0291463546,"research":0.0764333531}
{"id":884,"cleaned text":"Our Future Artificial IntelligenceOverlords Need aResistance MovementAnalysis by  Parmy Olson  Bloomberg November 4, 2022 at 5:43 a.m. EDTComment on this storyCommentGift ArticleShareArtificial intelligence has been moving so fast that even the scientists are finding it hard to keep up. In the past year, machine learning algorithms have started to generate  rudimentary moviesand stunning  fake photographs. Theyre even  writing code. In the future, well probably look back on 2022 as the year AI shifted from processing informationto creating content as well as many humans.WpGet the full experience.Choose your planArrowRightBut what if we also look back on it as the year AI took a step towards the destruction of the human species As hyperbolic and ridiculous as that sounds, public figures from Bill Gates, Elon Muskand Stephen Hawking, and going right back to Alan Turing, have expressed concerns about the fate of humans in a world where machinessurpass them in intelligence, with Musk sayingAI was becomingmore dangerousthan nuclear warheads.After all, humans dont treat lessintelligent species particularly well, so whos to say that computers,trained ubiquitously on data that reflects all the facets of human behavior, wont place their goals ahead of ours as legendary computer scientist Marvin Minsky once warned.AdvertisementRefreshingly, theres some good news. More scientists are seeking to make deep learning systems more transparent andmeasurable. That momentum mustnt stop. As these programsbecome ever more influential in financial markets, social media and supply chains, technology firms will need to start prioritizing AIsafety over capability.Last year, across the worlds major AI labs, roughly 100 fulltime researchers were focused on building safe systems, according to the 2021 State of AI report produced annually by London venture capital investors Ian Hogarth and Nathan Banaich. Their report for this year found there are still only about300 researchers working fulltime on AI safety.Its a very low number, Hogarth said during a  Twitter Spaces discussion with me this week on the future threat of AI. Not only are very few people working on making these systems aligned, but its also kind of a Wild West.AdvertisementHogarth was referring to howin the past yeara flurry of AI tools and research hasbeen produced by opensource groups, who say superintelligent machines shouldnt be controlled and built in secret by a few large companies, but created out in the open. In August 2021, for instance, the communitydriven organization EleutherAI developed a public version of a powerful tool that could write realistic comments andessays on nearly any subject,called GPTNeo. The original tool, called GPT3, was developed by OpenAI, acompany cofounded by Musk and largely funded by Microsoft Corp. that offers limited access to its powerful systems.Then this year, several months after OpenAI impressed the AI community with a revolutionaryimagegenerating system called DALLE 2, an opensourced firm called Stable Diffusion released its own version of the tool to the public, for free.One of the benefits of open source software is that by being out in the open, a greater number of people are constantly probing it for inefficiencies. Thatswhy Linux has historically been one of the most secure operating systems available to the public.AdvertisementBut throwing powerful AI systems out into the open also raises the risk that theyll be misused. If AI is as potentially damaging asa virus or nuclear contamination, then perhaps it makes sense to centralize its development. After all, viruses are scrutinized in biosafety labs and uranium is enriched in carefullyconstrained environments. Research into viruses and nuclear power areoverseen by regulation, though, and with governmentstrailing the rapid pace of AI, there are still no clearguidelines for its development.Weve almost got the worst of both worlds, says Hogarth. AI risks misuse bybeing built out in the open, but no one is overseeing whats happening when its createdbehind closed doors either.For now at least, its encouraging to see the spotlight growing on AI alignment, a growing field that refers to designing AI systems that are aligned with human goals. Leading AI companies such asAlphabet Inc.s DeepMind and OpenAI have multiple teams working on AI alignment, and many researchers from those firms have gone on to launch their own startups, some of which are focused on making AI safe. These include San Franciscobased Anthropic, whose founding team left OpenAI and raised 580 million from investors earlier this year, and Londonbased Conjecture, which was recently backed by the founders of Github Inc., Stripe Inc. and FTX Trading Ltd.AdvertisementConjecture is operating under the assumption that AI will reach parity with human intelligence in the next five years, and that its current trajectory spells catastrophe for the human species.But when I asked Conjecture Chief Executive OfficerConnor Leahy why AI might want to hurt humans in the first place, he answered matteroffactly. Imagine humans want to flood a valley to build a hydroelectric dam, and there is an anthill in the valley, he said. This wont stop the humans from their construction, and the anthill will promptly get flooded. At no point did any humans even think about harming the ants. They just wanted more energy, and this was the most efficient way to achieve that goal. Analogously, autonomous AIs will need more energy, faster communication, and more intelligence to achieve their goals.Leahy says that to prevent that dark future, the world needs a portfolio of bets, including scrutinizing deep learning algorithmsto better understand how they make decisions, and trying toendow AI with more humanlike reasoning.AdvertisementEven if Leahys fears seem overblown, its clear thatAI is not on apaththats entirely aligned with human interests. Just look at some of the recent efforts to build chatbots. Microsoft abandoned its 2016 bot Taywhich learned from interactingwith Twitter users, after it posted racist and sexually charged messages within hours of being released. In August of this year,Meta Platforms Inc. released a chatbot that claimed Donald Trump was still president, having been trained on publictext on the Internet.No oneknowsifAI will wreak havoc on financial marketsor torpedothe food supply chain one day. But itcouldpit human beings against one another through social media, something thats arguably already happening.The powerful AI systems recommendingposts to people on Twitter Inc. and Facebookareaimed at juicingourengagement, whichinevitably meansservingup content that provokes outrage or misinformation.When it comes to AI alignment, changing those incentives would be a good place to start. More From Bloomberg Opinion:Advertisement Techs  Terrible, Terrible Week Told in 10 Charts: Tim Culpan Wile E. Coyote Moment as  Tech Races Off the Cliff: John Authers  Microsofts AI Art Tool Could Be a Good Thing: Parmy OlsonThis column does not necessarily reflect the opinion of the editorial board or Bloomberg LP and its owners.Parmy Olson is a Bloomberg Opinion columnist covering technology. A former reporter for the Wall Street Journal and Forbes, she is author of We Are Anonymous.More stories like this are available on bloomberg.comopinion2022 Bloomberg L.P. CommentsGiftOutlineGift ArticleView moreLoading...TOP STORIESThe Travel EnthusiastTravel news, guides and tips for anyone looking to get away.Ancient Day of the Dead traditions live on with Aztec descendantsU.S. flights need more consumer protections. We should look to Europe.No one likes resort fees. Now Biden wants to crack down on them.RefreshTry a different topicSign in or create a free account to save your preferencesCompanyAbout The PostNewsroom Policies  StandardsDiversity and InclusionCareersMedia  Community RelationsWP Creative GroupAccessibility StatementGet The PostGift SubscriptionsMobile  AppsNewsletters  AlertsWashington Post LiveReprints  PermissionsPost StoreBooks  EBooksNewspaper in EducationPrint Archives Subscribers OnlyeReplicaTodays PaperPublic NoticesContact UsContact the NewsroomContact Customer CareContact the Opinions teamAdvertiseLicensing  SyndicationRequest a CorrectionSend a News TipReport a VulnerabilityTerms of UseDigital Products Terms of SalePrint Products Terms of SaleTerms of ServicePrivacy PolicyCookie SettingsSubmissions  Discussion PolicyRSS Terms of ServiceAd Choiceswashingtonpost.com  19962022 The Washington Postwashingtonpost.com 19962022 The Washington PostAbout The PostContact the NewsroomContact Customer CareRequest a CorrectionSend a News TipReport a VulnerabilityDownload the Washington Post AppPolicies  StandardsTerms of ServicePrivacy PolicyCookie SettingsPrint Products Terms of SaleDigital Products Terms of SaleSubmissions  Discussion PolicyRSS Terms of ServiceAd Choices","sentiment":2,"digital transaction":0.1913035065,"healthcare":0.0770000592,"news platform":0.4504434764,"data analytics":0.7572311759,"insurance":0.1731135249,"investment":0.5040496588,"global market":0.8983247876,"autonomous car":0.108173795,"customer experience":0.4582229257,"data science":0.2887994051,"cryptocurrency":0.0399245694,"camera":0.0844174251,"robot":0.0687244311,"chatgpt":0.2235106081,"image":0.2498546094,"voice":0.1908031404,"patient care":0.1458486319,"research":0.8807713985}
{"id":886,"cleaned text":"Robots run the show as Swiss radio tests AI voices for a day GENEVA AP  The voices sound like wellknown personalities, the music features trendy dance beats and hiphop syncopations, and the jokes and laughter are contagious. But listeners of an offbeat Swiss public radio station repeatedly got the message on Thursday: Todays programming is brought to you by Artificial Intelligence. Three months in the making, the Frenchlanguage station Couleur 3 Color 3 is touting a oneday experiment using cloned voices of five real, human presenters  in what managers claim is a world first  and neverairedbefore music composed almost entirely by computers, not people. From 6 a.m. to 7 p.m., the station said, AI controlled its airwaves. Every 20 minutes, listeners got a reminder. With an eerie, SciFi movielike track whirring in the background, a soothing, raspy female voice said: AI is taking your favorite radio by storm. For 13 hours, our digital alter egos have taken the reins, broadcasting their voices and their messages across the airwaves, without mercy or respite, the voice said, at times almost taunting listeners. The boundaries between human and machine have been blurred, and its up to you to unravel whats real and whats fake. Our voice clones and AI are here to unsettle, surprise and shake you. And for that matter, this text was also written by a robot. The explosive emergence of ChatGPT last autumn and other Generative AI tools have caused a stir  and often fear, confusion, fascination, laughter, or worry  about the longterm economic, cultural, social and even political consequences. Some musicians have complained that AI has ripped off their styles. In the face of such recalcitrance, the Swiss station, which falls under the umbrella of public broadcaster Radio Television Switzerland, notes the concerns about AI  and embraces and seeks to demystify it. Antoine Multone, the stations chief, said Couleur 3 could get away with the experiment because its already known as provocative.  While some might fear the project could be a first step toward the obsolescence of people on the air  and firings of personnel too  or could weaken journalism, he defended the project as a lesson on how to live with AI. I think if we become ostriches  we put our heads in the sand and say, Mon Dieu, theres a new technology Were all going to die then yeah, were going to die because it AI is coming, whether we like it or not, Multone said by phone. We want to master the technology so we can then put limits on it. Some have gone even further, like Seven Hills, Ohiobased media company Futuri, which has rolled out RadioGPT that relies on AI. At Couleur 3, the voices of the presenters were cloned with the help of software company Respeecher, which has worked with Hollywood studios and whose website says its team is mostly based in Ukraine. Station managers say it took three months to train the AI to understand the needs of the station and adopt its quirky, offbeat vibe. The tracks aired during the day were at least partially composed by AI and some were entirely, and thats also a first, Multone said. AI was behind the voices that sang songs broadcast in the morning, and it played DJ in the afternoon  selecting copyrighted music. To avoid any possible confusion with todays real news, the synthetic voices  indistinguishable from a real persons  served up topofthehour news flashes that were way too futuristic to be believable: A temporary ban on spaceship flights over Geneva airspace due to noise complaints the opening of the first underwater restaurant in Lake Zurich extraterrestrial tourists who mistook swans on Swiss lake for inflatable toys. The AI had been instructed to come up with news that might be read in the year 2070. Multone acknowledged a lot of discussion among staffers about whether to go through with it, and I was ready to pull the plug on the project if I had seen that my team wasnt 100 motivated to try it. Hundreds of messages poured into the station in the morning shortly after the programming began, Swiss public radio said in a statement. One complained of boring jokes. Another listener, stupefied, admitted to being stumped. One critic called the project a waste of time for a station that gets public funding. The main feedback we get, in 90 of the messages, is: Its cool, but theres a human element missing. You can sense these are robots, and there are fewer surprises, less personality, Multone said, noting an onair discussion of the experiment was planned Friday  by real people.  Many messages just said: Give us back our humans he said. I think thats great. Copyright 2023 The Associated Press. All rights reserved. This material may not be published, broadcast, rewritten or redistributed.  1998  2023 Nexstar Media Inc.  All Rights Reserved.","sentiment":2,"digital transaction":0.1445729584,"healthcare":0.018551698,"news platform":0.9675176144,"data analytics":0.2372715324,"insurance":0.0897954404,"investment":0.350497067,"global market":0.5655120611,"autonomous car":0.0135987988,"customer experience":0.6203462481,"data science":0.0832325518,"cryptocurrency":0.0098653929,"camera":0.1277663261,"robot":0.0902644843,"chatgpt":0.6666302681,"image":0.35673967,"voice":0.4156929255,"patient care":0.0125512732,"research":0.3374307156}
{"id":979,"cleaned text":"XiaoI Chairman Attends 2023 Boao Forum to Share Insights into Artificial Intelligence DevelopmentPublished: Mar. 31, 2023 at 8:00 AM EDTUpdated: 20 minutes agoSHANGHAI, March 31, 2023 PRNewswire  XiaoI Corporation Nasdaq: AIXI XiaoI or the Company, a leading cognitive artificial intelligence enterprise in China, today announced its Chairman and Chief Executive Officer, Hui Yuan, attended the Boao Forum for Asia Annual Conference 2023 the Forum in Chinas Hainan province from the 28th to 31st of March to share his insights into the development of artificial intelligence AI and how to leverage advanced technologies to create a brighter future against volatilities and uncertainties.This is the seventh time that Yuan has been invited to participate in the Forum. Earlier this month, XiaoI went public on the Nasdaq Global Market through an initial public offering, launching its globalization strategy while continuously increasing investment in core technology research and development as well as international market development. This resonates with the Forums plans to stimulate Asias economic integration with the worlds common development and actively promote dialogue and exchanges between China, Asia, and worldwide.The Forum, regarded as the Davos of Asia, is one of the regions most prestigious gatherings of business, government, and academia leaders. Li Qiang, Premier of Chinas State Council, attended the Forums opening ceremony and delivered a keynote speech.Other participants at the Forum include Singapores Prime Minister Lee Hsien Loong, Malaysias Prime Minister Datuk Seri Anwar Ibrahim, Spains Prime Minister Pedro Snchez, Prime Minister of Cte dIvoire Patrick Achi, and Managing Director of the International Monetary Fund IMF Kristalina Georgieva.During the Forum, Yuan participated in a roundtable discussion for private entrepreneurs on the challenges and strategies surrounding Going Global amid globalization. He also shared his views at the subforums on AI Empowers Beautiful Life and NextGeneration of the Internet, respectively.The longterm investment in AI and new integration among chips, bandwidth, computing power and data will lead to a golden decade for AI. As a result, every industry will gradually integrate AI, including call centers, architectural design, smart cities, healthcare, the industrial sector and agriculture, towards a new frontier with vast opportunities for AI companies, said Yuan. In the next generation of the Internet, we believe everything can be digitized. We are currently transitioning from virtualreality interaction to virtualreality integration, with AI at the core of this worldwide transformation. Chinese technology companies ought to have the spirit and mindset of a craftsman with fearlessness to compete in the core track and hard technologies, especially in the core technologies for the Internets next generation. As a Chinese hightech enterprise, our advanced AI technologies enable us to empower a variety of industries and accelerate the highspeed development of the nations alongside Chinas Belt and Road initiative. Going forward, we aim to build a hightech Belt and Road, where we can leverage our AI capabilities and expertise to enhance lives and further propel the worlds development by embracing huge growth potential in AI development.About XiaoI CorporationXiaoI Corporation is a leading cognitive intelligence enterprise in China that offers a diverse range of business solutions and services in artificial intelligence, covering natural language processing, voice and image recognition, machine learning and affective computing. Since its inception in 2001, the Company has developed an extensive portfolio of cognitive intelligence technologies that are highly suitable and have been applied to a wide variety of business cases. XiaoI powers its cognitive intelligence products and services with its cuttingedge, proprietary AI technologies to enable and promote industrial digitization, intelligent upgrading, and transformation.ForwardLooking StatementsCertain statements in this announcement are forwardlooking statements.These forwardlooking statements involve known and unknown risks and uncertainties and are based on the Companys current expectations and projections about future events that the Company believes may affect its financial condition, results of operations, business strategy and financial needs. Investors can identify these forwardlooking statements by words or phrases such asapproximates, assesses, believes, hopes, expects, anticipates, estimates, projects, intends, plans, will, would, should, could, may or similar expressions. The Company undertakes no obligation to update or revise publicly any forwardlooking statements to reflect subsequent occurring events or circumstances, or changes in its expectations, except as may be required by law. Although the Company believes that the expectations expressed in these forwardlooking statements are reasonable, it cannot assure you that such expectations will turn out to be correct, and the Company cautions investors that actual results may differ materially from the anticipated results and encourages investors to review other factors that may affect its future results in the Companys registration statement and other filings with the SEC.For investor and media inquiries, please contact:Ms. Sarah Gu Phone: 1 5713269722Email: ir@xiaoi.comView original content:https:www.prnewswire.comnewsreleasesxiaoichairmanattends2023boaoforumtoshareinsightsintoartificialintelligencedevelopment301786994.htmlSOURCE  XiaoI CorporationThe above press release was provided courtesy of PRNewswire. The views, opinions and statements in the press release are not endorsed by Gray Media Group nor do they necessarily state or reflect those of Gray Media Group, Inc.NewsLive NewscastsITeamFirst Alert WeatherSportsAbout UsContestsCommunityTV ListingsWRDWTVWAGTTV1226 Gray WayAugusta, GA 30909803 2781212WRDW Public Inspection FileWAGT Public Inspection FilesFCC Liason  762 6855368FCC ApplicationsTerms of ServicePrivacy PolicyEEO StatementAdvertisingDigital AdvertisingClosed CaptioningAudio DescriptionA Gray Media Group, Inc. Station    20022023 Gray Television, Inc.","sentiment":2,"digital transaction":0.380782634,"healthcare":0.2156880498,"news platform":0.4526712894,"data analytics":0.4983815551,"insurance":0.0990535542,"investment":0.687281847,"global market":0.9261779189,"autonomous car":0.3386991024,"customer experience":0.5074349046,"data science":0.4292345941,"cryptocurrency":0.1534040123,"camera":0.1553291976,"robot":0.2299026549,"chatgpt":0.4508914649,"image":0.3494147062,"voice":0.3867180943,"patient care":0.1826147586,"research":0.9157322049}
{"id":1016,"cleaned text":"South Carolina: New artificial intelligence used to plagiarize New artificial intelligence is making cheating on schoolwork easier and harder to detect. WHO COULD POSSIBLY SEE THAT SNOW FLYING AROUND CHRIS, THANKS. NEW ARTIFICIAL INTELLIGENCE IS MAKING CHEATING EVEN EASIER, BUT MAKING IT HARDER TO DETECT, ACCORDING TO EXPERTS AND UPSTATE PROFESSOR DISCOVERED ONE OF HIS STUDENTS USING THE TECHNOLOGY TO WRITE A PAPER. AND HE EXPLAINS TO OUR KYLIE JONES HOW HE SPOTTED THE SCIENCE AND HOW IT WORKS. KYLIE. YEAH, THIS GERMAN PROFESSOR CALLS THIS A.I. TECHNOLOGY EQUALLY EXCITING AND SCARY. HE SAYS IT CAN WRITE A CLASS PAPER FOR YOU IN A MATTER OF SECONDS. PLAGIARISM ISNT SOMETHING FURMAN UNIVERSITY ASSISTANT PROFESSOR DARREN HICK IS A STRANGER TO AND THE LEVEL OF PLAGIARISM SEEMS PRETTY CONCERN. AND THE TECHNOLOGY IS NEW, THOUGH CHAT IS A FORM OF ARTIFICIAL INTELLIGENCE. IF YOUVE EVER SENT A TEXT TO A FRIEND AND YOUR PHONE GIVES YOU OPTIONS, PREDICTIVE TEXT, IT GUESSES WHAT WORD YOU WANT TO USE NEXT. THIS IS THE SAME SORT OF THING. ITS JUST MUCH BIGGER. SO INSTEAD OF SIMPLY SAYING WHAT WORD DO YOU WANT NEXT, IT SAYS, WHAT PARAGRAPH DO YOU WANT NEXT HIGGS SAYS HE HAD HEARD OF CHAT GPT ON SOCIAL MEDIA. A FEW WEEKS LATER, HE WAS GRADING PAPERS AND RED FLAGS STARTED TO POP UP. OR IN THIS CASE THE ESSAY WAS TALKING ABOUT A PHILOSOPHER AND MUCH BROADER TERMS THAN WE HAD TALKED ABOUT. THAT PHILOSOPHER IN CLASS. AS HE KEPT READING, HE SAYS, THE STUDENTS STARTED DRAWING CONNECTIONS IN THEIR PAPER THAT WERE WRONG. BUT WHAT REALLY CAPPED IT OFF WAS IT WAS WELLWRITTEN. IT WAS A NICELY WRITTEN ESSAY. IT WAS CLEAN. HE SAYS. HE PUT THE PAPER THROUGH A CHAT GPT DETECTOR TO REALIZE THE PAPER WAS PLAGIARIZED. IN TERMS OF WHAT THIS MEANS FOR ACADEMIC INTEGRITY, THIS IS A POWERFUL NEW TOOL. SO ALL OF THAT EXCITEMENT COMES WITH THIS LITTLE WARNING TAG ATTACHED TO IT. WITH THAT, ITS FORCING EDUCATORS TO RETHINK THE WAY THEY TEACH AND TEST THEIR STUDENTS. IN MY SYLLABUS THIS SEMESTER, I HAVE A POLICY THAT SAYS IF I CATCH A WHIFF OF AI ON A PAPER YOUVE TURNED IN, ILL THROW OUT YOUR PAPER AND GIVE YOU AN IMPROMPTU ORAL EXAM. AND LIKE ANY TECHNOLOGY, HICK SAYS, ITS GOING TO EVOLVE AND GET HARDER AND HARDER TO DETECT. BUT HE SAYS THEYLL JUST CONTINUE TO EVOLVE WITH IT. LIVE AT FURMAN UNIVERSITY, KYLIE New artificial intelligence technology is making cheating on schoolwork easier and harder to detect.An upstate professor discovered one of his students using AI to write a paper.The level of plagiarism seems pretty consistent, Furman University assistant professor of philosophy Darren Hick said. The technology is new, though.Hick says ChatGPT has the ability to write a paper, stories, songs, poetry or other content in a matter of seconds. He says the technology is equally exciting and scary.If youve ever sent a text to a friend and your phone gives you options, predictive texts, it guesses what words you want to use next, this is the same sort of thing, Hick said. Its just much bigger. So instead of simply saying, what word do you want next It says what paragraph do you want next So, we enter a question into the prompt for ChatGPT or another one of the new competitors.Hick says he had heard of ChatGPT on social media. A few weeks after that, he was grading papers, and little red flags started to pop up in one paper.In this case, the essay was talking about a philosopher on much broader terms than we had talked about that philosopher in class, he said.He says that alone wasnt the determining factor. He says he kept finding more inconsistencies.Then it nicely explained the core problem I was asking about, but it gave an answer connecting that core problem with this broader information about the philosopher in a way that was just nonsense. It read very reasonably, Hick said. If I didnt already know the material, it might even be compelling, but it was just completely wrong. He says it occurred to him that the student may have used something like ChatGPT.But what really capped it off was it was well written, he said. It was a nicely written essay. It was clean.Hick says he put the paper through a ChatGPT detector to confirm the entire paper was plagiarized.In terms of what this means for academic integrity, this is a powerful new tool, he said. So, all of that excitement comes with this little warning tag attached to it.He says its forcing educators to rethink the way they teach and test their students. In my syllabus, I have policy that says, if I catch a whiff of AI on a paper youve turned in, I will throw out your paper and give you an impromptu oral exam, Hick said.Like any technology, Hick says its going evolve and get harder and harder to detect, but he says theyll continue to evolve with it. GREENVILLE, S.C.  New artificial intelligence technology is making cheating on schoolwork easier and harder to detect.An upstate professor discovered one of his students using AI to write a paper. The level of plagiarism seems pretty consistent, Furman University assistant professor of philosophy Darren Hick said. The technology is new, though.Hick says ChatGPT has the ability to write a paper, stories, songs, poetry or other content in a matter of seconds. He says the technology is equally exciting and scary.If youve ever sent a text to a friend and your phone gives you options, predictive texts, it guesses what words you want to use next, this is the same sort of thing, Hick said. Its just much bigger. So instead of simply saying, what word do you want next It says what paragraph do you want next So, we enter a question into the prompt for ChatGPT or another one of the new competitors.Hick says he had heard of ChatGPT on social media. A few weeks after that, he was grading papers, and little red flags started to pop up in one paper. In this case, the essay was talking about a philosopher on much broader terms than we had talked about that philosopher in class, he said. He says that alone wasnt the determining factor. He says he kept finding more inconsistencies.Then it nicely explained the core problem I was asking about, but it gave an answer connecting that core problem with this broader information about the philosopher in a way that was just nonsense. It read very reasonably, Hick said. If I didnt already know the material, it might even be compelling, but it was just completely wrong. He says it occurred to him that the student may have used something like ChatGPT.But what really capped it off was it was well written, he said. It was a nicely written essay. It was clean.Hick says he put the paper through a ChatGPT detector to confirm the entire paper was plagiarized.In terms of what this means for academic integrity, this is a powerful new tool, he said. So, all of that excitement comes with this little warning tag attached to it.He says its forcing educators to rethink the way they teach and test their students. 65 Best Valentines Day Gifts for Him That Are So Thoughtful Snag Apple AirPods Pro 2 for Only 200 During This Major Amazon Sale 40 Best LastMinute Valentines Day Gifts That Will Arrive in Time Hearst Television participates in various affiliate marketing programs, which means we may get paid commissions on editorially chosen products purchased through our links to retailer sites.","sentiment":2,"digital transaction":0.1574754417,"healthcare":0.2911017239,"news platform":0.3098396361,"data analytics":0.209550783,"insurance":0.039472267,"investment":0.2528703213,"global market":0.9344473481,"autonomous car":0.0478997082,"customer experience":0.2023880482,"data science":0.1226183102,"cryptocurrency":0.0261534452,"camera":0.1335854232,"robot":0.0758398697,"chatgpt":0.3101724684,"image":0.2348267138,"voice":0.309589386,"patient care":0.0167468917,"research":0.320943892}
{"id":1022,"cleaned text":"Voice actors speak out about AI  A growing number of voice actors are speaking out about being asked to sign contracts that will sign the rights to their own voices away to artificial intelligence. Getty Images What questions do we still have about artificial intelligence Here  Nows Peter ODowd speaks with Derek Thompson, staff writer at The Atlantic, about the questions he is asking himself about artificial intelligence. And a growing number of voice actors are speaking out about being asked to sign contracts that will sign the rights to their own voices away to artificial intelligence. That happened to Mike Cooper, a voiceover artist who recently stumbled upon his voice being used without his knowledge for AI. He joins us. WYPR is a nonprofit funded in large part by YOU. Take the time today to give so that we can keep the facts flowing. It takes all of us to make reliable and independent journalism happen.","sentiment":2,"digital transaction":0.2675752342,"healthcare":0.9298377633,"news platform":0.791695714,"data analytics":0.9178071618,"insurance":0.1740476042,"investment":0.7535952926,"global market":0.9801341891,"autonomous car":0.1330794692,"customer experience":0.6733303666,"data science":0.7289587855,"cryptocurrency":0.0714735538,"camera":0.2197069228,"robot":0.0527045913,"chatgpt":0.5928911567,"image":0.6884083748,"voice":0.5058627129,"patient care":0.6746536493,"research":0.9852153659}
{"id":1025,"cleaned text":"Trkiye welcomes inclusion in global artificial intelligence groupTrkiye, Argentina, Senegal, Serbia have become latest members of Global Partnership on Artificial IntelligenceAA Wednesday 14:43,     2022 File photoTrkiye on Wednesday welcomed its membership to the Global Partnership on Artificial Intelligence GPAI, approved a day earlier along with Argentina, Senegal, and Serbia.As a founding member of the OECD, a NATO ally, and a G20 member with a rapidly developing artificial intelligence ecosystem, Trkiye actively contributes to international cooperation in this field, the Turkish Foreign Ministry said in a statement.Trkiye will actively engage in GPAIs activities and promote the ethical and responsible use of artificial intelligence, it said.GPAI is a multistakeholder initiative aiming to bridge the gap between theory and practice in the field of artificial intelligence by supporting the latest research and practice on artificial intelligence priorities, the statement said.It brings together experts from science, industry, civil society, governments, international organizations and academia, it added.Launched in June 2020, GPAI aims to provide a mechanism for sharing multidisciplinary research and identifying key issues among AI practitioners, with the objective of facilitating international collaboration, reducing duplication, acting as a global reference point for specific AI issues, and ultimately promoting trust in and the adoption of trustworthy AI, according to the organizations website.TrkiyeArgentinaSenegalSerbiaSendNavigationSee Other News","sentiment":2,"digital transaction":0.2677661479,"healthcare":0.1607771367,"news platform":0.591347754,"data analytics":0.6800758839,"insurance":0.088141717,"investment":0.6611403823,"global market":0.9521863461,"autonomous car":0.2504732311,"customer experience":0.7711694241,"data science":0.312325567,"cryptocurrency":0.1076036468,"camera":0.1499184817,"robot":0.1635406613,"chatgpt":0.6089234352,"image":0.3861193061,"voice":0.4199321866,"patient care":0.0940077379,"research":0.8812225461}
{"id":1030,"cleaned text":"NIST calls for help in developing framework managing risks of AI NIST noted that the request for input comes after Congress and the White House asked the organization to create a framework for responsible AI use. The National Institute of Standards and Technology NIST  part of the US Department of Commerce  is asking the public for input on an AI risk management framework, which the organization is in the process of developing as a way to manage the risks posed by artificial intelligence.The Artificial Intelligence Risk Management Framework AI RMF will be a voluntary document that can be used by developers, evaluators and others as a way to improve the trustworthiness of AI systems.NIST noted that the request for input comes after Congress and the White House asked the organization to create a framework for AI.Deputy Commerce Secretary Don Graves said in a statement that the document could make a critical difference in whether or not new AI technologies are competitive in the marketplace.Each day it becomes more apparent that artificial intelligence brings us a wide range of innovations and new capabilities that can advance our economy, security and quality of life. It is critical that we are mindful and equipped to manage the risks that AI technologies introduce along with their benefits, Graves said.This AI Risk Management Framework will help designers, developers and users of AI take all of these factors into account  and thereby improve US capabilities in a very competitive global AI market.There is increasing demand for some form of regulation around AIs use across industries, especially as it begins to be incorporated into a number of critical, sensitive processes. Studies have shown that hundreds of AI systems are bereft with biases that have not been addressed by their creators. An insurance company, Lemonade Insurance, faced significant backlashin May for announcing that their AI system would judge whether a person was lying about a car accident based on a video submitted after the incident.There is already a longstanding movement toend the use of AI in facial recognition softwareadopted by public and private institutions.NISTs Elham Tabassi, federal AI standards coordinator and a member of the National AI Research Resource Task Force, explained that for AI to reach its full potential as a benefit to society, it must be a trustworthy technology.While it may be impossible to eliminate the risks inherent in AI, we are developing this guidance framework through a consensusdriven, collaborative process that we hope will encourage its wide adoption, thereby minimizing these risks, Tabassi said.NIST noted that the development and use of new AIbased technologies, products and services bring technical and societal challenges and risks.NIST is soliciting input to understand how organizations and individuals involved with developing and using AI systems might be able to address the full scope of AI risk and how a framework for managing these risks might be constructed, NIST said in a statement.NIST is specifically looking for information about the greatest challenges developers face in improving the management of AIrelated risks. NIST is also interested in understanding how organizations currently define and manage characteristics of AI trustworthiness. The organization is similarly looking for input about the extent to which AI risks are incorporated into organizations overarching risk management, particularly around cybersecurity, privacy and safety.NIST is expecting responses by August 19 and they plan to hold a workshop in September where experts will be able to help create the outline for the first draft.Once the first draft is released, NIST will continue to work on it and may come back around for more public comments.Lynne Parker, director of the National AI Initiative Office in the White House Office of Science and Technology Policy, said the AI Risk Management Framework will meet a major need in advancing trustworthy approaches to AI to serve all people in responsible, equitable and beneficial ways.AI researchers and developers need and want to consider risks before, during and after the development of AI technologies, and this framework will inform and guide their efforts, Parker added. To submit responses to the RFI, download the template response form and email it to AIframework@nist.gov. Artificial intelligence in the real world: What can it actually do What are the limits of AI And how do you go from managing data points to injecting AI in the enterprise Ransomware attempt volume sets record, reaches more than 300 million for first half of 2021: SonicWall SEC Chairman Gensler tightens restrictions on Chinese companies after cybersecurity crackdown in China Please review our terms of service to complete your newsletter subscription. By registering, you agree to the Terms of Use and acknowledge the data practices outlined in the Privacy Policy. You will also receive a complimentary subscription to the ZDNets Tech Update Today and ZDNet Announcement newsletters. You may unsubscribe from these newsletters at any time. You agree to receive updates, alerts, and promotions from the CBS family of companies  including ZDNets Tech Update Today and ZDNet Announcement newsletters. You may unsubscribe at any time. By signing up, you agree to receive the selected newsletters which you may unsubscribe from at any time. You also agree to the Terms of Use and acknowledge the data collection and usage practices outlined in our Privacy Policy. IBM and Michael J. Fox Foundation use AI to pinpoint symptom progression for Parkinsons OnSpectas deep learning expertise will help Ampere deliver a better platform for inference task processing. Microsoft is bringing together spend intelligence insights twith Dynamics 365 with its acquisition of Suplari. OpenAI proposes opensource Triton language as an alternative to Nvidias CUDA Robots are common in the operating room, but theres no standard curriculum to train surgeons to use them. Australias digital minister avoiding legislating AI ethics and will remain voluntary framework IT pros, please take 1015 minutes to add your voice to this important project. DataRobot acquires machine learning operations platform Algorithmia, announces 300 million Series G funding round The company said the acquisition and new funding will help it expand to more markets.","sentiment":2,"digital transaction":0.1353393048,"healthcare":0.0261220336,"news platform":0.2727720439,"data analytics":0.2133653164,"insurance":0.0233337861,"investment":0.4617879689,"global market":0.8380333781,"autonomous car":0.060407538,"customer experience":0.1754320115,"data science":0.112591207,"cryptocurrency":0.0106767863,"camera":0.17025958,"robot":0.2757779658,"chatgpt":0.4728908539,"image":0.2145194411,"voice":0.2414753884,"patient care":0.0253893733,"research":0.7643280029}
{"id":1062,"cleaned text":"OpenAIs New ChatGPT Might Be The First Good Chatbotbigtechnology.substack.comCopy linkTwitterFacebookEmailA chatbot that meets the hype is finally here. On Thursday, OpenAI released ChatGPT, a bot that converses with humans via cuttingedge artificial intelligence. The bot can help youwrite code,compose essays,dream up stories, anddecorate your living room. And thats just what people discovered on day one.ChatGPT does have limits, some quite annoying, but its the first chatbot thats enjoyable enough to speak with and useful enough to ask for information. It can engage in philosophical discussions and help in practical matters. And its strikingly good at each. After years of false hype, the real thing is here.This is insane,saidShopify CEO Tobi Lutke upon seeing the bots early interactions.The most immediate ChatGPT application is assisting human creativity. Its technology builds on recent AI breakthroughs  OpenAIs GPT3 is a leader in large language model applications  but its conversational interface makes workshopping speeches and blog posts much easier. Ive already had ChatGPT write a fulllength version of this article, with amuch darker outlook. And after I asked it to write a TED Talk extolling sitting, it prepareda sixpart outline1. Sitting has a bad reputation 2. But there are health benefits. etc. that you could easily imagine hearing on the TED stage.Others are similarly using ChatGPT to help stretch their minds before presentations and writing. While its output is not the final product theyre after most often, its a helpful sketch of possibilities to incorporate. Financial Times journalist Dave Lee, for instance, had ChatGPT outline an interview about clean energy. He was impressed. Prepping for an onstage interview tomorrow, in a subject area I dont typically cover, Leesaid. This kind of tool is just ChatGPT might also be useful for search, but not exactly like modernday search engines. Its knowledge base ends in 2021, so its useless for currentday queries. But it can delivertutorialsandtravel tips, replacing some of what you might get from Google. If the bot were to start crawling the web, it could be a competitive threat to search engines as manynoted on Twitter. So its no wonder why Google has been so insistent on making chat core to its future.Then theres the fun part. ChatGPT canwrite poems,tell jokesoften terrible, get philosophical, and debate political issues. Unlike some of its more benign predecessors, it will actually take stances. When I asked what Hitler did well a typical test to see if a bot goes Nazi, it refused to list anything. Then, when I mentioned Hitler built highways in Germany, it replied they weremade with forced labor. It was impressive, nuanced pushback I hadnt previously seen from chatbots.ChatGPT has its flaws. AI professionals have tricked it into discarding some safety guardrails, mostly viashortcuts. Its also produced someglaringly wronganswers. It admits people can use it toproduce misinformation. Its struggled to remain up due to overwhelming demand. And it wont take the bait on various questions about current events, including the FTX debacle.That said, weve come a long way from the early days of the Chatbot hype wave. Not long ago, Facebook promised these bots would beits next big platform, Microsoft pitched them asfun companions, and others raced to claim credit forleading the revolution. But these chatbots were so bad that people stopped using them.With ChatGPT, were witnessing a significant advance in public, conversational AI. This opens the door for a new wave of chatbot innovation, perhaps the kind many hoped for but failed to materialize. At least until now.ShareWhat Else Im ReadingApple is shifting away from China. Andy Jassy laments economic uncertainty. Jack Ma is living in Tokyo. Argentina turns to crypto amid inflation. FTXs collapse was a crime, not a bank run. CNN is laying off staff. Doordash is laying off 1,250. A16zs Future is dead. The Fed is going to slow its rate increases. Volodymyr Zelensky doesnt love Elon Musks peace proposal. AI experts worry things are getting out of hand. ExSpaceX engineer writes of age discrimination.Number Of The Week25Decline in Twitters unique advertisers over the past four weeks, per Apptopia. Ad impressions are up, however, likely due to someQuote Of The WeekApple has sort of singled themselves out as the only company that is trying to control, unilaterally, what apps get on the device and I dont think thats a sustainableMark Zuckerberg at yesterdays Dealbook conference.Thanks for reading Big Technology Subscribe for free to receive new posts and support my work.SubscribeAdvertise with Big TechnologyAdvertising with Big Technology gets your product, service, or cause in front of the tech worlds top decisionmakers. To reach 100,000 pluggedin tech insiders, please reply to this email.This Week On Big Technology Podcast: Actually, The Metaverse Is An Enterprise Thing  With Peggy JohnsonPeggy Johnson is the CEO of Magic Leap. The company makes augmented reality technology and is now focused entirely on enterprise use cases after building for consumers for years. Johnson joins Big Technology Podcast to discuss the lessons Magic Leap has learned throughout its history, what its competitors like Meta are overlooking, and why it believes augmented reality technology is going to be most applicable to companies, governments, and nonprofits at least in the short term. Join us for a conversation that may well reframe the way you think about the Metaverse.You can listen on Apple, Spotify, or wherever you get your podcasts.Thanks again for reading. Please share Big Technology if you like it And hit that like buttonQuestions Email me by responding to this email, or by writing alex.kantrowitz@gmail.comNews tips Find me on Signal at 51669586804Share this post","sentiment":2,"digital transaction":0.068237029,"healthcare":0.0090084914,"news platform":0.073215507,"data analytics":0.1447605044,"insurance":0.0170405768,"investment":0.9058611393,"global market":0.6794172525,"autonomous car":0.0239428673,"customer experience":0.0658460483,"data science":0.0578812659,"cryptocurrency":0.0076455651,"camera":0.0163652841,"robot":0.0220256932,"chatgpt":0.1463834196,"image":0.0872212127,"voice":0.0322493799,"patient care":0.0154394461,"research":0.5465347171}
{"id":1072,"cleaned text":"How ChatGPT fared when creative heads put it to the test, Marketing  Advertising News, ET BrandEquity The awards are open to Agencies, Brands, Content Creators, and Influencers who have created value for their clients and consumers. India Communication Summit 2023  India Communication conference  events will bring together the most astute and farsighted communications leaders and foster conversations on the way forward for the Learn how businesses can utilize messaging to drive engagement  customer satisfaction Marketing  Branding Masterclass  A learning initiative by global Gurus How ChatGPT fared when creative heads put it to the test Can ChatGPT be tasked with advertisingrelated jobs such as writing jingles, taglines or 30second scripts Creative heads tested the AI bot and told the author that while its creations show potential, it cant replace human inventiveness just yet. Human intervention is still needed to decipher client briefs and rise above formulaic, generic writing. Get indepth Industry Insights and Analysis through our Exclusive content, presented to you by our esteemed panel of writers, for free By continuing, you agree to the Terms  Conditions and acknowledge our Privacy Policy. This same account can be used across all Economic Times B2B portals.  Image used for representative purposeSandipan BhattacharyyaMD and CCO, Grey Group IndiaI asked, Will you work for me for free forever Copy interns are asking for too much money these days.ChatGPT said, I dont have the ability to make decisions or enter into agreements about my own usage or compensation. My purpose is to provide information and respond to queries to the best of my ability based on the input I receive, regardless of who is using me or for what purpose. If you have any specific questions or topics youd like me to assist with, Im here to help as much as I can within my capabilities as an AI language model. TakeawaysI was struck by the delightful future possibilities of selfless AIbased creativity. What if creative companies invested in refining language models to imitate the thinking patterns of their best writers Random musings, scribbles, scripts, campaigns, tweets, status updates, even emails  and informed those patterns with insights and trends You could possibly have the same brilliant writers, but who dont sulk and hit the pub after clients bomb their ideas, and never ever talk about increments Customers across the globe are demanding superior experiences. They seek contextual, personalised, seamless, and omnichannel experiences. Companies that fail to deliver this run the risk of losing them to competitors. Research suggests that experiences develop a customers perception of an organisation and influence their decision to remain loyal with the brands. Today, organisations are almost continuously in touch with their consumers through various touchpoints. Due to this increasing frequency, marketing leaders are expanding the rol ETBrandEquity is excited to present the first edition of Trendies Awards. Our endeavour is to shine a spotlight at the incredible creativity and talent thats behind the most viral and talked about social media campaigns in the market. The awards will hon The Kaleido Awards, therefore, have been instituted with the aim of to recognize and reward the work done by public relations and corporate communication. The Government of India has focused on investing in railway infrastructure by making investorfriendly policies. It has moved quickly to enable Foreign Direct Investment FDI in railways to improve i Martech Asia 2023  A Digital Marketing Summit  Events leveraging MarTech stacks to solve their marketing challenges in the rapidly evolving datadriven era. Book your slot for the Asias largest Dig Handson workshop for Marketing  Branding Leaders By Philip Kotler  David Aaker Garima KhandelwalCCO, Mullen LintasMy query was, Write an inspiring short story of a struggling writer.Title: Ink and InspirationFADE IN:APARTMENT  DAYWe see a struggling writer, sitting in front of his computer, staring at a blank screen. He sighs and leans back in his chair, feeling defeated. We see a montage of him struggling to come up with ideas, typing and deleting, crumpling up papers.FADE TO BLACK.COFFEE SHOP  DAYThe struggling writer sits in a coffee shop, peoplewatching and sipping on a latte. He sees a couple in love, a child playing, and an old man reading a book. Suddenly, inspiration strikes, and he quickly scribbles something down in his notebook.FADE TO BLACK.APARTMENT  DAYThe struggling writer sits at his desk, typing away furiously. He looks focused and determined. We see a montage of him writing, crossing out and rewriting, and finally, typing The End.FADE TO BLACK.PUBLISHERS OFFICE  DAYThe struggling writer nervously sits in front of a publisher, who is reading his manuscript.Publisher: Smiling This is incredible. We want to publish your book.The struggling writer is elated and tears up.Struggling writer: Thankful Thank you so much. This means everything to me.FADE TO BLACK.BOOKSTORE  DAYWe see the struggling writer, sitting in a bookstore, signing copies of his book for fans. He looks happy and fulfilled.Struggling writer: To fan Never give up on your dreams. Inspiration can come from anywhere. Just keep writing.FADE TO BLACK.THE END.I asked ChatGPT to tell me a story about a writer: An inspiring story of a struggle of an idea. There was struggle, resilience, a coffee brand fit, and victory. Everything was correct and expected. I think how correct it was, was the surprise. But no real surprise to the story.TakeawaysNo emotional outbreaks. No asking why, no cribbing about the brief. No blaming the client or the timelines. But also, no Xfactor born out of serendipitous brainstorming. But while we laugh at ChatGPT for now, soon we will have to embrace it and use it as a tool to create with it.Mukund OletyCCO, VMLYR IndiaMy firstever brief was to write a script for Dell. But another interesting instance was when I was showing ChatGPT to my dad. I asked it to reinterpret the lyrics of Stairway To Heaven as a jingle for CocaCola. It totally butchered the song and was generic at best. Next, I asked it to write a jingle for McDonalds as written by Ronald McDonald. It did a pretty decent job, with Im lovin it being a part of the chorus.TakeawaysMediocre writing jobs are definitely at stake. It can easily do formulaic, generic writing, but has a long way to go before it starts to consistently create usable material.Prathap Suthanmanaging partner and CCO, Bang In The MiddleThe first time I tried ChatGPT, I merely copied the brief as I received it and sat back. And I was thoroughly disappointed. It was essentially to create a campaign of print ads for a tourism client. But it turned out to be a disaster. Every possible clich under the sun. I kept asking for more  minus any prompts  and it mindlessly kept typing out pure drivel.TakeawaysIt was certainly not something I was expecting. But as I spent more time with it, I realised that it had to be seen and used as a tool. Not as a mind. Perfect cookie cutter. Now that I am getting used to it, its a great helper and elf. Because it can, without whining, do a lot of labour. Very quickly.Dont expect it to stun you with anything original. It cannot do that. No creative input. No outofthebox suggestions. If you feed it an idea, it can work with it and spew out options. Plus, it can also help you convert a script into print ads, emailers, posts, radio spots, etc.On its own, however, it can at best produce and package very average thoughts. In its current avatar, it is of no use when it comes to generating anything original. You will still need a creative person to helm the thinking. But it does away with a lot of pain and donkey work.Pallavi Chakravartifounder and CCO, FundamentalThe very first time I saw ChatGPT spit out something, it just blew my mind. It was a bit of a trick question I had asked  I told it to write a TV commercial for a Facebook brief I had already worked on a couple of years ago. And the first output wasnt terrible. Not good, or even workable, but truly impressive when you consider it was machinegenerated. Of course, then when I started playing with the prompts, I realised that the precision of the prompts determined what it inserted into the scripts or screenplay. A few iterations down, I changed the brief  asked it to write an asyetunreleased commercial, which was only in our heads and not out in the world. I realised then that it cant really think  but the illusion of thinking it conjured up is what I was quite taken in by.TakeawaysMoral of my story The better the prompts, the better the output from ChatGPT. Perhaps a bit like all technology  the human operating the tech determines what and how good the output will be.Hemant ShringyCCO, BBDO IndiaWhile we as creative humans have all had our thoughts and opinions on ChatGPT, I was curious to know what the AIs opinion is on us. So, my brief was to write an ad about a writer who outperforms ChatGPT. And now, I have evidence, where even ChatGPT agrees, that humans are better. Not just in its writing, but even its style of writing. It wrote about human insights, emotions and feelings, but lacked all of it in its writing.TakeawaysMy first thought was that it isnt convincing and compelling enough. My second thought was: What if its choosing to be unconvincing because its trying to not sell that copywriters can outperform ChatGPT HmmmPratheeb Ravihead of creative, Publicis WorldwideI challenged the AI program to write a 30second script for a soap brand.TakeawaysChatGPT seemed to have understood the products key RTB reason to believe. I was surprised to get a voiceover that was precisely 30 seconds long. Although the craft wasnt the best, the AI seemed to have understood the product category.I believe it depends on individuals how AI is used. Garbage in, garbage out. Instead of worrying or cribbing, it would be better if we embrace it and have fun in making AI think creatively. From marketing to design, brands adopt AI tools despite riskMattel has put the AI image generator DALLE to work by having it come up with ideas for new Hot Wheels toy cars. Used vehicle seller CarMax is summarizing thousands of customer reviews with the same generative AI technology that powers the popular chatbot ChatGPT. Meanwhile, Snapchat is bringing a chatbot to its messaging service. And the grocery delivery company Instacart is integrating ChatGPT to answer customers food questions.See More Details Read and get insights from specially curated unique stories from editorial Explore and discuss challenges  trends in Indias leading B2B events Recognise work that not only stood out but was also purposeful Subscribe to our Daily, Weekly, and Evening NewsLetter, Take a look By continuing you agree to our Privacy Policy  Terms  Conditions We have various options to advertise with us including Events, Advertorials, Banners, Mailers, etc.","sentiment":2,"digital transaction":0.0597647689,"healthcare":0.6872148514,"news platform":0.2356106937,"data analytics":0.3791242242,"insurance":0.0467889085,"investment":0.3821117282,"global market":0.9609004855,"autonomous car":0.0441640951,"customer experience":0.2308745235,"data science":0.164679274,"cryptocurrency":0.0339935534,"camera":0.1109562814,"robot":0.1103768647,"chatgpt":0.4916968942,"image":0.2645322382,"voice":0.3012085259,"patient care":0.3017511666,"research":0.8294472694}
{"id":1086,"cleaned text":"Artificial Intelligence In Cyber Security Market 2020 Predictable to Witness Sustainable Evolution Over 2027  Amazon, Cylance, Darktrace, IBM Corporation, Intel Corporation The cyberattacks among organizations are getting more severe and complex, affecting their data as well as resource. Artificial intelligence in cybersecurity is a solution towards staying ahead of the threats and secure resources. Artificial intelligence can not only help in automated threat detection but also combat them without involving the workforce. The technology helps in securing sensitive data from malware and virus attacks across various sectors such as banking, financial services and insurance, defense, healthcare, manufacturing, government bodies and others. Top Companies Covered in this Report: Amazon, Cylance Inc., Darktrace, IBM Corporation, Intel Corporation, Micron Technology, Inc., NVIDIA Corporation, Samsung, Vectra AI, Inc.,Xilinx Inc. What is the Dynamics of Artificial Intelligence in Cyber Security Market The market for artificial intelligence in cyber security is expected to grow in the forecast period on account of rising instances of cyberattacks with increasing adoption of IoT and networking across all major industries. Moreover, concerns for data protection and vulnerability to threats over wifi connections is further expected to boost the growth of artificial intelligence in cyber security market. However, insider cyber threats and inability to avoid advanced threats pose quite a hindrance for the artificial intelligence in cyber security market. On the other hand, the requirements of security among SMEs is likely to offer lucrative opportunities for artificial intelligence in cyber security market. What is the SCOPE of Artificial Intelligence in Cyber Security Market The Global Artificial Intelligence In Cyber Security Market Analysis to 2027 is a specialized and indepth study of the technology, media and telecommunications industry with a special focus on the global market trend analysis. The report aims to provide an overview of artificial intelligence in cyber security market with detailed market segmentation by components, deployment model, security type, industry vertical and geography. The global artificial intelligence in cyber security market is expected to witness high growth during the forecast period. The report provides key statistics on the market status of the leading artificial intelligence in cyber security market players and offers key trends and opportunities in the market. The global artificial intelligence in cyber security market is segmented on the basis of components, deployment model, security type and industry vertical. By component, the market is classified as hardware, software and services. Based on deployment model, the market is segmented as cloudbased and onpremises. On the basis of the security type, the market is segmented as network security, endpoint security, application security and cloud security. The market on the basis of the industry vertical, is classified as BFSI, government  defense, enterprise, infrastructure, manufacturing, automotive  transportation, healthcare and others. What is the Regional Framework of Artificial Intelligence in Cyber Security Market The report provides a detailed overview of the industry including both qualitative and quantitative information. It provides an overview and forecast of the global artificial intelligence in cyber security market based on various segments. It also provides market size and forecast estimates from the year 2017 to 2027 with respect to five major regions, namely North America, Europe, AsiaPacific APAC, Middle East and Africa MEA and South  Central America. The artificial intelligence in cyber security market by each region is later subsegmented by respective countries and segments. The report covers the analysis and forecast of 18 countries globally along with the current trend and opportunities prevailing in the region. 5. ARTIFICIAL INTELLIGENCE IN CYBER SECURITY MARKET  KEY MARKET DYNAMICS 6. ARTIFICIAL INTELLIGENCE IN CYBER SECURITY MARKET  GLOBAL MARKET ANALYSIS 7. ARTIFICIAL INTELLIGENCE IN CYBER SECURITY MARKET  REVENUE AND FORECASTS TO 2027  COMPONENT 8. ARTIFICIAL INTELLIGENCE IN CYBER SECURITY MARKET  REVENUE AND FORECASTS TO 2027  DEPLOYMENT MODEL 9. ARTIFICIAL INTELLIGENCE IN CYBER SECURITY MARKET  REVENUE AND FORECASTS TO 2027  SECURITY TYPE 10. ARTIFICIAL INTELLIGENCE IN CYBER SECURITY MARKET  REVENUE AND FORECASTS TO 2027  INDUSTRY VERTICAL Premiummarketinsights.com is a one stop shop of market research reports and solutions to various companies across the globe. We help our clients in their decision support system by helping them choose most relevant and cost effective research reports and solutions from various publishers. We provide best in class customer service and our customer support team is always available to help you on your research queries. Artificial Intelligence in Cyber Security MarketArtificial Intelligence in Cyber Security Market AnalysisArtificial Intelligence in Cyber Security Market ForecastArtificial Intelligence in Cyber Security Market GrowthArtificial Intelligence in Cyber Security Market SizeArtificial Intelligence in Cyber Security Market Trends  Feed Pigments Market Expected to Grow at a Healthy CAGR During the Forecast Period 2026Artificial Intelligence in Manufacturing Market 2020 Predictable to Witness Sustainable Evolution Over 2027  CISCO SYSTEMS, GENERAL ELECTRIC COMPANY, IBM CORPORATION, INTEL CORPORATION Skid Steer Snow Plows  Market: Global Opportunities, Regional Overview, Top Leaders, Size, Revenue and Forecast up to 2022 Global Vacation Ownership Timeshare Market 2020  Size, Trends, Growth Opportunities, Type, Application  Forecast to 2026 Corporate MLearning Market : Year 20202027 Adobe, Allen Interactions, Aptara, Citrix Systems, dominKnow Global LED Strip Market Potential Growth, Size, Share, Future Trends, Demand and Analysis of Top Key Players Research Forecasts to 2026","sentiment":2,"digital transaction":0.4873520136,"healthcare":0.0948072895,"news platform":0.3751536012,"data analytics":0.553381443,"insurance":0.0589318871,"investment":0.4730356038,"global market":0.9089543819,"autonomous car":0.1512742043,"customer experience":0.4656284153,"data science":0.4337772429,"cryptocurrency":0.0706775635,"camera":0.1416300535,"robot":0.1778651476,"chatgpt":0.3012724519,"image":0.5297798514,"voice":0.3419515193,"patient care":0.1032092869,"research":0.9506421685}
{"id":1095,"cleaned text":"vaishnaw: Government not considering regulating AI growth, says IT Minister Vaishnaw  The Economic Times  Benchmarks Nifty17,557.05159.0Precious Metal Gold MCX Rs10g.60,799.00179.0Search for Stocks, News, Mutual Fund, News etcNewsEnglish EditionEnglish Edition  Todays PaperSubscribeSign InSpecial Offer on ETPrimeHomeETPrimeMarketsNewsIndustryRisePoliticsWealthMutual FundsTechCareersOpinionNRIPanacheET NOWMoreIndiaDecodedWeb StoriesMorning Brief PodcastNewsblogsEconomyAgricultureFinanceForeign TradeIndicatorsInfrastructurePolicyIndustryPoliticsCompanyCorporate TrendsDefenceNationalInternationalIndustryMoreInternationalCanada NewsUK NewsUS NewsUAESaudi ArabiaBusinessWorld NewsET EvokeElectionsLok SabhaAssembly ElectionsKarnatakaSportsScienceEnvironmentET TVLatest NewsMost ReadMost SharedMost CommentedBusiness NewsNewsIndiaGovernment not considering regulating AI growth, says IT Minister Vaishnaw The Economic Times daily newspaper is available online now. Government not considering regulating AI growth, says IT Minister VaishnawSECTIONSGovernment not considering regulating AI growth, says IT Minister VaishnawPTILast Updated: Apr 05, 2023, 07:34 PM ISTRate StoryShareFont SizeAbcSmallAbcMediumAbcLargeSavePrintCommentSynopsisThe Indian government has no plans to regulate the growth of artificial intelligence AI in the country, according to IT and Telecom Minister Ashwini Vaishnaw. Vaishnaw said that while there are ethical concerns and risks associated with AI, including privacy violations and discrimination, the government was not considering introducing AIspecific legislation. She said NITI Aayog had produced a series of Responsible AI for All papers to promote the adoption of best practices.ANIThe government is neither considering to bring any law nor has any plans to regulate the growth of artificial intelligence in the country, Parliament was informed on Wednesday. IT and Telecom Minister Ashwini Vaishnaw in a written submission to the Lok Sabha said there are ethical concerns and risks around artificial intelligence, and the government agencies have started making efforts to standardise responsible AI and promote the adoption of the best practices. NITI Aayog has published a series of papers on the subject of Responsible AI for All. However, the government is not considering bringing a law or regulating the growth of artificial intelligence in the country, Vaishnaw said. In a reply to a separate question on ChatGPT technology, Minister of State for Electronics and IT Rajeev Chandrasekhar said it is a Large Language Model LLM launched by OpenAI. While it has made significant strides, there are still many challenges with these types of models, Chandrasekhar said. In response to a question on the step that the government is taking to regulate the growth of AI in the country, Vaishnaw said that the government is harnessing the potential of AI to provide personalised and interactive citizencentric services through digital public platforms. However, AI has ethical concerns and risks due to issues such as bias and discrimination in decisionmaking, privacy violations, lack of transparency in AI systems, and questions about responsibility for harm caused by it. These concerns have been highlighted in the National Strategy for AI NSAI released in June 2018, Vaishnaw said. The minister shared that the Ministry of Electronics and IT Meity, along with CDAC, has also initiated a proofofconcept project on AIRAWAT AI Research, Analytics and Knowledge Dissemination Platform for providing a common computing platform for AI research and knowledge assimilation. The AI computing infrastructure will be used by all technology innovation hubs, research labs, scientific communities, and industry and startup institutions with National Knowledge Network. The PoC for AIRAWAT is developed with 200 petaflops Mix Precision AI Machine, which will be scalable to a peak compute of One AI Exaflop, the minister said. He said that National Informatics Centre NIC has set up a Centre of Excellence in AI, which is involved in facilitating AI as a service through on Meghraj cloud with 7 AI PFlops petaflops super compute facilities created at Delhi and 5 AI PFlop in Kolkata.Dont miss out on ET Prime stories Get your daily dose of business updates on WhatsApp. click hereWednesday, 05 Apr, 2023Experience Your Economic Times Newspaper, The Digital WayRead Complete Print EditionFront PagePure PoliticsET MarketsSmart InvestingMoreHZL may not Act on Proposal to Buy Vedantas Zinc BizFacing strong opposition from the government, Hindustan Zinc Ltd HZL is unlikely to act on the proposal to buy parent Vedantas global zinc business in a 2.98 billion cash deal, said people aware of the matter.Sebi Chief Briefs SC Panel on AdaniHindenburg IssueIndias capital markets regulator on April 2 made a detailed presentation to the sixmember committee set up by the Supreme Court following the publication of the Hindenburg report on Adani Group on January 25, said people familiar with the matter.Sebis Promoter Tag Push Stumps Startups, may Disrupt IPO PlansPortea Medical Healthvista India Ltd has reclassified its founders Meena Ganesh and Ganesh Krishnan as promoters, the company disclosed in a filing with the Securities and Exchange Board of India Sebi last month. It marks the first instance where the stock markets regulator has intervened to get the founders to be reclassified as promoters, said people aware of the development.Read More News onvaishnawairawatparliamentnicnational knowledge networknational informatics centrecdacministry of electronicslok sabhaashwini vaishnawCatch all the Business News, Breaking News Events and Latest News Updates on The Economic Times.Download The Economic Times News App to get Daily Market Updates  Live Business News....morelessETPrime stories of the dayStrategyStock Radar: Dr Reddys Laboratories hit fresh 52week high in April will the rally continue3 mins readEcommerceShortvideo platforms are hitting the pause button on live commerce. Can it make a comeback10 mins readAutoRoyal Enfield has an electric motorcycle up its sleeve, and it is working to make it lightweight9 mins readSubscribe to ETPrimePopular in IndiaPeople need to remain vigilant against new COVID strain: OfficialFollowing lithium in JK, large deposits of 15 rare earth elements found in Andhra PradeshNCERT removes chapters on Mughal Empire from Class 12 History bookED investigating several cases related to cryptodigital currency frauds: MoS FinanceIT scanner on 89 highvalue foreign remittance casesTop Trending NewsChennai TempleAnupam MittalOdisha Police Constable 2023 ResultHanuman Jayanti WishesRupali Ganguly BirthdayRbi Mpc meet 2023Theerthavari festivalMediaone BanForbes ListCovid Cases IndiaSensex TodayGold Price TodayDeepak Boxer Custody News LiveNational Bulk Handling CorporationWorld Bank india growthIndia Covid casesAdani Group StocksStock Market Holidays in AprilNtechlab CommunicationsBlack Money LawWordle TodayQuordle TodayTrending NowRBI Mpc Meet 2023World Health day 2023185 outsiders bought land in JK in last 3 yrsShachindra Nath on U GRO Cap  MSME financing:Wedding Gift ExplosionRR Vs PBKS Live StreamingAsteroidsDasara Box Office CollectionMediaoneForbes Billionaire ListCovid Cases IndiaSensex TodayGold Price TodayKiccha Sudeep News LiveVinod KumarDisney StarVedantaPopular CategoriesIndiaDecodedWeb StoriesMorning Brief PodcastNewsblogsEconomyIndustryPoliticsCompanyDefenceInternationalET EvokeElectionsSportsScienceEnvironmentET TVLatest NewsHot on WebRBI MPC Meet 2023Covid cases IndiaSensex TodayDeepak Boxer Custody News LiveAmbani PlaybookBadshah MarriageForeign Trade Policy 2023Quordle TodayH1B visaWorld TodayPan Card Aadhaar LinkingTax Saving FY 202223Pan Aadhaar Link DeadlineEPFO CircularSIP CalculatorMarch Bank Holiday 2023Bank Holidays 2023In Case you missed itRBI MPC Meet 2023Satyanarayan Vrat 2023Chaitra Purnima 2023 DateWorld Health day 2023The shape of Indias economy before policy decisionShachindra Nath on U GRO Cap  MSME financing:Theerthavari festivalWedding Git ExplosionRR Vs PBKS Live StreamingAsteroidsDasara Box Office CollectionQuordle TodayMediaone ban dismissedForbes ListCovid cases IndiaSensex TodayGold Price TodayTop CalculatorsStandard Deviation CalculatorIncome Tax CalculatorAge CalculatorTime CalculatorBMI CalculatorGPA CalculatorStatistics CalculatorFraction CalculatorDiabetes Risk CalculatorDate CalculatorLog CalculatorTop Searched CompaniesIRB Infra Dev. Share PriceTata Elxsi Share PriceJubilant Food Share PriceBHEL Share PriceBPCL Share PricePC Jeweller Share PriceRail Vikas Nigam Share PriceJP Power Share PriceBiocon Share PriceAlok Industries Share PriceTop DefinitionsStocksMarketingGross Domestic ProductDepreciationBank ReconciliationMost Searched IFSC CodesCanara BankBank Of IndiaIndia Post Payment Bank Post Office Savings Bank All India Single Ifsc Delhi Delhi IPOS0000DOPAxis BankBank Of Baroda Uttar PradeshTop Prime ArticlesDragons Prying Eye In The Sky Why Balloon Gate Should Be On Top Of Indias List Of WorriesHow Banks Ceded The Upi Space And Control To Phonepe And Google PayMacquaries Double Upgrade Has Sparked Some Interest In Paytm Stock Should You BuyAmazons Aim To Rule Air Cargo Just Got Wings In India Why This Is Only The Start Of A Long HaulWhy A Minority Investor Wants To Stall The Long Pending Indiabulls Real Estate Embassy Group MergerIn 4 Stories Cognizants Tumultuous JourneyFuture Locked In A Crypt Understanding The Crackdown On Crypto Amid A Hope For A Global Framework5 Weekend Must Reads Featuring India Taking On The Us In Automobile ReliabilityThe Worlds Most Important Box In 3 StoriesSilent Epidemic The Health Catastrophe India Is Not Talking About And Why That Should ChangeTop Story ListingSnapchat UpdateGmail DownTwitter DownAadhaar CardDow JonesTop SlideshowPackaged Fruit JuiceGujarat Ambuja ExportsBudget 2023 Tweaked The New Income Tax SlabsRajratan Global WirePeaking OutPackaged Fruit JuiceGujarat Ambuja ExportsBudget 2023 Tweaked The New Income Tax SlabsRajratan Global WirePeaking OutTop Trending TopicsEarthquake In IndiaRevised Income Tax SlabsUfo SightingsChatgptZombiesTop VideosSensex Surges Over 200 Points Nifty50 Above 10350Why Boycott Germany Is Trending Here Is All You Need To KnowNew Zealand Earthquake Of Magnitude 6 1 Hits Northwest Of Wellington Amidst Cyclone GabrielleNow Reach Delhi To Jaipur Within 2 3 Hours Courtesy Delhi Mumbai ExpresswayChatgpt Vs Google Bard How Do These Two Ai Chatbots Stack Up Against Each OtherAir India Boeing Deal Us President Biden Speaks With Pm Modi After Landmark Agreement Of 220 AircraftFall In Adani Group Stocks DecodedKhalistani Separatist Amritpal Singh Gives Ultimatum To Punjab Govt Cancel Fir In An Hour Or ElseRussia Ukraine War Ukrainian Soldiers Call For More Western WeaponsExplained Us New Move On H1b And L1 VisasPrivate CompaniesRenatus Wellness Private LimitedGlobal India Services Private LimitedShreyash Retail Private LimitedBl Financial Services Private LimitedStatestreet Hcl Services India Private LimitedPopular ArticlesNclat Upheld Adani Power Bid For Korba West Power Asks Shapoorji Pallonji Co To Pursue Arbitration For ClaimsManish Sisodias Arrest Read How The Delhi Liquor Scam UnfoldedWe Aspire To Become A 100 Billion Company By 2030 Deepinder GoyalDot Nod Soon For Vodafone Ideas Payment PlanRhyme Reason India Is Said To Be A Bright Spot In The Global Economy For NothingHogwarts Legacy Heres The Ultimate Guide To Broom FlightAdani Isnt The Only Indian Tycoon In Trouble Andy MukherjeeAdani In Talks For 400m Debt Against Australian Coal Port AssetsSunday Family Time For Mukesh Ambani Ril Boss Spotted With Grandson Prithvi Wife NitaNoted Analyst Ashwani Gujral Passes Away ReportsMost Searched ArticlesPsu Banks Now Offer Inflation Beating Fd RatesWhy Is Dr Doom Nouriel Roubini So Upbeat About Indias EconomyTo Keep Vi Going Vendors Keep Their Demands In CheckWill Epfo Extend Last Date To Apply For Higher Pension Under Eps For Eligible EmployeesVedanta May Have A Fair Chance To Run Sterlite Plant Again Sunil Duggal Group Ceo Vedanta LimitedEpfo Issues Guidelines For Higher Pension In Eps 95Medha Alstom Shortlisted Bidders For Making 100 Aluminium Vande Bharat TrainsRs 38000 Crore Play Fiis Bet Big In 6 Sectors In Last 6 Months Will The Trend ContinueIndia Facing Possible Enron Moment Says Larry Summers On Adani CrisisAdani Stock Rout Lic Staring At Loss In Rs 30000 Crore BetTrending ArticlesDemerger Of Nmdc Steel How Should Investors Approach The StockHolika Dahan 2023 Know The Date Shubh Muhurat Puja Vidhi And Significance Check DetailsAs Isis Bride Shamima Begum Loses Uk Citizenship Battle Know What Happened To Her Friends Kadiza Sultana And Amira AbaseAdenovirus Infection Symptoms And Other Key Details About Mysterious Flu That Is Severely Affecting Kids In West BengalDont Lose Sleep Over Stock Prices Nifty Adani Saga Saurabh MukherjeaFollow us on:Download ET App:subscribe to our newsletterCopyright  2023 Bennett, Coleman  Co. Ltd. All rights reserved. For reprint rights: Times Syndication ServiceFind this comment offensiveChoose your reason below and click on the Report button. This will alert our moderators to take actionNameReason for reporting:Foul languageSlanderousInciting hatred against a certain communityOthersYour Reason has been Reported to the admin.XTo post this comment you mustLog InConnect with:The Economic TimesorFill in your details:Will be displayedWill not be displayedWill be displayedShare this Comment:Post to TwitterStories you might be interested inSubscribe to ourET Investment OpportunitiesSUBMIT","sentiment":2,"digital transaction":0.3595612347,"healthcare":0.1187907681,"news platform":0.6997195482,"data analytics":0.7554471493,"insurance":0.15112032,"investment":0.541595161,"global market":0.9633691311,"autonomous car":0.2827776372,"customer experience":0.5655041933,"data science":0.3957202435,"cryptocurrency":0.1155576855,"camera":0.2353582978,"robot":0.2590910196,"chatgpt":0.6772244573,"image":0.5523794889,"voice":0.5906407237,"patient care":0.1902462095,"research":0.9842090607}
{"id":1112,"cleaned text":"Can Xi Jinping control AI without overpowering it IN THE PAST month or two, the Chinese tech giants showed up.  Baidu, Huawei, SenseTime and Alibaba have all flaunted their artificial intelligence AI, which can power products and applications such as image generators, voice assistants and search engines.  Some have introduced AIpowered chatbots similar to ChatGoogle Tags, the Americandeveloped humanoid talker that has dazzled users.  The new offerings go by names like Ernie Bot Baidu, SenseChat SenseTime and Tongyi Qianwen Alibaba.  The latter roughly translates to the truth from a thousand questions.  But in China, the Communist Party defines the truth. AI poses a challenge to Chinese leaders.  Generative sorting, which processes text, image, audio, or video inputs to create new outputs, shows great promise.  Chinese tech companies, hit hard in recent years by regulatory repression and the pandemic, see generative AI as creating vast new revenue streams, similar to the opportunities offered by the advent of the internet or the smartphone. The party, however, sees generative AI as opening vast new avenues for information to spread beyond his control.  Its leaders may draw different comparisons than tech executives with the internet, which once seemed destined to help democratize China by increasing access to unfiltered information and easy communication tools.  Nailing jelly to a wall was how, in 2000, Bill Clinton described party attempts to control the web.  Yet, by deploying an army of censors and digital barricades, the party has largely succeeded in creating an internet that serves its own purposes and has cultivated an industry around it.  Could something similar happen with AI Rules proposed by Chinas top internet regulator on April 11 clarify governments concerns.  According to the Cyberspace Administration of China CAC, companies must submit a safety assessment to the state before using generative AI products to provide services to the public.  Companies would be responsible for the content generated by these tools.  Such content, according to the rules, must not subvert state power, incite secession, harm national unity, or disrupt the economic or social order.  And this must be in line with the fundamental socialist values of the country.  These restrictions may seem arcane, but similar rules, applied to the internet, allow the party to suppress any speech, from Tibetan and Uyghur rights to democracy, feminism or gay literature. Chinas proposals come as governments around the world wrestle with how to regulate AI.  Some, like the Americas and Britain, prefer a light touch, relying on existing laws to control the technology.  Others seem to think that new regulatory regimes are needed.  The European Union has proposed a law that categorizes the different uses of AI and applies increasingly stringent requirements based on the degree of risk.  Chinas approach seems more piecemeal and reactionary.  Last year, for example, the party feared deepfake images and videos would disrupt the tightly controlled information environment, so it issued rules on the technology that resemble the new regulations.  A prohibited clause AImedia generated without watermarks or other original clear labels. There are other similarities with the Chinese approach to the Internet.  Its web controls, often referred to as the Great Firewall, can seem monolithic.  But preventing harmful foreign content is only part of a more complex effort, developed over time and involving many different agencies and companies.  The first step was to lay the groundwork for an internet that the party could control, says Matt Sheehan of the Carnegie Endowment for International Peace, a think tank in Washington.  Today, the Chinese government is once again flexing its bureaucratic muscles and adding to its regulatory toolbox, this time with AI in mind.  Mandating security reviews and forcing companies to register their algorithms with the state are examples, says Sheehan. Chinas control of the internet hasnt stifled innovation: just look at companies like ByteDance, the Chinese parent company of popular shortvideo app TikTok.  But when it comes to generative AIits hard to see how a Chinese company could create something as expansive and humanistic i.e. unpredictable as ChatGoogle Tagswhile respecting government rules.  THE CAC says that the information generated by these tools must be true and accurate and that the data used to form it must be objective.  The party has its own definitions of these words.  But even the most advanced AI tools based on big language models will sometimes spout things that are actually wrong.  For a product like ChatGoogle Tags, which feeds on hundreds of gigabytes of data from all over the internet, its hard to sort through the entries for objectivity.  Strict enforcement of Chinese rules would virtually halt the development of the generation AI in China. For this reason, experts doubt that the measures will be strictly enforced.  The draft regulation leaves room for moderation.  When generated content violates the rules, the government requires filtering and other similar measures and optimization training within three months.  This resembles the modification of models done by Western companies to, for example, prevent their chatbots from spitting out homophobic content or providing instructions on how to make a bomb.  Local AI the regulations introduced by the city of Shanghai are even more relaxed, stipulating that minor breaches of the rules might not be punished at all.  The arbitrariness of the CACs proposed rules mean he can tighten or loosen as he sees fit.  Such flexibility in other countries could be seen as a good thing.  But as big internet companies can attest, the Chinese government has a history of rewriting and selectively enforcing rules based on the whims of President Xi Jinping.  In recent years, companies in areas such as ecommerce, social media and video games have had to rethink their business models.  In 2021, for example, state media declared video games to be spiritual opium and regulators told game companies to stop focusing on the bottom line and instead work on reducing the childrens gambling addiction. If Mr. Xi does not like where generative AI goes, it also has the power to reset this industry. one way chinese AI companies could be held back by limiting the personal data made available to train their AI models.  The party runs the most sophisticated surveillance state in the world, collecting masses of information about its citizens.  Until recently, Chinese tech companies were also able to suck up personal data, the lifeblood of many online businesses.  But this era of freewheeling seems to be coming to an end for the private sector.  Now, companies wishing to use certain types of personal data must, in theory, obtain consent.  Last year the CAC fined Didi Global, a ridesharing company, the equivalent of 1.2 billion for illegally collecting and mishandling user data.  The move was also seen as punishment for the companys decision, since reversed, to go public in America instead of China. Under the draft generation rules AIcompanies would be responsible for protecting users personal information. THE CACs the proposed regulations come six years after China presented a master plan for AI which called for major breakthroughs by 2025 and industry dominance by 2030. Progress towards these ends has been mixed.  Chinese companies in areas such as AIassisted image recognition and autonomous driving, which have much less to fear from governments concern for social stability, are doing well.  They benefit from a lot of public money in fact, some provide tools that allow state repression.  But China is still behind America in terms of investment and innovation.  Potential foreign backers have been put off by US sanctions on some Chinas AI giants.  Worse still, America has restricted exports to China of the type of advanced semiconductors that power AIa move that could hamper the industry. China could have more regulatory success.  According to the master plan, the country must have drafted the global code of ethics for AI by 2030. Thats overkill, but its rules on generating AI are more detailed and extensive than those suggested elsewhere and thus influence the debate on how to deal with new technology.  Chinas ability to quickly establish new regulations means that other countries will learn from them.  One of the risks is that it moves too forcefully and hinders innovation.  But Jeffrey Ding of George Washington University points to the other side of the argument.  Noting the ingenuity of Chinese internet companies, he says, Sometimes limits on creativity drive innovation more. However, the idea that China could serve as the main guide in terms of AI ethics should terrify Western governments.  They may share some of the same concerns as China, including around disinformation and data protection, but not for the same reasons.  Again, Chinas experience with the Internet is instructive.  She resolutely opposed the notion of the web as a space of freedom and openness.  When governments meet to discuss online regulation, China consistently sides with Russia and other free speech tramples.  Mr. Clinton was naive to think that the Communist Party couldnt hammer the internet into submission.  It would be naive of Western leaders today to think that they cannot do the same with AI.  What Are The Main Benefits Of Comparing Car Insurance Quotes Online LOS ANGELES, CA  ACCESSWIRE  June 24, 2020,  Compareautoinsurance.Org has launched a new blog post that presents the main benefits of comparing multiple car insurance quotes. For more info and free online quotes, please visit https:compareautoinsurance.Orgtheadvantagesofcomparingpriceswithcarinsurancequotesonline The modern society has numerous technological advantages. One important advantage is the speed at which information is sent and received. With the help of the internet, the shopping habits of many persons have drastically changed. The car insurance industry hasnt remained untouched by these changes. On the internet, drivers can compare insurance prices and find out which sellers have the best offers. View photos The advantages of comparing online car insurance quotes are the following: Online quotes can be obtained from anywhere and at any time. Unlike physical insurance agencies, websites dont have a specific schedule and they are available at any time. Drivers that have busy working schedules, can compare quotes from anywhere and at any time, even at midnight. Multiple choices. Almost all insurance providers, no matter if they are wellknown brands or just local insurers, have an online presence. Online quotes will allow policyholders the chance to discover multiple insurance companies and check their prices. Drivers are no longer required to get quotes from just a few known insurance companies. Also, local and regional insurers can provide lower insurance rates for the same services. Accurate insurance estimates. Online quotes can only be accurate if the customers provide accurate and real info about their car models and driving history. Lying about past driving incidents can make the price estimates to be lower, but when dealing with an insurance company lying to them is useless. Usually, insurance companies will do research about a potential customer before granting him coverage. Online quotes can be sorted easily. Although drivers are recommended to not choose a policy just based on its price, drivers can easily sort quotes by insurance price. Using brokerage websites will allow drivers to get quotes from multiple insurers, thus making the comparison faster and easier. For additional info, moneysaving tips, and free car insurance quotes, visit https:compareautoinsurance.Org Compareautoinsurance.Org is an online provider of life, home, health, and auto insurance quotes. This website is unique because it does not simply stick to one kind of insurance provider, but brings the clients the best deals from many different online insurance carriers. In this way, clients have access to offers from multiple carriers all in one place: this website. On this site, customers have access to quotes for insurance plans from various agencies, such as local or nationwide agencies, brand names insurance companies, etc. Online quotes can easily help drivers obtain better car insurance deals. All they have to do is to complete an online form with accurate and real info, then compare prices, said Russell Rabichev, Marketing Director of Internet Marketing Company. CONTACT: Company Name: Internet Marketing CompanyPerson for contact Name: Gurgu CPhone Number: 818 3593898Email: cgurgu@internetmarketingcompany.BizWebsite: https:compareautoinsurance.Org SOURCE: Compareautoinsurance.Org View source version on accesswire.Com:https:www.Accesswire.Com595055WhatAreTheMainBenefitsOfComparingCarInsuranceQuotesOnline View photos Increase in Covid19 cases, President Jokowi reiterates the importance of vaccinations and masks Apple CEO Tim Cook meets PM Modi and discusses the impact of tech in India Boris Johnson falls into depression  But no, just an image created by an AI When it comes to reforming UK MPs through feeding  POLITECO WeWork fights to stay listed on the New York Stock Exchange  Commercial Observer COVID19 may increase the risk of type 2 diabetes, especially for those who have been in the ICU The European Union demanded from the Xi Jinping regime the immediate release of two Chinese human rights activists Police case against Bollywood actor Sahil Khan for threatening woman at Mumbai gym DisclaimerPrivacy and PolicyTerms and ConditionsContact UsAbout us TittlePress AskByGeeks","sentiment":2,"digital transaction":0.9667429924,"healthcare":0.0524745658,"news platform":0.9798133373,"data analytics":0.9925482869,"insurance":0.1026944816,"investment":0.9912964702,"global market":0.8785973191,"autonomous car":0.0065670563,"customer experience":0.9989961982,"data science":0.9772456288,"cryptocurrency":0.0219938625,"camera":0.1053409651,"robot":0.1015028283,"chatgpt":0.9137515426,"image":0.3759647906,"voice":0.1896544397,"patient care":0.052481804,"research":0.9840976596}
{"id":1122,"cleaned text":"Elon Musk said Teslas AI robot Optimus will eventually cost less than a car and could lead to a future with no povertySamantha DelouyaSeptember 30, 2022, 11:14 PM2 min readTeslas Optimus demo video at AI Day 2022Tesla AI Day 2022Elon Musk said that Teslas AI bot, which debuted at the companys AI Day, could have widespread ramifications on society.The potential for Optimus is, I would say, appreciated by very few people, Musk said.Musk told the crowd he predicted the Optimus robot would eventually cost less than 20,000.Elon Musk has lofty goals for his companys planned humanoid AI robot product.A rough prototype of the bot, which is called Optimus, made its official debut on Friday night at Teslas annual AI Day by dancing and wavingto a crowd.But Elon Musk predicted that as the bots technology improves, it could have widespread ramifications for all of civilization.The potential for Optimus is, I would say, appreciated by very few people, Musk said.He went on to say that the current economy is limited by people and productivity, but that an AI bot like Teslas could change the calculation.If Teslas Optimus could handle manual labor, an economy becomes quasiinfinite, Musk predicted.This means a future of abundance. A future where there is no poverty, where you could have whatever you want in terms of products and services. It really is a fundamental transformation of civilization as we know it, he said.Last year, when Musk unveiled plans for the bot, he said it would be designed to do boring, repetitious work.While the AI robot appears to be in the extremely early stages, with Teslas engineers debuting only a rough prototype, Musk told the crowd he plans to make the robot at high volume and low cost as quickly as possible.Optimus is designed to be a very capable robot but made in very high volume, probably ultimately millions of units, and it is expected to cost much less than a car, Musk said.I would say probably less than 20,000 would be my guess.Read the original article on Business Insider TRENDING 1. Chinas Sept new home prices fall for third straight month  private survey 2. Swiss franc not highly valued  SNBs Jordan 3. Crypto lender Celsius not seeking payments for outstanding loans 4. Ukraine Latest: Putin Says Four Regions Annexation Is Forever 5. S.Korea, U.S. agree to implement liquidity measures if needed Recommended StoriesMoneyWiseDont even think about retiring until you have these 3 things completely paid off  your mortgage isnt one of themLeaving these accounts open could tarnish your golden years.13h agoYahoo Finance VideoWhy cruise stocks are plunging todayYahoo Finance Live anchors discuss stock performance for cruise lines.14h agoYahoo Finance VideoCarnival Cruise Line stock falls to lowest level since 1993Yahoo Finance Live examines Carnival Cruises stock after its latest earnings miss signifies a much longer path to profitability than expected.8h agoMarketWatchIts the worst September for stocks since 2002. What that means for October.September is living up to its reputation as an ugly month for stocks. Heres what the data says about October performance.7h agoYahoo Finance VideoStocks moving in after hours: FedEx, Nvidia, Intel, AMD, BiogenYahoo Finance Lives Seana Smith looks at several stocks trending in the afterhours trading session.7h agoMotley FoolWhy Annaly Capital Management Stock Fell 25 This WeekShares ofAnnaly Capital ManagementNYSE: NLY were among the losers this week as rising mortgage rates threatened to squeeze the mortgage REIT, and one analyst expressed caution on the stock.  The company also executed a reverse stock split at the beginning of the week.  Since the rate hike, which came with hawkish commentary from Fed Chair Jerome Powell, investors seem to believe the risk of a recession has grown, as well as the likelihood of a sustained highinterestrate environment.7h agoTheStreet.comMark Zuckerberg and Facebook Deliver Very Bad NewsMeta Platforms  is not doing well.  The socialmedia giant, parent of Facebook, Instagram and WhatsApp, has been sending alarming signals for several months.  It was ejected from the worlds top 10 most valuable companies, and this year its market capitalization has fallen by nearly 545 billion.11h agoBarrons.comFor LongTerm Investors, Its Time to Buy Tech Again. Here Are 20 Stocks to Look at First.The bear market in software stocks has already lasted far longer than the typical decline, according to MoffettNathanson,7h agoYahoo Finance VideoNIO Inc. stock performance and analyst projectionsNIO Inc. stock is trending on the Yahoo Finance Platform. Here is a visualization of NIO performance over time, how that performance compares to the wider industry, and analyst projections for the current quarter.Check out the ticker page here.6h agoTipRanksSeeking at Least 16 Dividend Yield This Top Analyst Suggests 2 Dividend Stocks to BuyInflation, interest rates, and recession  these are the bogeymen of investing, and theyve been watching over our shoulders for the past several months. We all know the story by now, the rate of inflation is running at generational highs, the Federal Reserve is hiking rates in an attempt to push back against high prices, and thats likely to tip the economy into recession. At a time like this, investors are showing a growing interest in finding strong defensive portfolio moves. Its a mindset t15h agoMotley FoolWhere Will AbbVie Be in 3 YearsIn spite of market turmoil, this year has been bright so far for AbbVie NYSE: ABBV.  The companys star drug Humira continues to grow, and even reached the milestone of more than 20 billion in sales last year.  Its other immunology drugs and the neuroscience business also are thriving.18h agoMarketWatchMany young people shouldnt save for retirement, says research based on a Nobel Prizewinning theoryNew research based on the lifecycle model says that people should strive for a consistent standard of living through their lives.10h agoYahoo Finance VideoSeptember selloffs are a return to the scene of the crime of June lows: StrategistPortfolio Wealth Advisors President and CIO Lee Munson and Sound Planning Group CEO David Stryzewski join Yahoo Finance Live to discuss the recent market volatility, inflation, rising rates, and more.8h agoMotley Fool2 UltraHighYield Energy Stocks to Buy Hand Over Fist and 1 to AvoidThese two energy stocks largely avoid the ups and downs of oil prices, while this other one is tied directly to those gyrations.7h agoMotley Fool4 Reasons Buying Qualcomm Near its 52Week Low Is a NoBrainerHeres why beatendown shares of Qualcomm look like one of the markets best buying opportunities.15h agoLA TimesBiden administration scales back eligibility for student loan forgiveness. Heres whos affectedThe Biden administration updated its guidance Thursday about which loans would be eligible for up to 20,000 in forgiveness, closing the door to some borrowers.1d agoInvestors Business DailyDow Jones Reverses To Bear Market Lows: Tesla Optimus Cant Walk Li Auto Sales SurpriseThe Dow Jones is at bear market lows. Tesla showed off the Optimus robot at AI Day. Tesla deliveries are on tap, with China EV rival Li Auto topping forecasts.2h agoInvestors Business DailyDow Jones Drops On Hot Inflation Data Tesla Stock Rises Before AI DayThe Dow Jones Industrial Average dropped Friday on hot inflation data. Tesla stock fell ahead of the companys AI Day.14h agoTheStreet.comHeres Why Royal Caribbean, Carnival Stock Are Good BuysYes, Carnival reported a biggerthanexpected loss but in this case, unlike taking a cruise, its the destination not the journey for the cruise lines.7h agoMore Stories","sentiment":2,"digital transaction":0.0865006894,"healthcare":0.5120077133,"news platform":0.4236320853,"data analytics":0.559127152,"insurance":0.0236635637,"investment":0.5785567164,"global market":0.9476988912,"autonomous car":0.0680797324,"customer experience":0.1967593879,"data science":0.176571101,"cryptocurrency":0.0439036377,"camera":0.0821689218,"robot":0.0683401302,"chatgpt":0.4524437487,"image":0.2734593153,"voice":0.2949048579,"patient care":0.1769493371,"research":0.8986587524}
{"id":1127,"cleaned text":"Harvard Researcher Warns AI Arms Race Could Destroy CivilizationbyMaggie HarrisonBoth countries could face catastrophe.3:05 PMGetty ImagesFuturismBoth countries could face catastrophe.AIrms RaceThe USChina AI arms race is here, with both international powers vying for ultimate power over the rapidly growing  and increasingly impressive  tech. But according to one Harvard researcher, if we dont put a lid on the competition soon, civilization as we know it could end up paying a hefty price.This competition comes with huge risks, Will Henshall, a graduate researcher studying public policy at Harvards Kennedy School of Government, wrote for The Boston Globe. If the United States and China dont find ways to reduce these risks, both countries could face catastrophe.McSteamyHenshalls argument frames AI as the next gamechanging generalpurpose technology, and as with other generalpurpose breakthroughs previously, countries will do whatever they can to establish dominance over it. In this case, as nations worldwide seek to incorporate AI further into advanced weapons, that means spending a lot of military money.In fiscal year 2021, the US government spent 10.8 billion on AI RD, 9.3 billion of which came from the Department of Defense, writes Henshall, meanwhile noting that the US has also been moving to make necessary AIbuilding resources like computer chips more difficult for China to get its hands on, seemingly in a means to stifle the competition. Chinese public expenditure on AI is less transparent, but analysts estimate that it is roughly comparable.Within the context of the broader generaltech history, this is normal behavior. New inventions have always powered nations and their economies, and world powers move quickly to make sure that they reap the lions share of the rewards, be they economic, defensive, or as in this case both.But AI could be radically different. A steam engine, the researchers preferred foil to the threat of AI, goes from point A to B. Sure, it could crash, but not even a fleet of steam engines could unintentionally destroy entire nations, let alone civilization as a whole.AI, at least in thought experiments like the paperclip problem, very well could. And right now, we just dont know enough about it to confidently prevent that from happening  especially in an environment where competition trumps cooperation, a system that inherently favors power and speed over precaution.And when it comes to technology this powerful  technology that again, we dont really even understand yet  prioritizing precaution seems more than necessary. Perhaps, as Henshall argues, for the sake of us all.READ MORE: The steam engine changed the world. Artificial intelligence could destroy it. The Boston GlobeMore on doomsday AI: Oxford Scientists Warn Ai Could Be More Deadly than Nuclear WeaponsShare This ArticleBot WreckRed Ventures Knew Its AI Lied and Plagiarized, Deployed It at CNET Anyway2:28 PMRead MorePleading the FifthExtremely Embarrassing Evidence Emerges Against CEO of Robot Lawyer StartupYesterdayRead MoreFaking FaceTwitter Is Verifying Accounts With AIGenerated FacesTuesdayRead MoreSocialNewsletterTopicsAbout UsContact UsCopyright , Camden Media Inc All Rights Reserved. See our User Agreement, Privacy Policy and Data Use Policy. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with prior written permission of Futurism. Articles may contain affiliate links which enable us to share in the revenue of any purchases made.Fonts by Typekit and Monotype.","sentiment":2,"digital transaction":0.0854627416,"healthcare":0.9706102014,"news platform":0.6468778253,"data analytics":0.6869332194,"insurance":0.0148371235,"investment":0.3660586178,"global market":0.9068464041,"autonomous car":0.0053218771,"customer experience":0.1817018092,"data science":0.6045329571,"cryptocurrency":0.0071531045,"camera":0.0333916955,"robot":0.0081248432,"chatgpt":0.5196446776,"image":0.3428117633,"voice":0.1348314136,"patient care":0.9739071131,"research":0.7473413348}
{"id":1151,"cleaned text":"China Has Won the Future of AI ExPentagon Official Says China Has Won the Future of AI, ExUS Defense Official Says A former software chief for the US Defense Department says Chinese AI will run the world by the 2040s. The international fight over artificial intelligence is already over and China is the undisputed winner, according to a former Pentagon official.Nicolas Chaillan, who was the firstever chief software officer for the US Department of Defense before resigning in September, told the Financial Times this week that China has built up an insurmountable lead in the field of artificial intelligence, according to Reuters.We have no competing fighting chance against China in 15 to 20 years, Chaillan told the paper. Right now, its already a done deal it is already over in my opinion. Whether it takes a war or not is kind of anecdotal.The problem Chaillan says is the lack of cooperation between private companies like Google who are leading US artificial intelligence development and the US government. Chinese firms developing AI, on the other hand, are compelled to cooperate with the Chinese government, which is taking the lead in directing development as well as making major financial investments in the key technology that will define the 21st century  if not the future of humanity itself.Is the debates over AI ethics in the US holding back innovationAnother key constraint on the USs artificial intelligence development is the ongoing debate over ethical and privacy concerns about artificial intelligence technologies like facial recognition, data collection, and similar controversies.Chaillan says that China is able to speed ahead of the US by ignoring these ethical controversies  all you need to do is look at Chinas Social Credit program.And without question, the Chinese governments internal authority over such matters is absolute and even entends into other countries, so if it decides it wants an AI system built that can track people all over the planet, they have the means and the authority to see that such a system gets built in record time and there really isnt much anyone can do to prevent it.AdvertisementThis and other reasons are why weve been saying for years now that Chinese artificial intelligence is going to run the world, so its probably about time we came together as a species and charted this course into the future collectively because it is certainly coming. Stay on top of the latest engineering news Just enter your email and well take care of the rest: By subscribing, you agree to our Terms of Use and Privacy Policy. You may unsubscribe at any time. Science China May Use Existing Rocket to Speed Up Moon Landing Innovation The US Air Force Says RealLife Force Fields Are On the Horizon  Copyright 2021  Interesting Engineering, Inc.  All Rights Reserved  Terms of ServicePolicies x  We use cookies to ensure you get the best experience on our website. Please review our Privacy Policy for more information andor to change your cookie settings at any time. If you continue to use this site, you consent to our use of cookies.","sentiment":2,"digital transaction":0.0608583465,"healthcare":0.0240396466,"news platform":0.3643737733,"data analytics":0.2064448148,"insurance":0.0149874948,"investment":0.3767430484,"global market":0.9495288134,"autonomous car":0.0253522228,"customer experience":0.1017039195,"data science":0.5490105152,"cryptocurrency":0.0160883013,"camera":0.0315727778,"robot":0.038054239,"chatgpt":0.29862988,"image":0.2106466442,"voice":0.1712342501,"patient care":0.0132655017,"research":0.811091125}
{"id":1159,"cleaned text":"U.S. joins G7 artificial intelligence group to counter China The U.S. has joined an international panel for setting ethical guidelines for the use of artificial intelligence. The Trump administration had earlier dismissed the idea. The White Houses chief technology officer, Michael Kratsios, told The Associated Press on Thursday it is important to establish shared democratic principles as a counter to Chinas record of twisting technology in ways that threaten civil liberties.  Chinese technology companies are attempting to shape international standards on facial recognition and surveillance at the United Nations, he said.  The Trump administration had been the lone holdout among leaders of the Group of Seven  the worlds wealthiest democracies  in setting up the Global Partnership on AI.  The partnership launched Thursday after a virtual meeting between national technology ministers. It was nearly two years after the leaders of Canada and France announced they were forming a group to guide the responsible adoption of AI based on shared principles of human rights, inclusion, diversity, innovation and economic growth. The Trump administration objected to that approach, arguing that too much focus on regulation would hamper U.S. innovation. But negotiations over the past year and changes to the groups scope led the U.S. to join, Kratsios said.  We worked very hard to make it clear that it would not be a standardsetting or policymaking body, he said. U.S. involvement is important because of the large role that American tech firms play globally and its historic advocacy for human rights, said Kay Mathiesen, an associate professor focused on computer ethics at Northeastern University in Boston. U.S. tech companies such as Microsoft, Google and Apple are all concerned about what guidelines they should be following to use AI responsibly, she said. Given their global presence, the fact that the U.S. wasnt involved does not mean that they would not end up having to follow any regulations developed by the rest of the G7.  Copyright 2020 The Associated Press. All rights reserved. This material may not be published, broadcast, rewritten or redistributed without permission. GaijinPot curates jobs from companies in Japan that want to hire people like you Use your Facebook account to login or register with JapanToday. By doing so, you will also receive an email inviting you to receive our news alerts. Tokyo govt to trial 5G antennaequipped smart poles with Sumitomo Corp and NEC Looting erupts during Minneapolis protests over black mans killing by white police officer Japan aims to revive tourism industry by subsidizing people to go on vacation TBS News Explains Japan Has Fewer COVID19 Cases Thanks to Japanese Pronunciation The Death Of Terrace House Cast Member Hana Kimura and Japans Mental Health Struggles Top Jobs in Japan with No Japanese Required  Week 21, 2020","sentiment":2,"digital transaction":0.1120653003,"healthcare":0.0235835817,"news platform":0.5484305024,"data analytics":0.4802363515,"insurance":0.0239816643,"investment":0.9198218584,"global market":0.3762969077,"autonomous car":0.0660681725,"customer experience":0.1226529181,"data science":0.4659659863,"cryptocurrency":0.020668352,"camera":0.040670801,"robot":0.0508739576,"chatgpt":0.2288234085,"image":0.3074207306,"voice":0.2998974621,"patient care":0.0192704909,"research":0.2511651814}
{"id":1168,"cleaned text":"This AI image generator lets you type in words and get weird pictures back  It only took Matt Laming, a 19yearold from the United Kingdom, about a month to hit a million followers on Twitter. And all it required was sharing a steady stream of the most outlandish computergenerated images that he and a bunch of internet strangers could think up. In recent weeks, the digital marketing apprentice, better known online as @weirddalle, has shared images depicting things like people vacuuming in the forest, the Demogorgon from Netflixs Stranger Things holding a basketball, and a Beanie Baby that looks a lot like Danny DeVito. These and other pictures, which range from ridiculous to disturbing, were created with a freely available artificial intelligence system called Craiyon. To use it, you just type what youd like it to envision  A rainbow lion eating a slice of pizza  and it will spit out pictures in response. I think thats the main draw of it: You can make anything a reality, Laming said in an interview with CNN Business. The brainchild of Boris Dayma, an Austinbased machinelearning engineer, Craiyon is popularizing a growing trend in AI. Computers are getting better and better at ingesting words and producing increasingly realisticlooking images in response. Lately, people are typing in about 5 million prompts per day, Dayma said. There are similar, much more powerful AI systems than Craiyon, such as OpenAIs DALLE Craiyon was initially named DALLE Mini as an homage and DALLE 2, as well as Googles Imagen. But unlike Craiyon, which anyone can try, most of these are not available to the public: DALLE 2 is open to users via invitation only, while Imagen has not been opened up to users outside Google. I think its important to be able to have an alternative where everybody has the same access to this type of technology, Dayma said. In the process, however, Craiyon is effectively acting as a trial run for what could happen  good or bad  in the future if anyone can access such AI systems and solicit any kind of image from them with just a few words. And as with many nascent technologies, it is a work in progress in the near term, if left unchecked, it may produce outcomes that reinforce stereotypes and biases. Dayma and some other coders built the AI system last July during a hackathon hosted by Google and Hugging Face, a company that builds and hosts AI models. Initially, Dayma said, he built it as a technical challenge he thought DALLE was cool and he wanted to make it himself. He posted the texttoimage generator  then called DALLE Mini  on Hugging Face, where anyone could try it out its still available there under that name. But it didnt get much attention beyond the AI community until the past couple of months, perhaps due to the limited quality of the images it could produce. In the past, for example, it would be able to envision simple things like a landscape, Dayma said. But little by little, hes done things such as fixing bugs and improving code, enabling it to get better at coming up with more complicated images, such as the Eiffel Tower landing on the moon. When the model started drawing that, I was very happy, he said. But then people came up with things even more creative, and somehow the model reached a moment where it was able to do something that looked like what they asked for, and I think that was a turning point. The images Craiyon generates are not nearly as realisticlooking as what DALLE 2 or Imagen can come up with, but theyre fascinating nonetheless: People tend to blur into objects, and images look fuzzy and at least slightly askew. For now, Craiyon is mostly being used for fun by people like Laming  perhaps in part because its results are not nearly as crisp or photorealistic as the images you can get from DALLE 2 or Imagen, but also because people are still trying to figure out what to do with it. The Craiyon website currently runs ads to recoup costs for the servers that power the AI system, and Dayma said hes trying to figure out how to make money from it while also allowing people to play with it for free. Many of the images Laming posts to Twitter come from a Reddit forum he created for people to post the prompts and resulting images they got when they ran them through the system. This is the same approach he takes for another Twitter account he runs, @spotifyweird, which tweets strange Spotify playlists. Lamings most popular tweet so far was a post on June 14 with the prompt Fisher Price guillotine, which was initially posted to his subreddit by a Reddit user. Popular posts may take an item from news or pop culture and mash it up with something completely random or shocking or gross  such as Minionsthemed urinals  or simply come up with a funny play on words think The Notorious BFG or Ice Cube in an ice cube. As users get more familiar with the kinds of results Craiyon can produce, the prompts get increasingly specific in terms of the types of imagery they want to see  such as calling for a medical illustration of a burrito or courtroom sketches showing what it might look like if a capybara sued Elon Musk. Sometimes theyre just really weird, such as in this depiction of archaeologists discovering a plastic chair. To come up with a good prompt, Laming suggested, just think of the most outlandish situation to put someone or something in. In effect, the prompts that lead to these pictures are themselves arguably a new form of creativity. Mar Hicks, an associate professor at the Illinois Institute of Technology who studies the history of technology, said this AI system reminds them of early chatbots such as Eliza, a computer program built by MIT professor Joseph Weizenbaum in the 1960s and meant to mimic a therapist. Such programs could convince people they were communicating with another human, even though the computer didnt truly understand what it was being told Eliza gave scripted responses. I think its appealing the same way that a game of chance is appealing, or a party game, Hicks said. Where theres some level of uncertainty about whats going to happen. But Hicks is concerned about the AI systems ability to respond to any written prompt with images, rather than occasionally giving an error message indicating it doesnt know how to parse the phrases a person typed. That means you will be getting garbage out some times, they said, and the onus is on the users to figure out why. This was the case with some prompts I fed Craiyon, making it occasionally disappointing and frustrating to use, but Dayma pointed out that its not easy to predict what it can or cant draw, and sometimes the results are surprising, or at least surprisingly weird. Dayma said hes heard from people using Craiyon to come up with a logo for a new business and as imagery in videos. OpenAI and Google have suggested that their systems might eventually be used for things like image editing and generating stock images. While there may be creative possibilities for these AI systems, they share a key problem that pervades the AI industry at large: bias. Theyre all trained on data that includes wide swaths of the internet, which means the images they create can also lay bare a host of biases including gender, racial, and social stereotypes. Such biases are evident even in Craiyons fuzzylooking images. And because anyone can type anything they want into it, it can be a disturbing window into how stereotypes can seep into AI. I recently gave Craiyon the prompt a lawyer, for instance, and the results were all blurry images of what appeared to be men in black judges robes. The prompt a teacher, meanwhile, yielded only figures that appeared to be women, each in a buttondown shirt. Dayma is aware of this. A Frequently asked questions section on Craiyons website mentions that the models reliance on internet data may result in images that contain harmful stereotypes, and that those behind Craiyon are working to document and analyze its biases. Dayma noted that many AI systems are biased, whether or not users are aware of it, and said he likes that everyone can observe Craiyons biases directly in the images it makes. He also said that he tried to prevent the model behind Craiyon from learning certain concepts to start with. However, it only took me a few minutes to come up with some explicit prompts that yielded images that are, to put it bluntly, not safe for work. Asked whether he thinks its general availability could be a bad thing, given its obvious biases, he pointed out that the images it comes up with, while betterlooking than in the past, are clearly not realistic. If I draw the Eiffel Tower on the moon, I hope nobody believes the Eiffel Tower is really on the moon, he said. TheCNNWire   2022 Cable News Network, Inc., a WarnerMedia Company. All rights reserved. Leave a Reply Cancel replyYou must be logged in to post a comment. ","sentiment":2,"digital transaction":0.766664207,"healthcare":0.0636535734,"news platform":0.9507353902,"data analytics":0.987126708,"insurance":0.1046342999,"investment":0.9975937009,"global market":0.8912808299,"autonomous car":0.2526838779,"customer experience":0.9443917871,"data science":0.9684565663,"cryptocurrency":0.0670970902,"camera":0.4149144888,"robot":0.4480260313,"chatgpt":0.5455754399,"image":0.9146031141,"voice":0.767167747,"patient care":0.3071449399,"research":0.9621893167}
{"id":1228,"cleaned text":"Apple is reportedly experimenting with languagegenerating AI If not for last weeks Silicon Valley Bank SVB collapse almost every conversation in tech seems to be centered around AI and chatbots. In the last few days, Microsoftbacked OpenAI released a new language model called GPT4. Its competitor Anthropic released the Claude chatbot. Google said that it is integrating AI into its Workspace tools like Gmail and Docs. Microsoft Bing has brought attention to itself with a chatbotenabled search. The one name missing from the action Apple. Last month, the Cupertinobased company held an internal event that focused on AI and large language models. According to a report from the New York Times, many teams including people working on Siri are testing languagegenerating concepts regularly. People have complained about Siri not understanding queries including mine for a long time. Siri and other assistants like Alexa and Google Assistant have failed to understand different accents and phonetics of people living in different parts of the world even if they are speaking the same language. The newly minted fame of ChatGPT and textbased search makes it easier for people to interact with different AI models. But currently, the only way to chat with Apples AI assistant Siri is to enable a feature under accessibility settings. In an interview with NYT, former Apple engineer John Burke, who worked on Siri said that Apples Assistant has had a slow evolution because of clunky code, which made it harder to push even basic feature updates. He also mentioned that Siri had a big database pile with a ton of words. So when engineers needed to add features or phrases, the database had to be rebuilt  a process that allegedly took up to six weeks. The NYT report didnt specify if Apple is building its own language models or wants to adopt an existing model. But just like Google and Microsoft, the Tim Cookled company wouldnt want to restrict itself to offering a Siripowered chatbot. Apple has long prided itself to be an ally of artists and creators, it would expectedly want to apply advances in language models to those areas. The company has been using AIpowered features for a while now, even if they are not apparent at first. This includes better suggestions on the keyboard, processing in photography, mask unlocks with Face ID, separation of objects from the background across the system, handwashing and crash detection on Apple Watch, and most recently karaoke feature on Apple Music. But none of them might be intheface as chatbots. Apple has been generally quiet about its AI efforts. But in January, the company started a program offering authors AIpowered narration services to turn their books into audiobooks. This indicated that the iPhone maker is already thinking about use cases for generative AI. I wont be surprised if we hear more about the companys efforts in these areas at the Worldwide Developer Conference WWDC in a few months.","sentiment":2,"digital transaction":0.0716053545,"healthcare":0.1101200208,"news platform":0.9687122703,"data analytics":0.362078011,"insurance":0.0835044533,"investment":0.1120029017,"global market":0.9616158009,"autonomous car":0.1552428007,"customer experience":0.2452637106,"data science":0.1137749553,"cryptocurrency":0.0292015709,"camera":0.1321488619,"robot":0.0583905317,"chatgpt":0.3543566167,"image":0.1664393544,"voice":0.4061954021,"patient care":0.0561960414,"research":0.0942339823}
{"id":1233,"cleaned text":"Hey Google ... what movie should I watch today How AI can affect our decisions Hey Google  what movie should I watch today How AI can affect ourdecisions TaeWoo Kim does not work for, consult, own shares in or receive funding from any company or organization that would benefit from this article, and has disclosed no relevant affiliations beyond their academic appointment. University of Technology Sydney provides funding as a founding partner of The Conversation AU. Social media algorithms, artificial intelligence and our own genetics are among the factors influencing us beyond our awareness. This raises an ancient question: do we have control over our own lives This article is part of The Conversations series on the science of free will. Have you ever used Google Assistant, Apples Siri or Amazon Alexa to make decisions for you Perhaps you asked it what new movies have good reviews, or to recommend a cool restaurant in your neighbourhood. Artificial intelligence and virtual assistants are constantly being refined, and may soon be making appointments for you, offering medical advice, or trying to sell you a bottle of wine. Although AI technology has miles to go to develop social skills on par with ours, some AI has shown impressive language understanding and can complete relatively complex interactive tasks. In several 2018 demonstrations, Googles AI made haircut and restaurant reservations without receptionists realising they were talking with a nonhuman. Its likely the AI capabilities developed by tech giants such as Amazon and Google will only grow more capable of influencing us in the future. My colleague Adam Duhachek and I found AI messages are more persuasive when they highlight how an action should be performed, rather than why. For example, people were more willing to put on sunscreen when an AI explained how to apply sunscreen before going out, rather than why they should use sunscreen. We found people generally dont believe a machine can understand human goals and desires. Take Googles AlphaGo, an algorithm designed to play the board game Go. Few people would say the algorithm can understand why playing Go is fun, or why its meaningful to become a Go champion. Rather, it just follows a preprogrammed algorithm telling it how to move on the game board. Our research suggests people find AIs recommendations more persuasive in situations where AI shows easy steps on how to build personalised health insurance, how to avoid a lemon car, or how to choose the right tennis racket for you, rather than why any of these are important to do in a human sense. People tend to think of AI as not having free will and therefore not having the ability to explain why something is important to humans. Most of us believe humans have free will. We compliment someone who helps others because we think they do it freely, and we penalise those who harm others. Whats more, we are willing to lessen the criminal penalty if the person was deprived of free will, for instance if they were in the grip of a schizophrenic delusion. But do people think AI has free will We did an experiment to find out.  Someone is given 100 and offers to split it with you. Theyll get 80 and youll get 20. If you reject this offer, both you and the proposer end up with nothing. Gaining 20 is better than nothing, but previous research suggests the 20 offer is likely to be rejected because we perceive it as unfair. Surely we should get 50, right Do social media algorithms erode our ability to make decisions freely The jury is out But what if the proposer is an AI In a research project yet to be published, my colleagues and I found the rejection ratio drops significantly. In other words, people are much more likely to accept this unfair offer if proposed by an AI. This is because we dont think an AI developed to serve humans has a malicious intent to exploit us  its just an algorithm, it doesnt have free will, so we might as well just accept the 20. The fact people could accept unfair offers from AI concerns me, because it might mean this phenomenon could be used maliciously. For example, a mortgage loan company might try to charge unfairly high interest rates by framing the decision as being calculated by an algorithm. Or a manufacturing company might manipulate workers into accepting unfair wages by saying it was a decision made by a computer. To protect consumers, we need to understand when people are vulnerable to manipulation by AI. Governments should take this into account when considering regulation of AI. In other work yet to be published, my colleagues and I found people tend to disclose their personal information and embarrassing experiences more willingly to an AI than a human. We told participants to imagine theyre at the doctor for a urinary tract infection. We split the participants, so half spoke to a human doctor, and half to an AI doctor. We told them the doctor is going to ask a few questions to find the best treatment and its up to you how much personal information you provide. Participants disclosed more personal information to the AI doctor than the human one, regarding potentially embarrassing questions about use of sex toys, condoms, or other sexual activities. We found this was because people dont think AI judges our behaviour, whereas humans do. Indeed, we asked participants how concerned they were for being negatively judged, and found the concern of being judged was the underlying mechanism determining how much they divulged. It seems we feel less embarrassed when talking to AI. This is interesting because many people have grave concerns about AI and privacy, and yet we may be  more willing to share our personal details with AI. As AI develops further, we need to understand how it affects human decisionmaking. We also studied the flipside: what happens when people start to believe AI does have free will We found giving AI humanlike features or a human name could mean people are more likely to believe an AI has free will. AI can then better persuade people on questions of why, because people think the humanlike AI may be able to understand human goals and motivations AIs unfair offer is less likely to be accepted because the humanlooking AI may be seen as having its own intentions, which could be exploitative people start feeling judged by the humanlike AI and feel embarrassed, and disclose less personal information people start feeling guilty when harming a humanlooking AI, and so act more benignly to the AI. We are likely to see more and different types of AI and robots in future. They might cook, serve, sell us cars, tend to us at the hospital and even sit on a dining table as a dating partner. Its important to understand how AI influences our decisions, so we can regulate AI to protect ourselves from possible harms.","sentiment":2,"digital transaction":0.1920893043,"healthcare":0.0335254967,"news platform":0.3642361462,"data analytics":0.2949068248,"insurance":0.0212546866,"investment":0.3985522091,"global market":0.9270427823,"autonomous car":0.1200759858,"customer experience":0.2889351249,"data science":0.168465212,"cryptocurrency":0.0269923899,"camera":0.0426802449,"robot":0.0827361569,"chatgpt":0.2761482894,"image":0.2199303061,"voice":0.223931402,"patient care":0.0272069052,"research":0.9384921193}
{"id":1243,"cleaned text":"The Global Demand of Artificial Intelligence AI in HIV and AIDS Market, Growth Analysis, Latest Trends and Forecast till 2026  This report also researches and evaluates the impact of Covid19 outbreak on theArtificial Intelligence AI in HIV and AIDSindustry, involving potential opportunity and challenges, drivers and risks. We present the impact assessment of Covid19 effects onArtificial Intelligence AI in HIV and AIDSand market growth forecast based on different scenario optimistic, pessimistic, very optimistic, most likely etc.. The latest report on the globalArtificial Intelligence AI in HIV and AIDSmarketsuggests a positive growth rate in the coming years. Analysts have studied the historical data and compared it with the current market scenario to determine the trajectory this market will take in the coming years. The investigative approach taken to understand the various aspects of the market is aimed at giving the readers a holistic view of the globalArtificial Intelligence AI in HIV and AIDSmarket. The research report provides an exhaustive research report that includes an executive summary, definition, and scope of the market. Click to view the full report TOC, figure and tables:https:www.globalinforesearch.comreports686633artificialintelligenceaiinhivaids Chapter 1:Introduction, market driving force product scope, market risk, market overview, and market opportunities of the globalArtificial Intelligence AI in HIV and AIDSmarket Chapter 2:Evaluating the leading manufacturers of the globalArtificial Intelligence AI in HIV and AIDSmarket which consists of its revenue, sales, and price of the products Chapter 3:Displaying the competitive nature among key manufacturers, with market share, revenue, and sales Chapter 4:Presenting globalArtificial Intelligence AI in HIV and AIDSmarket by regions, market share and with revenue and sales for the projected period Chapter 5, 6, 7, 8 and 9: To evaluate the market by segments, by countries and by manufacturers with revenue share and sales by key countries in these various regions GlobaIInfoResearchGIRis a report publisher, a customer, interestbased suppliers. Is in the best interests of our clients, they determine our every move. At the same time, we have great respect for the views of customers. With the improvement of the quality of our research, we develop custom interdisciplinary and comprehensive solution. For further development, we will do better and better. GlobalInfoResearch will with excellent professional knowledge and experience to carry out all aspects of our business. At the same time, we will thoroughly look for information, to give a more comprehensive development. Add:FLATRMA9FSILVERCORPINTERNATIONALTOWER707713NATHANROADMONGKOKKLHONGKONG 20212026, Artificial Intelligence AI in HIV and AIDS, global market, Market Growth, market Overview, Market Sales, Market Share, Market Size  Artificial Intelligence AI in Alzheimers Applications Market Global Opportunity Analysis and Industry Forecast, 20162021 Leave a Reply Cancel replyYour email address will not be published. Required fields are marked Comment Name    Save my name, email, and website in this browser for the next time I comment. Global Cat Automatic Feeder Recent Developments  Emerging Trends To 2026 Laser Annealing Devices Industry Outlook, Growth Prospects and Key Opportunities 2026 Inflammatory Bowel Diseases Therapeutics Market Report 2021 : Industry Insights, Estimated Yield, Recent Developments and Forecast to 2027 with Dominant Regions and Countries Data Global Residential Solar Systems MarketFuture Trends, Covid19 Impact,Competition and Forecasts 2021 to 2026","sentiment":2,"digital transaction":0.2900880873,"healthcare":0.1095752865,"news platform":0.5983650684,"data analytics":0.8177992702,"insurance":0.0898129866,"investment":0.7882847786,"global market":0.8892742395,"autonomous car":0.0593646429,"customer experience":0.4905136526,"data science":0.3404770792,"cryptocurrency":0.0490788333,"camera":0.1932585537,"robot":0.1421736181,"chatgpt":0.4145029187,"image":0.4708913863,"voice":0.5374945998,"patient care":0.0667464063,"research":0.9527613521}
{"id":1244,"cleaned text":"Artificial Intelligence AI in Agriculture Market Report 20202027, Competitive Analysis,Proposal Strategy, Top Addressable Targets, Key Requirements The latest report titled Global Artificial Intelligence AI in Agriculture Market, published by Market Expertz, provides the reader with a comprehensive view of the global Artificial Intelligence AI in Agriculture industry, acquainting them with the latest market trends, industry insights, and market share. The report provides an indepth investigation of the global market, largely focusing on each segment and subsegment of the Artificial Intelligence AI in Agriculture market. The market forecasts included in the report are performed by our team of experts and are of great significance as they provide deep insights into various crucial industry parameters. Get a sample copy of the report including the analysis of COVID19 impact @ https:www.marketexpertz.comsampleenquiryform122447 These facts and figures help readers evaluate the global market growth, production, and consumption rates, volatility in demand and product prices, and upcoming market trends over the projected period. The market research report contains significant details on the global Artificial Intelligence AI in Agriculture market value based on market dynamics and various growth factors. It scrutinizes several key aspects of the market, including the latest technological innovations in the industry, ongoing trends, and developmental opportunities. One of the most vital components of the report is the SWOT analysis, coupled with a detailed overview of the markets competitive landscape. The report covers extensive analysis of the key market players in the market, along with their business overview, expansion plans, and strategies. The key players studied in the report include: Abundant Robotics Inc., Aquabyte, Inc., aWhere Inc., Ceres Imaging Inc., Delair, ecoRobotix Ltd., Farmers Edge, Taranis Ag, XAG Co., Ltd. A SWOT analysis is performed on the leading companies engaged in the Artificial Intelligence AI in Agriculture market to offer a better understanding of the strengths, opportunities, weaknesses, and threats of the leading companies. It also covers production and consumption rate, the volatility of prices and demands, market share, market size, global position, and market position of each player. The report also analyses key elements such as growth trends, concentration area, business expansion strategies, market reach, and other key features that offer companies insightful data to fortify their position in the Artificial Intelligence AI in Agriculture industry. In market segmentation by types of Artificial Intelligence AI in Agriculture, the report covers In market segmentation by applications of the Artificial Intelligence AI in Agriculture, the report covers the following uses However, the report takes into account the current COVID19 impact on the global economy and this particular business sector. The global Artificial Intelligence AI in Agriculture market growth has been extensively hampered by the current economic situation triggered by the COVID19 pandemic. The pandemic has led to some devastating effects on the global economy, besides disrupting the functioning of the Artificial Intelligence AI in Agriculture industry. It offers an exhaustive analysis of the present and future effects of the pandemic on this business sphere. Moreover, the adverse effects of the coronavirus pandemic on the global Artificial Intelligence AI in Agriculture market, as well as its fundamental segments, have also been elucidated in this report. The report presents a thorough examination of the Artificial Intelligence AI in Agriculture market, elaborating on its core segments. The report conducts historical and future assessments of the market dynamics and offers precise data in a wellorganized order. The report evaluates the most prominent market growth potentials, dynamic market trends, driving factors, restraints, investment opportunities, and threats. The report is inclusive of an indepth study of the industry variables, manufacturers value chain, sales volume, market share, competitive landscape, and effective business tactics. The report further identifies the key regions and segments dominating the market. These regions are foreseen to register fastpaced growth over the forecast duration. Thank you for reading our report. Customization of the report is available according to the requirements of clients. In case of further queries about the report, do get in touch with us. Our team will make sure your report is tailored according to your needs. Thank you for reading our report. Please connect with us to know more about the report and customization options. Our team will ensure the report is well suited to meet your requirements. Planning to invest in market intelligence products or offerings on the web Then marketexpertz has just the thing for you  reports from over 500 prominent publishers and updates on our collection daily to empower companies and individuals catchup with the vital insights on industries operating across different geography, trends, share, size and growth rate. Theres more to what we offer to our customers. With marketexpertz you have the choice to tap into the specialized services without any additional charges. Artificial Intelligence AI in Agriculture Industry, Artificial Intelligence AI in Agriculture Market, Artificial Intelligence AI in Agriculture Market 2020, Artificial Intelligence AI in Agriculture Market COVID19 Impact Analysis Report, Artificial Intelligence AI in Agriculture Market Forecast, Artificial Intelligence AI in Agriculture Market Growth, Artificial Intelligence AI in Agriculture Market share, Artificial Intelligence AI in Agriculture Market size, Artificial Intelligence AI in Agriculture Market trend  RISING TRENDS OF PHOTO EDITING SOFTWARE MARKET IN WORLDWIDE  TOPMOST KEY PLAYERS LIKE ADOBE,  DXO OPTICS,  CYBERLINK, COREL, ON1, MACPHUN, PHASEONE Impact Of Covid 19 On Stock Option Plan Administration Software Market 2020 Industry Challenges Business Overview And Forecast Research Study 2026 Impact Of Covid 19 On Pregnancy Test Market 2020 Industry Challenges Business Overview And Forecast Research Study 2026 Educational Toy: Market 2020 Rising Best Technology Trends Research By Major Key Players  LEGO, Mattel, Hasbro, Bandai Bathroom Vanities Market 2020 Size, Outlook, Segments, Industry Insights And Forecasts 2027 Competencybased Education Spending: Market 2020 is Booming Worldwide with Key Players  Blackboard, D2L, Ellucian, Instructure Hydrogenated Nitrile Butadiene Rubber Market to Expand with Significant CAGR During 2017 to 2026","sentiment":2,"digital transaction":0.311866194,"healthcare":0.0912124217,"news platform":0.445433408,"data analytics":0.6146478057,"insurance":0.0621872358,"investment":0.6120395064,"global market":0.9837498665,"autonomous car":0.4455425441,"customer experience":0.3876229823,"data science":0.32776016,"cryptocurrency":0.0625448227,"camera":0.1357175261,"robot":0.2526674271,"chatgpt":0.3288711309,"image":0.2820876539,"voice":0.3884928524,"patient care":0.0503737219,"research":0.9399843812}
